{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open('../style.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an LR-Table-Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Grammar for Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the goal is to generate an *SLR-table-generator* we first need to implement a parser for context free grammars.\n",
    "The file `arith.g` in the directory `Examples` contains an example grammar that describes arithmetic expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat Examples/arith.g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <span style=\"font-variant:small-caps;\">Ply</span> to develop a parser for context free grammars.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ 'VARIABLE',  # r'[a-z][a-z0-9_]*'\n",
    "           'TOKEN',     # r'[A-Z][A-Z0-9_]*'\n",
    "           'LITERAL',   # r\"'.'\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_VARIABLE = r'[a-z][a-z0-9_]*'\n",
    "t_TOKEN    = r'[A-Z][A-Z0-9_]*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_comment(t):\n",
    "    r'//.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_LITERAL(t):\n",
    "    r\"'.*?'\"\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literals = [':', '|', ';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ignore = ' \\t\\r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_newline(t):\n",
    "    r'\\n'\n",
    "    t.lexer.lineno += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column(token):\n",
    "    program    = token.lexer.lexdata  # the complete string given to the scanner\n",
    "    line_start = program.rfind('\\n', 0, token.lexpos)\n",
    "    return token.lexpos - line_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    column = find_column(t)\n",
    "    print(f\"Illegal character '{t.value[0]}' in line {t.lineno}, column {column}.\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scanner(file_name):\n",
    "    with open(file_name, 'r') as handle:\n",
    "        program = handle.read() \n",
    "    print(program)\n",
    "    lexer.input(program)\n",
    "    lexer.lineno = 1          # reset line number\n",
    "    for t in lexer:           # start scanning and collect all tokens\n",
    "        print(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scanner('Examples/arith.g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by generating both scanner and parser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.yacc as yacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 'grammar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_grammar_one(p):\n",
    "    \"grammar : rule\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_grammar_more(p):\n",
    "    \"grammar : rule grammar\"\n",
    "    p[0] = p[1] + p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_rule(p):\n",
    "    \"rule : VARIABLE ':' body_list ';'\"\n",
    "    p[0] = [ (p[1],) + body for body in p[3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_body_list_one(p):\n",
    "    \"body_list : body\"\n",
    "    p[0] = [p[1]]\n",
    "\n",
    "def p_body_list_more(p):\n",
    "    \"body_list : body '|' body_list \"\n",
    "    p[0] = [p[1]] + p[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_body_empty(p):\n",
    "    \"body : \"\n",
    "    p[0] = ()\n",
    "\n",
    "def p_body_more(p):\n",
    "    \"body : item body\"\n",
    "    p[0] = (p[1],) + p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_item_variable(p):\n",
    "    \"item : VARIABLE\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_terminal(p):\n",
    "    \"item : TOKEN\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_literal(p):\n",
    "    \"item : LITERAL\"\n",
    "    p[0] = p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_error(t):\n",
    "    column = find_column(t)\n",
    "    if t:\n",
    "        print(f'Syntax error at token \"{t.value}\" in line {t.lineno}, column {column}.')\n",
    "    else:\n",
    "        print('Syntax error at end of input.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yacc.yacc(write_tables=False, debug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file):\n",
    "    lexer.lineno = 1\n",
    "    with open(file, 'r') as handle:\n",
    "        grammar = handle.read() \n",
    "    print(grammar)\n",
    "    ast = yacc.parse(grammar)\n",
    "    return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleList = parse('Examples/arith.g')\n",
    "ruleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Class `GrammarRule`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `GrammarRule` is used to store a single grammar rule.  As we have to use objects of type `GrammarRule` as keys in a dictionary later, we have to provide the methods `__eq__`, `__ne__`, and `__hash__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrammarRule:\n",
    "    def __init__(self, variable, body):\n",
    "        self.mVariable = variable\n",
    "        self.mBody     = body\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, GrammarRule)    and \\\n",
    "               self.mVariable == other.mVariable and \\\n",
    "               self.mBody     == other.mBody\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__repr__())\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.mVariable} → {\" \".join(self.mBody)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parse_grammar` takes a string `filename` as its argument and returns the grammar that is stored in the specified file.  The grammar is represented as list of rules.  Each rule is represented as a tuple.  The example below will clarify this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(rules):\n",
    "    return [ GrammarRule(var, tuple(body)) for (var, *body) in rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = transform(ruleList)\n",
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a string `name`, which is either a *variable*, a *token*, or a *literal*, the function `is_var` checks whether `name` is a variable.  The function can distinguish variable names from tokens and literals because variable names consist only of lower case letters, while tokens are all uppercase and literals start with the character \"`'`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_var(name):\n",
    "    return name[0] != \"'\" and name[0].islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a list `Rules` of `GrammarRules`, the function `collect_variables(Rules)` returns the set of all *variables* occuring in `Rules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_variables(Rules):\n",
    "    Variables = set()\n",
    "    for rule in Rules:\n",
    "        Variables.add(rule.mVariable)\n",
    "        for item in rule.mBody:\n",
    "            if is_var(item):\n",
    "                Variables.add(item)\n",
    "    return Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set `Rules` of `GrammarRules`, the function `collect_tokens(Rules)` returns the set of all *tokens* and *literals* occuring in `Rules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tokens(Rules):\n",
    "    Tokens = set()\n",
    "    for rule in Rules:\n",
    "        for item in rule.mBody:\n",
    "            if not is_var(item):\n",
    "                Tokens.add(item)\n",
    "    return Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Marked Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `ExtendedMarkedRule` stores a single *marked rule* of the form\n",
    "$$ v \\rightarrow \\alpha \\bullet \\beta : L $$\n",
    "where the *variable* $v$ is stored in the member variable `mVariable`, while $\\alpha$ and $\\beta$ are stored in the variables `mAlpha`and `mBeta` respectively.  The set of follow tokens $L$ is stored in the variable `mFollow`. These variables are assumed to contain tuples of *grammar symbols*.  A *grammar symbol* is either\n",
    "- a *variable*,\n",
    "- a *token*, or\n",
    "- a *literal*, i.e. a string enclosed in single quotes.\n",
    "\n",
    "\n",
    "Later, we need to maintain sets of *marked rules* to represent *states*.  Therefore, we have to define the methods `__eq__`, `__ne__`, and `__hash__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedMarkedRule():\n",
    "    def __init__(self, variable, alpha, beta, follow):\n",
    "        self.mVariable = variable\n",
    "        self.mAlpha    = alpha\n",
    "        self.mBeta     = beta\n",
    "        self.mFollow   = follow\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, ExtendedMarkedRule) and \\\n",
    "               self.mVariable == other.mVariable     and \\\n",
    "               self.mAlpha    == other.mAlpha        and \\\n",
    "               self.mBeta     == other.mBeta         and \\\n",
    "               self.mFollow   == other.mFollow\n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.mVariable) + \\\n",
    "               hash(self.mAlpha)    + \\\n",
    "               hash(self.mBeta)     + \\\n",
    "               hash(self.mFollow)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        alphaStr  = ' '.join(self.mAlpha)\n",
    "        betaStr   = ' '.join(self.mBeta)\n",
    "        if len(self.mFollow) > 1:\n",
    "            followStr = '{' + ','.join(self.mFollow) + '}'\n",
    "        else:\n",
    "            followStr = ','.join(self.mFollow)\n",
    "        return f'{self.mVariable} → {alphaStr} • {betaStr}: {followStr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an *extended marked rule* `self`, the function `is_complete` checks, whether the *extended marked rule* `self` has the form\n",
    "$$ c \\rightarrow \\alpha\\; \\bullet: L,$$\n",
    "i.e. it checks, whether the $\\bullet$ is at the end of the grammar rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_complete(self):\n",
    "    return len(self.mBeta) == 0\n",
    "\n",
    "ExtendedMarkedRule.is_complete = is_complete\n",
    "del is_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an *extended marked rule* `self` of the form\n",
    "$$ c \\rightarrow \\alpha \\bullet X\\, \\delta: L, $$\n",
    "the function `symbol_after_dot` returns the *symbol* $X$. If there is no symbol after the $\\bullet$, the method returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_after_dot(self):\n",
    "    if len(self.mBeta) > 0:\n",
    "        return self.mBeta[0]\n",
    "    return None\n",
    "\n",
    "ExtendedMarkedRule.symbol_after_dot = symbol_after_dot\n",
    "del symbol_after_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an extended marked rule, this function returns the variable following the dot.  If there is no variable following the dot, the function returns `None`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_var(self):\n",
    "    if len(self.mBeta) > 0:\n",
    "        var = self.mBeta[0]\n",
    "        if is_var(var):\n",
    "            return var\n",
    "    return None\n",
    "\n",
    "ExtendedMarkedRule.next_var = next_var\n",
    "del next_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `move_dot(self)` transforms an *extended marked rule*  of the form \n",
    "$$ c \\rightarrow \\alpha \\bullet X\\, \\beta: L $$\n",
    "into an *extended marked rule* of the form\n",
    "$$ c \\rightarrow \\alpha\\, X \\bullet \\beta: L, $$\n",
    "i.e. the $\\bullet$ is moved over the next symbol.  Invocation of this method assumes that there is a symbol\n",
    "following the $\\bullet$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_dot(self):\n",
    "    return ExtendedMarkedRule(self.mVariable, \n",
    "                              self.mAlpha + (self.mBeta[0],), \n",
    "                              self.mBeta[1:],\n",
    "                              self.mFollow)\n",
    "\n",
    "ExtendedMarkedRule.move_dot = move_dot\n",
    "del move_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `to_rule(self)` turns the *extended marked rule* `self` into  a `GrammarRule`, i.e. the *extended marked rule*\n",
    "$$ c \\rightarrow \\alpha \\bullet \\beta: L $$\n",
    "is turned into the grammar rule\n",
    "$$ c \\rightarrow \\alpha\\, \\beta. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rule(self):\n",
    "    return GrammarRule(self.mVariable, self.mAlpha + self.mBeta)\n",
    "\n",
    "ExtendedMarkedRule.to_rule = to_rule\n",
    "del to_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `to_rule(self)` turns the *extended marked rule* `self` into a `MarkedRule`, i.e. the *extended marked rule*\n",
    "$$ c \\rightarrow \\alpha \\bullet \\beta: L $$\n",
    "is turned into the marked rule\n",
    "$$ c \\rightarrow \\alpha\\bullet \\beta. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_marked_rule(self):\n",
    "    return MarkedRule(self.mVariable, self.mAlpha, self.mBeta)\n",
    "\n",
    "ExtendedMarkedRule.to_marked_rule = to_marked_rule\n",
    "del to_marked_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `MarkedRule` is similar to the class `ExtendedMarkedRule` but does not have the *follow set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkedRule():\n",
    "    def __init__(self, variable, alpha, beta):\n",
    "        self.mVariable = variable\n",
    "        self.mAlpha    = alpha\n",
    "        self.mBeta     = beta\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, MarkedRule)     and \\\n",
    "               self.mVariable == other.mVariable and \\\n",
    "               self.mAlpha    == other.mAlpha    and \\\n",
    "               self.mBeta     == other.mBeta     \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.mVariable) + \\\n",
    "               hash(self.mAlpha)    + \\\n",
    "               hash(self.mBeta)     \n",
    "    \n",
    "    def __repr__(self):\n",
    "        alphaStr  = ' '.join(self.mAlpha)\n",
    "        betaStr   = ' '.join(self.mBeta)\n",
    "        return f'{self.mVariable} → {alphaStr} • {betaStr}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of *extended marked rules* `M`, the function `combine_rules` *combines* those extended marked ruless that have the same *core*:  If \n",
    "$$ a \\rightarrow \\beta \\bullet \\gamma : L $$\n",
    "is an extended marked rule, then its *core* is defined as the marked rule\n",
    "$$ a \\rightarrow \\beta \\bullet \\gamma. $$\n",
    "If $a \\rightarrow \\beta \\bullet \\gamma : L_1$ and $a \\rightarrow \\beta \\bullet \\gamma : L_2$ are two extended marked rules, then they can be *combined* into the rule\n",
    "$$ a \\rightarrow \\beta \\bullet \\gamma : L_1\\cup L_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rules(M):\n",
    "    Result = set()\n",
    "    Core   = set()\n",
    "    for emr1 in M:\n",
    "        Follow = set()\n",
    "        core1 = emr1.to_marked_rule()\n",
    "        if core1 in Core:\n",
    "            continue\n",
    "        Core.add(core1)\n",
    "        for emr2 in M:\n",
    "            core2 = emr2.to_marked_rule()\n",
    "            if core1 == core2:\n",
    "                Follow |= emr2.mFollow\n",
    "        new_emr = ExtendedMarkedRule(core1.mVariable, core1.mAlpha, core1.mBeta, frozenset(Follow))\n",
    "        Result.add(new_emr)\n",
    "    return frozenset(Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR-Table-Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Grammar` represents a context free grammar.  It stores a list of the `GrammarRules` of the given grammar.\n",
    "Each grammar rule of the form\n",
    "$$ a \\rightarrow \\beta $$\n",
    "The start symbol is assumed to be the variable on the left hand side of the first rule. The grammar is *augmented* with the rule\n",
    "$$ \\widehat{s} \\rightarrow s. $$\n",
    "Here $s$ is the start variable of the given grammar and $\\widehat{s}$ is a new variable that is the start variable of the *augmented grammar*. The symbol `$` denotes the end of input.  The non-obvious member variables of the class `Grammar` have the following interpretation\n",
    "- `mStates` is the set of all states of the *LR-parser*.  These states are sets of *extended marked rules*.\n",
    "- `mStateNames`is a dictionary assigning names of the form `s0`, `s1`, $\\cdots$, `sn` to the states stored in \n",
    "  `mStates`.  The functions `action` and `goto` will be defined for *state names*, not for *states*, because \n",
    "  otherwise the table representing these functions would become both huge and unreadable.\n",
    "- `mConflicts` is a Boolean variable that will be set to true if the table generation discovers \n",
    "  *shift/reduce conflicts* or *reduce/reduce conflicts*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self, Rules):\n",
    "        self.mRules      = Rules\n",
    "        self.mStart      = Rules[0].mVariable\n",
    "        self.mVariables  = collect_variables(Rules)\n",
    "        self.mTokens     = collect_tokens(Rules)\n",
    "        self.mStates     = set()\n",
    "        self.mStateNames = {}\n",
    "        self.mConflicts  = False\n",
    "        self.mVariables.add('ŝ')\n",
    "        self.mTokens.add('$')\n",
    "        self.mRules.append(GrammarRule('ŝ', (self.mStart, ))) # augmenting\n",
    "        self.compute_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of `Variables`, the function `initialize_dictionary` returns a dictionary that assigns the empty set to all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dictionary(Variables):\n",
    "    return { a: set() for a in Variables }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a `Grammar`, the function `compute_tables` computes\n",
    "- the sets `First(v)` for every variable `v`,\n",
    "- the set of all *states* of the *LR-Parser*,\n",
    "- the *action table*, and\n",
    "- the *goto table*. \n",
    "\n",
    "Given a grammar `g`,\n",
    "- the set `g.mFirst` is a dictionary such that `g.mFirst[a] = First[a]` and\n",
    "- the set `g.mFollow` is a dictionary such that `g.mFollow[a] = Follow[a]` for all variables `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tables(self):\n",
    "    self.mFirst  = initialize_dictionary(self.mVariables)\n",
    "    self.compute_first()\n",
    "    self.compute_rule_names()\n",
    "    self.all_states()\n",
    "    self.compute_action_table()\n",
    "    self.compute_goto_table()\n",
    "    \n",
    "Grammar.compute_tables = compute_tables\n",
    "del compute_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_rule_names` assigns a unique name to each *rule* of the grammar.  These names are used later\n",
    "to represent *reduce actions* in the *action table*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rule_names(self):\n",
    "    self.mRuleNames = {}\n",
    "    counter = 0\n",
    "    for rule in self.mRules:\n",
    "        self.mRuleNames[rule] = 'r' + str(counter)\n",
    "        counter += 1\n",
    "        \n",
    "Grammar.compute_rule_names = compute_rule_names\n",
    "del compute_rule_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_first(self)` computes the sets $\\texttt{First}(c)$ for all variables $c$ and stores them in the dictionary `mFirst`.  Abstractly, given a variable $c$ the function $\\texttt{First}(c)$ is the set of all tokens that can start a string that is derived from $c$:\n",
    "$$\\texttt{First}(\\texttt{c}) := \n",
    "  \\Bigl\\{ t \\in T \\Bigm| \\exists \\gamma \\in (V \\cup T)^*: \\texttt{c} \\Rightarrow^* t\\,\\gamma \\Bigr\\}.\n",
    "$$\n",
    "The definition of the function $\\texttt{First}()$ is extended to strings from $(V \\cup T)^*$ as follows:\n",
    "- $\\texttt{FirstList}(\\varepsilon) = \\{\\}$.\n",
    "- $\\texttt{FirstList}(t \\beta) = \\{ t \\}$  if $t \\in T$.\n",
    "- $\\texttt{FirstList}(\\texttt{a} \\beta) = \\left\\{\n",
    "       \\begin{array}[c]{ll}\n",
    "         \\texttt{First}(\\texttt{a}) \\cup \\texttt{FirstList}(\\beta) & \\mbox{if $\\texttt{a} \\Rightarrow^* \\varepsilon$;} \\\\\n",
    "         \\texttt{First}(\\texttt{a})                                & \\mbox{otherwise.}\n",
    "       \\end{array}\n",
    "       \\right.\n",
    "      $ \n",
    "\n",
    "If $\\texttt{a}$ is a variable of $G$ and the rules defining $\\texttt{a}$ are given as \n",
    "$$\\texttt{a} \\rightarrow \\alpha_1 \\mid \\cdots \\mid \\alpha_n, $$\n",
    "then we have\n",
    "$$\\texttt{First}(\\texttt{a}) = \\bigcup\\limits_{i=1}^n \\texttt{FirstList}(\\alpha_i). $$\n",
    "The dictionary `mFirst` that stores this function is computed via a *fixed point iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first(self):\n",
    "    change = True\n",
    "    while change:\n",
    "        change = False\n",
    "        for rule in self.mRules:\n",
    "            a, body = rule.mVariable, rule.mBody\n",
    "            first_body = self.first_list(body)\n",
    "            if not (first_body <= self.mFirst[a]):\n",
    "                change = True\n",
    "                self.mFirst[a] |= first_body           \n",
    "    print('First sets:')\n",
    "    for v in self.mVariables:\n",
    "        print(f'First({v}) = {self.mFirst[v]}')\n",
    "        \n",
    "Grammar.compute_first = compute_first\n",
    "del compute_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a tuple of variables and tokens `alpha`, the function `first_list(alpha)` computes the function $\\texttt{FirstList}(\\alpha)$ that has been defined above.  If `alpha` is *nullable*, then the result will contain the empty string $\\varepsilon = \\texttt{''}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_list(self, alpha):\n",
    "    if len(alpha) == 0:\n",
    "        return { '' }\n",
    "    elif is_var(alpha[0]): \n",
    "        v, *r = alpha\n",
    "        return eps_union(self.mFirst[v], self.first_list(r))\n",
    "    else:\n",
    "        t = alpha[0]\n",
    "        return { t }\n",
    "    \n",
    "Grammar.first_list = first_list\n",
    "del first_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments `S` and `T` of `eps_union` are sets that contain tokens and, additionally, they might contain the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_union(S, T):\n",
    "    if '' in S: \n",
    "        if '' in T: \n",
    "            return S | T\n",
    "        return (S - { '' }) | T\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an augmented grammar $G = \\langle V,T,R\\cup\\{\\widehat{s} \\rightarrow s\\,\\$\\}, \\widehat{s}\\rangle$ \n",
    "and a variable $a$, the set of tokens that might follow $a$ is defined as:\n",
    "$$\\texttt{Follow}(a) := \n",
    " \\bigl\\{ t \\in \\widehat{T} \\,\\bigm|\\, \\exists \\beta,\\gamma \\in (V \\cup \\widehat{T})^*: \n",
    "                           \\widehat{s} \\Rightarrow^* \\beta \\,a\\, t\\, \\gamma \n",
    "  \\bigr\\}.\n",
    "$$\n",
    "The function `compute_follow` computes the sets $\\texttt{Follow}(a)$ for all variables $a$ via a *fixed-point iteration*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\mathcal{M}$ is a set of *extended marked rules*, then the *closure* of $\\mathcal{M}$ is the smallest set $\\mathcal{K}$ such that\n",
    "we have the following:\n",
    "- $\\mathcal{M} \\subseteq \\mathcal{K}$,\n",
    "- If $a \\rightarrow \\beta \\bullet c\\, \\delta: L$ is a *extended marked rule* from \n",
    "  $\\mathcal{K}$, $c$ is a variable, and $t\\in L$ and if, furthermore,\n",
    "  $c \\rightarrow \\gamma$ is a grammar rule,\n",
    "  then the marked rule $c \\rightarrow \\bullet \\gamma: \\texttt{First}(\\delta\\,t)$\n",
    "  is an element of $\\mathcal{K}$:\n",
    "  $$(a \\rightarrow \\beta \\bullet c\\, \\delta:L) \\in \\mathcal{K} \n",
    "         \\;\\wedge\\; \n",
    "         (c \\rightarrow \\gamma) \\in R \\;\\wedge\\; t \\in L\n",
    "         \\;\\Rightarrow\\; (c \\rightarrow \\bullet \\gamma: \\texttt{First}(\\delta\\,t)) \\in \\mathcal{K}\n",
    "  $$\n",
    "\n",
    "We define $\\texttt{closure}(\\mathcal{M}) := \\mathcal{K}$.  The function `cmp_closure` computes this closure for a given set of *extended marked rules* via a *fixed-point iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_closure(self, Marked_Rules):\n",
    "    All_Rules = Marked_Rules\n",
    "    New_Rules = Marked_Rules\n",
    "    while True:\n",
    "        More_Rules = set()\n",
    "        for rule in New_Rules:\n",
    "            c = rule.next_var()\n",
    "            if c == None:\n",
    "                continue\n",
    "            delta = rule.mBeta[1:]\n",
    "            L = rule.mFollow\n",
    "            for newRule in self.mRules:\n",
    "                head, alpha = newRule.mVariable, newRule.mBody\n",
    "                if c == head:\n",
    "                    newL = frozenset({ x for t in L for x in self.first_list(delta + (t,)) })\n",
    "                    More_Rules |= { ExtendedMarkedRule(head, (), alpha, newL) }\n",
    "        if More_Rules <= All_Rules:\n",
    "            return frozenset(All_Rules)\n",
    "        New_Rules  = More_Rules - All_Rules\n",
    "        All_Rules |= New_Rules\n",
    "\n",
    "Grammar.cmp_closure = cmp_closure\n",
    "del cmp_closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a set of *extended marked rules* $\\mathcal{M}$ and a *grammar symbol* $X$, the function $\\texttt{goto}(\\mathcal{M}, X)$ \n",
    "is defined as follows:\n",
    "$$\\texttt{goto}(\\mathcal{M}, X) := \\texttt{closure}\\Bigl( \\bigl\\{ \n",
    "   a \\rightarrow \\beta\\, X \\bullet \\delta:L \\bigm| (a \\rightarrow \\beta \\bullet X\\, \\delta:L) \\in \\mathcal{M} \n",
    "   \\bigr\\} \\Bigr).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goto(self, Marked_Rules, x):\n",
    "    Result = set()\n",
    "    for mr in Marked_Rules:\n",
    "        if mr.symbol_after_dot() == x:\n",
    "            Result.add(mr.move_dot())\n",
    "    return combine_rules(self.cmp_closure(Result))\n",
    "\n",
    "Grammar.goto = goto\n",
    "del goto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `all_states` computes the set of all states of an *LR-parser*.  The function starts with the state\n",
    "$$ \\texttt{closure}\\bigl(\\{ \\widehat{s} \\rightarrow \\bullet s : {\\$} \\}\\bigr) $$\n",
    "and then tries to compute new states by using the function `goto`.  This computation proceeds via a \n",
    "*fixed-point iteration*.  Once all states have been computed, the function assigns names to these states.\n",
    "This association is stored in the dictionary *mStateNames*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_states(self): \n",
    "    start_state  = self.cmp_closure({ ExtendedMarkedRule('ŝ', (), (self.mStart,), frozenset({'$'})) })\n",
    "    start_state  = combine_rules(start_state)\n",
    "    self.mStates = { start_state }\n",
    "    New_States   = self.mStates\n",
    "    while True:\n",
    "        More_States = set()\n",
    "        for Rule_Set in New_States:\n",
    "            for mr in Rule_Set: \n",
    "                if not mr.is_complete():\n",
    "                    x = mr.symbol_after_dot()\n",
    "                    next_state = self.goto(Rule_Set, x)\n",
    "                    if next_state not in self.mStates and next_state not in More_States:\n",
    "                        More_States.add(next_state)\n",
    "                        print('.', end='')\n",
    "        if len(More_States) == 0:\n",
    "            break\n",
    "        New_States = More_States;\n",
    "        self.mStates |= New_States\n",
    "        print('\\n', len(self.mStates), sep='')\n",
    "    print(\"All LR-states:\")\n",
    "    counter = 1\n",
    "    self.mStateNames[start_state] = 's0'\n",
    "    print(f's0 = {set(start_state)}')\n",
    "    for state in self.mStates - { start_state }:\n",
    "        self.mStateNames[state] = f's{counter}'\n",
    "        print(f's{counter} = {set(state)}')\n",
    "        counter += 1\n",
    "\n",
    "Grammar.all_states = all_states\n",
    "del all_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the *action table* and is defined as follows:\n",
    "- If $\\mathcal{M}$ contains an *extended marked rule* of the form $a \\rightarrow \\beta \\bullet t\\, \\delta:L$\n",
    "  then we have\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\langle \\texttt{shift}, \\texttt{goto}(\\mathcal{M},t) \\rangle.$$\n",
    "- If $\\mathcal{M}$ contains an *extended marked rule* of the form $a \\rightarrow \\beta\\, \\bullet:L$ and we have\n",
    "  $t \\in L$, then we define\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\langle \\texttt{reduce}, a \\rightarrow \\beta \\rangle$$\n",
    "- If $\\mathcal{M}$ contains the *extended marked rule* $\\widehat{s} \\rightarrow s \\bullet:\\{\\$\\}$, then we define \n",
    "  $$\\texttt{action}(\\mathcal{M},\\$) := \\texttt{accept}. $$\n",
    "- Otherwise, we have\n",
    "  $$\\texttt{action}(\\mathcal{M},t) := \\texttt{error}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_action_table(self):\n",
    "    self.mActionTable = {}\n",
    "    print('\\nAction Table:')\n",
    "    for state in self.mStates:\n",
    "        stateName = self.mStateNames[state]\n",
    "        actionTable = {}\n",
    "        # compute shift actions\n",
    "        for token in self.mTokens:   \n",
    "            newState  = self.goto(state, token)\n",
    "            if newState != set():\n",
    "                newName = self.mStateNames[newState]\n",
    "                actionTable[token] = ('shift', newName)\n",
    "                self.mActionTable[stateName, token] = ('shift', newName)\n",
    "                print(f'action(\"{stateName}\", {token}) = (\"shift\", {newName})')\n",
    "        # compute reduce actions\n",
    "        for mr in state:\n",
    "            if mr.is_complete():\n",
    "                for token in mr.mFollow:\n",
    "                    action1 = actionTable.get(token)\n",
    "                    action2 = ('reduce', mr.to_rule())\n",
    "                    if action1 == None:\n",
    "                        actionTable[token] = action2  \n",
    "                        r = self.mRuleNames[mr.to_rule()]\n",
    "                        self.mActionTable[stateName, token] = ('reduce', r)\n",
    "                        print(f'action(\"{stateName}\", {token}) = {action2}')\n",
    "                    elif action1 != action2: \n",
    "                        self.mConflicts = True\n",
    "                        print('')\n",
    "                        print(f'conflict in state {stateName}:')\n",
    "                        print(f'{stateName} = {state}')\n",
    "                        print(f'action(\"{stateName}\", {token}) = {action1}')     \n",
    "                        print(f'action(\"{stateName}\", {token}) = {action2}')\n",
    "                        print('')\n",
    "        for mr in state:\n",
    "            if mr == ExtendedMarkedRule('ŝ', (self.mStart,), (), frozenset({'$'})):\n",
    "                actionTable['$'] = 'accept'\n",
    "                self.mActionTable[stateName, '$'] = 'accept'\n",
    "                print(f'action(\"{stateName}\", $) = accept')\n",
    "\n",
    "Grammar.compute_action_table = compute_action_table\n",
    "del compute_action_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `compute_goto_table` computes the *goto table*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_goto_table(self):\n",
    "    self.mGotoTable = {}\n",
    "    print('\\nGoto Table:')\n",
    "    for state in self.mStates:\n",
    "        for var in self.mVariables:\n",
    "            newState = self.goto(state, var)\n",
    "            if newState != set():\n",
    "                stateName = self.mStateNames[state]\n",
    "                newName   = self.mStateNames[newState]\n",
    "                self.mGotoTable[stateName, var] = newName\n",
    "                print(f'goto({stateName}, {var}) = {newName}')\n",
    "\n",
    "Grammar.compute_goto_table = compute_goto_table\n",
    "del compute_goto_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_quotes(t):\n",
    "    if t[0] == \"'\" and t[-1] == \"'\":\n",
    "        return t[1:-1]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_parse_table(self, file):\n",
    "    with open(file, 'w', encoding=\"utf-8\") as handle:\n",
    "        handle.write('# Grammar rules:\\n')\n",
    "        for rule in self.mRules:\n",
    "            rule_name = self.mRuleNames[rule] \n",
    "            handle.write(f'{rule_name} =(\"{rule.mVariable}\", {rule.mBody})\\n')\n",
    "        handle.write('\\n# Action table:\\n')\n",
    "        handle.write('actionTable = {}\\n')\n",
    "        for s, t in self.mActionTable:\n",
    "            action = self.mActionTable[s, t]\n",
    "            t = strip_quotes(t)\n",
    "            if action[0] == 'reduce':\n",
    "                rule_name = action[1]\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = ('reduce', {rule_name})\\n\")\n",
    "            elif action == 'accept':\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = 'accept'\\n\")\n",
    "            else:\n",
    "                handle.write(f\"actionTable['{s}', '{t}'] = {action}\\n\")\n",
    "        handle.write('\\n# Goto table:\\n')\n",
    "        handle.write('gotoTable = {}\\n')\n",
    "        for s, v in self.mGotoTable:\n",
    "            state = self.mGotoTable[s, v]\n",
    "            handle.write(f\"gotoTable['{s}', '{v}'] = '{state}'\\n\")\n",
    "        handle.write('\\n# States:\\n')\n",
    "        handle.write('stateNames = {}\\n')\n",
    "        for s in self.mStateNames:\n",
    "            name = self.mStateNames[s]\n",
    "            handle.write(f\"stateNames['{name}'] = {s}\\n\")           \n",
    "\n",
    "Grammar.dump_parse_table = dump_parse_table\n",
    "del dump_parse_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(file):\n",
    "    rules        = parse(file)\n",
    "    grammarRules = transform(rules) \n",
    "    grammar      = Grammar(grammarRules)\n",
    "    grammar.dump_parse_table('parse-table.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyse('Examples/arith.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse('Examples/postfix.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse('Examples/arith-small.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "analyse('Examples/c-grammar.g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
