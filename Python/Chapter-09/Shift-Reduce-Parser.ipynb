{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open('../style.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Shift-Reduce Parser for Arithmetic Expressions\n",
    "\n",
    "In this notebook we implement a generic *shift reduce parser*.  The parse table that we use \n",
    "implements the following grammar for arithmetic expressions:\n",
    "$$\n",
    "  \\begin{eqnarray*}\n",
    "  \\mathrm{expr}        & \\rightarrow & \\mathrm{expr}\\;\\;\\texttt{'+'}\\;\\;\\mathrm{product}   \\\\\n",
    "                       & \\mid        & \\mathrm{expr}\\;\\;\\texttt{'-'}\\;\\;\\mathrm{product}   \\\\\n",
    "                       & \\mid        & \\mathrm{product}                                    \\\\[0.2cm]\n",
    "  \\mathrm{product}     & \\rightarrow & \\mathrm{product}\\;\\;\\texttt{'*'}\\;\\;\\mathrm{factor} \\\\\n",
    "                       & \\mid        & \\mathrm{product}\\;\\;\\texttt{'/'}\\;\\;\\mathrm{factor} \\\\\n",
    "                       & \\mid        & \\mathrm{factor}                                     \\\\[0.2cm]\n",
    "  \\mathrm{factor}      & \\rightarrow & \\texttt{'('} \\;\\;\\mathrm{expr} \\;\\;\\texttt{')'}     \\\\\n",
    "                       & \\mid        & \\texttt{NUMBER} \n",
    "  \\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` transforms the string `s` into a list of tokens. See below for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    '''Transform the string s into a list of (type, value) tuples.'''\n",
    "    lexSpec = r'''([ \\t\\n]+)      |  # blanks and tabs\n",
    "                  ([1-9][0-9]*|0) |  # number\n",
    "                  ([-+*/()])      |  # arithmetical operators\n",
    "                  (.)                # unrecognized character\n",
    "               '''\n",
    "    tokenList = re.findall(lexSpec, s, re.VERBOSE)\n",
    "    result    = []\n",
    "    for ws, number, operator, error in tokenList:\n",
    "        if ws:        \n",
    "            continue\n",
    "        elif number:\n",
    "            # Store the generic type 'NUMBER' and the actual value string\n",
    "            result.append(('NUMBER', number))\n",
    "        elif operator:\n",
    "            # For operators, type and value are identical\n",
    "            result.append((operator, operator))\n",
    "        else:\n",
    "            result.append(('ERROR', error))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize('1 + 2 * (3 - 4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftReduceParser():\n",
    "    def __init__(self, actionTable, gotoTable, stateTable):\n",
    "        self.mActionTable = actionTable\n",
    "        self.mGotoTable   = gotoTable\n",
    "        self.mStateTable  = stateTable\n",
    "        \n",
    "    def parse(self, TL: list[str]) -> bool:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, TL): \n",
    "    index   = 0                 # points to next token\n",
    "    Symbols: list[str] = []     # stack of grammar symbols (stores types, e.g., 'NUMBER')\n",
    "    States : list[str] = ['s0'] # stack of states\n",
    "    # The Forest stack stores the tree nodes/values\n",
    "    Forest : list[str | tuple] = [] \n",
    "    TL += [('EOF', 'EOF')]\n",
    "    while True:\n",
    "        q = States[-1]\n",
    "        # Unpack the current lookahead token into type and value\n",
    "        token_type, token_value = TL[index]\n",
    "        # Debug output (optional formatting)\n",
    "        # We map the remaining tokens to their string representation for cleaner printing\n",
    "        remaining_tokens = [val for _, val in TL[index:]]\n",
    "        print(f'States:  [ {\", \".join(States)} ]')\n",
    "        print('Symbols:', \" \".join(Symbols + ['|'] + remaining_tokens).strip())\n",
    "        # Use token_type for the table lookup\n",
    "        action = self.mActionTable.get((q, token_type), 'error')\n",
    "        match action:\n",
    "            case 'error': \n",
    "                print(f'Action({q}, {token_type}) undefined.')\n",
    "                print('Syntax error!\\n')\n",
    "                return False\n",
    "            case 'accept':\n",
    "                print('Accepting!\\n')\n",
    "                return Forest[0] \n",
    "            case 'shift', s:\n",
    "                print(f'Shifting state {s}\\n')\n",
    "                Symbols += [token_type] # Stack tracks the grammar type\n",
    "                States  += [s]\n",
    "                # Forest tracks the actual value ('1', '+', etc.)\n",
    "                Forest += [token_value]\n",
    "                index   += 1\n",
    "            case 'reduce', rule:\n",
    "                head, body = rule\n",
    "                print(f'Reducing with rule {head} â†’ {\" \".join(body)}')\n",
    "                n        = len(body)\n",
    "                children = tuple(Forest[-n:]) if n > 0 else ()\n",
    "                Forest   = Forest[:-n]\n",
    "                Forest  += [(head, children)]\n",
    "                Symbols = Symbols[:-n]\n",
    "                States  = States [:-n] \n",
    "                Symbols = Symbols + [head]\n",
    "                state   = States[-1]\n",
    "                States += [ self.mGotoTable[state, head] ]\n",
    "            \n",
    "ShiftReduceParser.parse = parse \n",
    "del parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Parse-Table.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the given parse tree using `graphviz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tree(tree: tuple | str) -> graphviz.Digraph:\n",
    "    dot = graphviz.Digraph(format='png')\n",
    "    # Counter to generate unique IDs for each node in the graph\n",
    "    counter = 0\n",
    "\n",
    "    def get_id():\n",
    "        nonlocal counter\n",
    "        counter += 1\n",
    "        return f'node{counter}'\n",
    "\n",
    "    def visit(node, parent_id=None):\n",
    "        # Create a unique ID for the current node\n",
    "        node_id = get_id() \n",
    "        if isinstance(node, tuple):\n",
    "            # It's a Non-Terminal: (Head, (Children...))\n",
    "            head, children = node\n",
    "            # Draw the Non-Terminal node (default shape is oval)\n",
    "            dot.node(node_id, label=head)\n",
    "            # Connect to parent if it exists\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, node_id)\n",
    "            # Recursively visit all children\n",
    "            for child in children:\n",
    "                visit(child, node_id)\n",
    "        else:\n",
    "            # It's a Terminal: string value (e.g., '1', '+')\n",
    "            label = str(node)\n",
    "            # Draw the Terminal node with a distinct shape/font\n",
    "            dot.node(node_id, label=label, shape='box', fontname='Courier')\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, node_id)\n",
    "                \n",
    "    # Start the traversal from the root\n",
    "    visit(tree)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(s: str):\n",
    "    parser = ShiftReduceParser(actionTable, gotoTable, stateTable)\n",
    "    TL     = tokenize(s)\n",
    "    print(f'tokenlist: {TL}\\n')\n",
    "    tree = parser.parse(TL)\n",
    "    if tree:\n",
    "        print('Parse successful!')\n",
    "        return draw_tree(tree)\n",
    "    else:\n",
    "        print('Parse failed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = test('1 + 2 * 3')\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test('1 + 2 * (3 - 4)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('1 + * 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
