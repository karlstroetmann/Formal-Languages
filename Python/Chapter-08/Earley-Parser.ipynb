{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "HTML(open('../style.css').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an Earley Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import ply.lex as lex\n",
    "import ply.yacc as yacc\n",
    "import re\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['VARIABLE', 'TERMINAL', 'LITERAL']\n",
    "\n",
    "t_VARIABLE = r'[a-z][a-z0-9_]*'\n",
    "t_TERMINAL = r'[A-Z][A-Z0-9_]*'\n",
    "t_ignore = ' \\t\\r'\n",
    "\n",
    "def t_LITERAL(t):\n",
    "    r\"'.'\"\n",
    "    t.value = t.value[1] # Strip quotes\n",
    "    return t\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n'\n",
    "    t.lexer.lineno += 1\n",
    "\n",
    "def t_error(t):\n",
    "    # Keeping original error printing style\n",
    "    print(f\"Illegal character '{t.value[0]}' in line {t.lineno}.\")\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "literals = [':', ';']\n",
    "meta_lexer = lex.lex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_grammar_one(p):\n",
    "    \"grammar : rule\"\n",
    "    p[0] = [p[1]]\n",
    "\n",
    "def p_grammar_more(p):\n",
    "    \"grammar : rule grammar\"\n",
    "    p[0] = [p[1]] + p[2]\n",
    "\n",
    "def p_rule(p):\n",
    "    \"rule : VARIABLE ':' item_list ';'\"\n",
    "    p[0] = [p[1]] + p[3]\n",
    "\n",
    "def p_item_list_zero(p):\n",
    "    \"item_list : \"\n",
    "    p[0] = []\n",
    "\n",
    "def p_item_list_more(p):\n",
    "    \"item_list : item item_list\"\n",
    "    p[0] = [p[1]] + p[2]\n",
    "\n",
    "def p_item_variable(p):\n",
    "    \"item : VARIABLE\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_terminal(p):\n",
    "    \"item : TERMINAL\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_item_literal(p):\n",
    "    \"item : LITERAL\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_error(t):\n",
    "    if t:\n",
    "        print(f'Syntax error at token \"{t.value}\" in line {t.lineno}.')\n",
    "    else:\n",
    "        print('Syntax error at end of input.')\n",
    "\n",
    "# Build the meta-parser\n",
    "meta_parser = yacc.yacc(write_tables=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s: str) -> list[tuple[str, str]]:\n",
    "    '''Transform the string s into a list of (type, value) pairs.'''\n",
    "    lexSpec = r'''([ \\t]+)        |  # blanks and tabs\n",
    "                  ([1-9][0-9]*|0) |  # number\n",
    "                  ([()])          |  # parentheses \n",
    "                  ([-+*/])        |  # arithmetical operators\n",
    "                  (.)                # unrecognized character\n",
    "               '''\n",
    "    tokenList = re.findall(lexSpec, s, re.VERBOSE)\n",
    "    result    = []\n",
    "    for ws, number, parenthesis, operator, error in tokenList:\n",
    "        if ws:        \n",
    "            continue\n",
    "        elif number:\n",
    "            result += [ ('NUMBER', number) ]\n",
    "        elif parenthesis:\n",
    "            # For literals like '(', the type is '(' and value is '('\n",
    "            result += [ (parenthesis, parenthesis) ]\n",
    "        elif operator:\n",
    "            # For literals like '+', the type is '+' and value is '+'\n",
    "            result += [ (operator, operator) ]\n",
    "        else:\n",
    "            result += [ (f'ERROR({error})', error) ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyItem():\n",
    "    def __init__(self, variable: str, alpha: tuple[str, ...], beta: tuple[str, ...], index: int) -> None:\n",
    "        self.mVariable = variable\n",
    "        self.mAlpha    = alpha\n",
    "        self.mBeta     = beta\n",
    "        self.mIndex    = index\n",
    "        # New: Store backpointers. Set of (predecessor_item, child_node)\n",
    "        self.mBackpointers: set[tuple[EarleyItem, EarleyItem | tuple]] = set()\n",
    "    \n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        # Crucial: Equality MUST ignore mBackpointers to allow state merging\n",
    "        return isinstance(other, EarleyItem)     and \\\n",
    "               self.mVariable == other.mVariable and \\\n",
    "               self.mAlpha    == other.mAlpha    and \\\n",
    "               self.mBeta     == other.mBeta     and \\\n",
    "               self.mIndex    == other.mIndex\n",
    "    \n",
    "    def __ne__(self, other: object):\n",
    "        return not self.__eq__(other)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        # Hash only the core properties\n",
    "        alphaStr = ' '.join(self.mAlpha)\n",
    "        betaStr  = ' '.join(self.mBeta)\n",
    "        return hash((self.mVariable, alphaStr, betaStr, self.mIndex))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        alphaStr = ' '.join(self.mAlpha)\n",
    "        betaStr  = ' '.join(self.mBeta)\n",
    "        return f'<{self.mVariable} → {alphaStr} • {betaStr}, {self.mIndex}>'\n",
    "\n",
    "    def isComplete(self) -> bool:\n",
    "        return len(self.mBeta) == 0\n",
    "\n",
    "    def sameVar(self, c: str) -> bool:\n",
    "        return len(self.mBeta) > 0 and self.mBeta[0] == c\n",
    "\n",
    "    def scan(self, T: str) -> bool:\n",
    "        # Updated: Check if the next symbol in rule matches the token TYPE (T)\n",
    "        if len(self.mBeta) > 0:\n",
    "            return self.mBeta[0] == T\n",
    "        return False\n",
    "\n",
    "    def nextVar(self) -> str | None:\n",
    "        if len(self.mBeta) > 0:\n",
    "            var = self.mBeta[0]\n",
    "            # Variables are lowercase and not quoted literals\n",
    "            if len(var) > 0 and var[0] != \"'\" and var.islower():\n",
    "                return var\n",
    "        return None\n",
    "\n",
    "    def moveDot(self):\n",
    "        return EarleyItem(self.mVariable, \n",
    "                          self.mAlpha + (self.mBeta[0],), \n",
    "                          self.mBeta[1:], \n",
    "                          self.mIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self, Rules: list[list[str]]):\n",
    "        self.mRules = Rules   \n",
    "\n",
    "    def startItem(self) -> EarleyItem:\n",
    "        return EarleyItem('Start', (), (self.startVar(),), 0)\n",
    "\n",
    "    def finishItem(self) -> EarleyItem:\n",
    "        return EarleyItem('Start', (self.startVar(),), (), 0)\n",
    "\n",
    "    def startVar(self) -> str:\n",
    "        return self.mRules[0][0]\n",
    "\n",
    "    def toString(self) -> str:\n",
    "        result = ''\n",
    "        for head, *body in self.mRules:\n",
    "            result += f'{head}: {body};\\n'\n",
    "        return result\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarleyParser():\n",
    "    def __init__(self, grammar, TokenList):\n",
    "        self.mGrammar   = grammar \n",
    "        # mString now stores (Type, Value) tuples\n",
    "        self.mString    = [None] + TokenList \n",
    "        # Use Dict[EarleyItem, EarleyItem] to retrieve existing items and update them\n",
    "        self.mStateList = [{} for i in range(len(TokenList)+1)] \n",
    "        \n",
    "        print('Grammar:\\n')\n",
    "        print(self.mGrammar)\n",
    "        print(f'Input: {self.mString}\\n')\n",
    "        \n",
    "        start = self.mGrammar.startItem()\n",
    "        self.mStateList[0][start] = start\n",
    "\n",
    "    def parse(self):\n",
    "        \"run Earley's algorithm\"\n",
    "        print(\"starting...\")\n",
    "        n = len(self.mString) - 1 \n",
    "        for i in range(0, n+1):\n",
    "            if i + 1 <= n:\n",
    "                next_token = self.mString[i+1]\n",
    "            else:\n",
    "                next_token = 'EOF'\n",
    "            print('_' * 80)\n",
    "            print(f'next token = {next_token}')\n",
    "            print('_' * 80)\n",
    "            change = True\n",
    "            while change:\n",
    "                change = self.complete(i)\n",
    "                change = self.predict(i) or change\n",
    "            self.scan(i)\n",
    "            \n",
    "            # print state\n",
    "            print(f'\\nQ{i}:')\n",
    "            Qi = self.mStateList[i]\n",
    "            for item in Qi.values(): \n",
    "                print(item)\n",
    "            if i + 1 <= n:\n",
    "                print(f'\\nQ{i+1}:')\n",
    "                Qip1 = self.mStateList[i+1]\n",
    "                for item in Qip1.values(): \n",
    "                    print(item)\n",
    "        \n",
    "        finish = self.mGrammar.finishItem()\n",
    "        final_state = self.mStateList[-1]\n",
    "        if finish in final_state:\n",
    "            print('Parsing successful!')\n",
    "            # Return the actual item from the set so we have its backpointers\n",
    "            return final_state[finish]\n",
    "        else:\n",
    "            print('Parsing failed!')\n",
    "            return None\n",
    "\n",
    "    def complete(self, i: int) -> bool:\n",
    "        change = False\n",
    "        added  = True\n",
    "        Qi     = self.mStateList[i]\n",
    "        \n",
    "        # We need to loop until no more items (or backpointers) are added\n",
    "        while added:\n",
    "            added = False\n",
    "            # We collect additions in a separate dict to safely iterate\n",
    "            new_additions = {}\n",
    "            \n",
    "            for item in list(Qi.values()):\n",
    "                if item.isComplete():\n",
    "                    C  = item.mVariable\n",
    "                    j  = item.mIndex\n",
    "                    Qj = self.mStateList[j]\n",
    "                    \n",
    "                    for prevItem in Qj.values():\n",
    "                        if prevItem.sameVar(C):\n",
    "                            moved = prevItem.moveDot()\n",
    "                            source = (prevItem, item) # Backpointer: (Prev, Child)\n",
    "                            \n",
    "                            # Check where to add this\n",
    "                            target_item = None\n",
    "                            \n",
    "                            # Is it already in Qi?\n",
    "                            if moved in Qi:\n",
    "                                target_item = Qi[moved]\n",
    "                            # Is it in our current new batch?\n",
    "                            elif moved in new_additions:\n",
    "                                target_item = new_additions[moved]\n",
    "                            else:\n",
    "                                # It's completely new\n",
    "                                target_item = moved\n",
    "                                new_additions[moved] = moved\n",
    "                            \n",
    "                            # Add the backpointer\n",
    "                            if source not in target_item.mBackpointers:\n",
    "                                target_item.mBackpointers.add(source)\n",
    "                                # If the item was already in Qi, adding a backpointer \n",
    "                                # technically changes the 'derivation' but not the state set size.\n",
    "                                # However, Earley loop condition usually tracks set size.\n",
    "                                # We flag 'added' if the ITEM itself is new.\n",
    "                                if moved not in Qi:\n",
    "                                    added = True\n",
    "            \n",
    "            # If we found completely new items, add them to Qi and print\n",
    "            if new_additions:\n",
    "                change = True\n",
    "                print(\"completion:\")\n",
    "                for it in new_additions.values():\n",
    "                    if it not in Qi:\n",
    "                        print(f'{it} added to Q{i}')\n",
    "                        Qi[it] = it\n",
    "                    else:\n",
    "                        # Logic to merge if it was in Qi but we added backpointers is handled above\n",
    "                        pass\n",
    "                        \n",
    "        return change\n",
    "\n",
    "    def predict(self, i: int) -> bool:\n",
    "        change = False\n",
    "        added  = True\n",
    "        Qi     = self.mStateList[i]\n",
    "        \n",
    "        while added:\n",
    "            added = False\n",
    "            new_items = {}\n",
    "            \n",
    "            for item in list(Qi.values()):\n",
    "                c = item.nextVar()\n",
    "                if c is not None:\n",
    "                    for rule in self.mGrammar.mRules:\n",
    "                        if c == rule[0]:\n",
    "                            newItem = EarleyItem(c, (), tuple(rule[1:]), i)\n",
    "                            if newItem not in Qi and newItem not in new_items:\n",
    "                                new_items[newItem] = newItem\n",
    "                                added = True\n",
    "            \n",
    "            if new_items:\n",
    "                change = True\n",
    "                print(\"prediction:\")\n",
    "                for it in new_items.values():\n",
    "                    print(f'{it} added to Q{i}')\n",
    "                    Qi[it] = it\n",
    "                    \n",
    "        return change\n",
    "\n",
    "    def scan(self, i: int) -> None:\n",
    "        Qi = self.mStateList[i]\n",
    "        n  = len(self.mString) - 1 \n",
    "        \n",
    "        if i + 1 <= n:\n",
    "            token_tuple = self.mString[i+1] # (Type, Value)\n",
    "            token_type  = token_tuple[0]\n",
    "            \n",
    "            for item in list(Qi.values()):\n",
    "                if item.scan(token_type):\n",
    "                    moved = item.moveDot()\n",
    "                    source = (item, token_tuple) # Backpointer: (Prev, (Type, Value))\n",
    "                    \n",
    "                    target_state = self.mStateList[i+1]\n",
    "                    \n",
    "                    if moved in target_state:\n",
    "                        target_state[moved].mBackpointers.add(source)\n",
    "                    else:\n",
    "                        moved.mBackpointers.add(source)\n",
    "                        target_state[moved] = moved\n",
    "                        print('scanning:')\n",
    "                        print(f'{moved} added to Q{i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trees(item: EarleyItem) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of parse trees. Each tree is:\n",
    "    - A tuple (Variable, [children]) for Non-Terminals.\n",
    "    - A string (Value) for Terminals.\n",
    "    \"\"\"\n",
    "    # Base Case: Start -> . Alpha\n",
    "    if not item.mBackpointers:\n",
    "        return [[]] \n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for predecessor, child_node in item.mBackpointers:\n",
    "        predecessor_trees = build_trees(predecessor)\n",
    "        \n",
    "        child_trees = []\n",
    "        \n",
    "        if isinstance(child_node, tuple) and not isinstance(child_node, EarleyItem):\n",
    "            # It is a Terminal Token (Type, Value). We want the Value in the tree.\n",
    "            # child_node is like ('NUMBER', '1') or ('+', '+')\n",
    "            token_value = child_node[1]\n",
    "            child_trees = [token_value]\n",
    "            \n",
    "        elif isinstance(child_node, EarleyItem):\n",
    "            # It is a Non-Terminal\n",
    "            sub_forest = build_trees(child_node)\n",
    "            child_trees = [(child_node.mVariable, kids) for kids in sub_forest]\n",
    "            \n",
    "        # Cartesian product to combine history with current child\n",
    "        for prev in predecessor_trees:\n",
    "            for curr in child_trees:\n",
    "                results.append(prev + [curr])\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trees(item: EarleyItem) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of parse trees. Each tree is:\n",
    "    - A tuple (Variable, [children]) for Non-Terminals.\n",
    "    - A string (Value) for Terminals.\n",
    "    \"\"\"\n",
    "    # Base Case: Start -> . Alpha\n",
    "    if not item.mBackpointers:\n",
    "        return [[]] \n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for predecessor, child_node in item.mBackpointers:\n",
    "        predecessor_trees = build_trees(predecessor)\n",
    "        \n",
    "        child_trees = []\n",
    "        \n",
    "        if isinstance(child_node, tuple) and not isinstance(child_node, EarleyItem):\n",
    "            # It is a Terminal Token (Type, Value). We want the Value in the tree.\n",
    "            # child_node is like ('NUMBER', '1') or ('+', '+')\n",
    "            token_value = child_node[1]\n",
    "            child_trees = [token_value]\n",
    "            \n",
    "        elif isinstance(child_node, EarleyItem):\n",
    "            # It is a Non-Terminal\n",
    "            sub_forest = build_trees(child_node)\n",
    "            child_trees = [(child_node.mVariable, kids) for kids in sub_forest]\n",
    "            \n",
    "        # Cartesian product to combine history with current child\n",
    "        for prev in predecessor_trees:\n",
    "            for curr in child_trees:\n",
    "                results.append(prev + [curr])\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tree(tree: tuple | str) -> graphviz.Digraph:\n",
    "    dot = graphviz.Digraph(format='png')\n",
    "    # Counter to generate unique IDs for each node in the graph\n",
    "    counter = 0\n",
    "\n",
    "    def get_id():\n",
    "        nonlocal counter\n",
    "        counter += 1\n",
    "        return f'node{counter}'\n",
    "\n",
    "    def visit(node, parent_id=None):\n",
    "        # Create a unique ID for the current node\n",
    "        node_id = get_id() \n",
    "        if isinstance(node, tuple):\n",
    "            # It's a Non-Terminal: (Head, (Children...))\n",
    "            head, children = node\n",
    "            # Draw the Non-Terminal node (default shape is oval)\n",
    "            dot.node(node_id, label=head)\n",
    "            # Connect to parent if it exists\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, node_id)\n",
    "            # Recursively visit all children\n",
    "            for child in children:\n",
    "                visit(child, node_id)\n",
    "        else:\n",
    "            # It's a Terminal: string value (e.g., '1', '+')\n",
    "            label = str(node)\n",
    "            # Draw the Terminal node with a distinct shape/font\n",
    "            dot.node(node_id, label=label, shape='box', fontname='Courier')\n",
    "            if parent_id:\n",
    "                dot.edge(parent_id, node_id)\n",
    "                \n",
    "    # Start the traversal from the root\n",
    "    visit(tree)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser(file: str, word: str) -> None: \n",
    "    # 1. Parse Grammar\n",
    "    meta_lexer.lineno = 1\n",
    "    with open(file, 'r') as handle:\n",
    "        grammarStr = handle.read() \n",
    "    \n",
    "    print(\"--- Loading Grammar ---\")\n",
    "    # print(grammarStr) # Optional\n",
    "    Rules = meta_parser.parse(grammarStr) \n",
    "    grammar = Grammar(Rules)\n",
    "    \n",
    "    # 2. Tokenize\n",
    "    TokenList = tokenize(word)\n",
    "    \n",
    "    # 3. Run Earley\n",
    "    ep = EarleyParser(grammar, TokenList)\n",
    "    final_item = ep.parse()\n",
    "    \n",
    "    # 4. Show Trees\n",
    "    if final_item:\n",
    "        # build_trees returns a list of trees for the 'Start' item.\n",
    "        # 'Start' -> 'expr' . \n",
    "        # The forest will look like: [ [('expr', [...])] ]\n",
    "        # We want the inner ('expr', ...) tuple.\n",
    "        \n",
    "        forest = build_trees(final_item)\n",
    "        \n",
    "        print(f\"\\n--- Visualization ({len(forest)} trees found) ---\")\n",
    "        for i, tree_list in enumerate(forest):\n",
    "            if tree_list:\n",
    "                # Extract the actual tree from the list wrapper\n",
    "                actual_tree = tree_list[0]\n",
    "                print(f\"Tree {i+1}: {actual_tree}\")\n",
    "                display(draw_tree(actual_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_parser('simple.g', '1 + 2 * 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat simple.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ambiguous.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_parser('ambiguous.g', '1 + 2 * 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
