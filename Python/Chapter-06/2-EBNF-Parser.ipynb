{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open('../style.css').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An EBNF based Parser for Arithmetic Expressions\n",
    "\n",
    "In this notebook we implement an <span style=\"font-variant:small-caps;\">Ebnf</span> recursive-descend parser for arithmetic expressions.  This parser implements the following <span style=\"font-variant:small-caps;\">Ebnf</span> grammar:\n",
    "$$\n",
    "  \\begin{eqnarray*}\n",
    "  \\mathrm{expr}    & \\rightarrow & \\mathrm{product}\\;\\;\\bigl((\\texttt{'+'}\\;|\\;\\texttt{'-'})\\;\\; \\mathrm{product}\\bigr)^* \\\\[0.2cm]\n",
    "  \\mathrm{product} & \\rightarrow & \\mathrm{factor} \\;\\;\\bigl((\\texttt{'*'}\\;|\\;\\texttt{'/'})\\;\\; \\mathrm{factor}\\bigr)^*  \\\\[0.2cm]   \n",
    "  \\mathrm{factor}  & \\rightarrow & \\texttt{'('} \\;\\;\\mathrm{expr} \\;\\;\\texttt{')'}                             \\\\\n",
    "                   & \\mid        & \\texttt{NUMBER} \n",
    "  \\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` receives a string `s` as argument and returns a list of tokens.\n",
    "The string `s` is supposed to represent an arithmetical expression. \n",
    "\n",
    "**Note:** \n",
    " - We need to set the flag `re.VERBOSE` in our call of the function `findall`\n",
    "   below because otherwise we are not able to format the regular expression `lexSpec` the way \n",
    "   we have done it.  Furthermore, we wouldn't have been able to add comments inside the regular expression.\n",
    " - Since the regular expression does not allow white space, `tokenList` will contain lots of \n",
    "   empty strings.  These have to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s: str) -> list[str]:\n",
    "    lexSpec = r'''[1-9][0-9]*|0 |  # numbers\n",
    "                  [-+*/()]      |  # arithmetical operators and parentheses\n",
    "               '''\n",
    "    tokenList = re.findall(lexSpec, s, re.VERBOSE)\n",
    "    return [t for t in tokenList if t != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenize('12 * 13 + 14 * 4 / 6 - 7'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Recursive Descend Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the functions `parseExpr`, `parseProduct`, and `parseFactor` are mutually recursive,\n",
    "we need to declare their types in a forward declaration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseExpr(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    return None # type: ignore\n",
    "\n",
    "def parseProduct(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    return None # type: ignore\n",
    "\n",
    "def parseFactor(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    return None # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parse` takes a string `s` as input and parses this string according to the recursive grammar\n",
    "shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(s: str) -> float:\n",
    "    TL           = tokenize(s)\n",
    "    result, Rest = parseExpr(TL)\n",
    "    assert Rest == [], f'Parse Error: could not parse {TL}, Rest = {Rest}'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parseExpr(TL)` takes a list of tokens `TL` and tries to parse an expresssion according to the following\n",
    "<span style=\"font-variant:small-caps;\">Ebnf</span> grammar rule:\n",
    "$$ \\mathrm{expr} \\;\\rightarrow\\; \\mathrm{product}\\;\\;\\bigl((\\texttt{'+'}\\;|\\;\\texttt{'-'})\\;\\; \\mathrm{product}\\bigr)^* $$\n",
    "It returns the value of the expression and a list of all the tokens that have not been consumed during parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseExpr(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    result, Rest = parseProduct(TL)\n",
    "    while len(Rest) >= 2 and Rest[0] in {'+', '-'}: \n",
    "        operator = Rest[0]\n",
    "        arg, Rest = parseProduct(Rest[1:])\n",
    "        if operator == '+': \n",
    "            result += arg\n",
    "        else:             # operator == '-': \n",
    "            result -= arg\n",
    "    return result, Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parseProduct(TL)` takes a list of tokens `TL` and tries to parse a product according to the following\n",
    "<span style=\"font-variant:small-caps;\">Ebnf</span> grammar rule:\n",
    "$$ \\mathrm{product} \\;\\rightarrow\\; \\mathrm{factor} \\;\\;\\bigl((\\texttt{'*'}\\;|\\;\\texttt{'/'})\\;\\; \\mathrm{factor}\\bigr)^*  $$\n",
    "It returns the value of the product and a list of all the tokens that have not been consumed during parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseProduct(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    result, Rest = parseFactor(TL)\n",
    "    while len(Rest) >= 2 and Rest[0] in {'*', '/'}:\n",
    "        operator = Rest[0]\n",
    "        arg, Rest = parseFactor(Rest[1:])\n",
    "        if operator == '*':\n",
    "            result *= arg\n",
    "        else:             # operator == '/':\n",
    "            result /= arg\n",
    "    return result, Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parseFactor` implements the following grammar rules:\n",
    "$$\n",
    "  \\begin{eqnarray*}\n",
    "  \\mathrm{factor}      & \\;\\rightarrow\\; & \\texttt{'('} \\;\\;\\mathrm{expr} \\;\\;\\texttt{')'}                \\\\\n",
    "                       & \\;\\mid          & \\;\\texttt{NUMBER} \n",
    "  \\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "It takes one argument:\n",
    "- `TL` is the list of tokens that still need to be consumed.\n",
    "\n",
    "It returns a pair of the form `(value, Rest)` where\n",
    "- `value` is the result of evaluating the arithmetical expression\n",
    "  that is represented by `TL` and\n",
    "- `Rest` is a list of those tokens that have not been consumed while trying to parse a factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFactor(TL: list[str]) -> tuple[float, list[str]]:\n",
    "    if TL[0] == '(': \n",
    "        expr, Rest = parseExpr(TL[1:])\n",
    "        assert Rest[0] == ')', f\"ERROR: ')' expected, got {Rest[0]}\"\n",
    "        return expr, Rest[1:]\n",
    "    else:\n",
    "        return float(TL[0]), TL[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(s: str) -> float:\n",
    "    r1 = parse(s)\n",
    "    r2 = eval(s)\n",
    "    assert r1 == r2\n",
    "    return r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse('12 * 13 + 14 * 4 / 6 - 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('11+22*(33-44)/(5-10*5/(4-3))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test('0*11+22*(33-44)/(5-10*5/(4-3))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
