\chapter{Regular Expressions \label{chapter:regular-expressions}}
\href{http://en.wikipedia.org/wiki/Regular_expression}{\emph{Regular expressions}} are terms that
specify those formal languages that are simple enough to be recognized by a finite state machine.   
A regular expression is able to specify 
\begin{enumerate}
\item the choice between different alternatives,
\item concatenation, and
\item repetition.
\end{enumerate}
Many modern scripting languages are heavily based on regular expression, for example
the success of the programming language \href{http://en.wikipedia.org/wiki/Perl}{\textsl{Perl}} is
largely based on its efficiency in dealing with regular expressions.
All modern high-level languages, e.g.~\textsl{Java}, \texttt{C\#}, and many others
provide extensive libraries to support regular expressions.  Furthermore, there are a number of 
\textsc{Unix} tools like \href{http://en.wikipedia.org/wiki/Grep}{\texttt{grep}}, 
\href{http://en.wikipedia.org/wiki/Sed}{\texttt{sed}} or
\href{http://en.wikipedia.org/wiki/Awk}{\texttt{awk}} that are based on regular expressions.  Hence,
every aspiring computer scientist needs to be comfortable with regular expressions.


\section{Preliminary Definitions}
Before we can define the syntax and semantics of regular expressions, we need some auxiliary definitions. 


\begin{Definition}[Product of Languages]
  If $\Sigma$ is an  alphabet and $L_1 \subseteq \Sigma^*$ and $L_2 \subseteq \Sigma^*$ are formal
  languages, the \emph{product} of $L_1$ and $L_2$ is written as
  $L_1 \cdot L_2$ and is defined as the set of all concatenations $w_1w_2$ such that $w_1 \in L_1$ and
  $w_2 \in L_2$, i.e.~we have
  \\[0.2cm]
  \hspace*{1.3cm}
  $L_1 \cdot L_2 := \bigl\{ w_1w_2 \mid w_1 \in L_1 \wedge w_2 \in L_2 \bigr\}$ \eox
\end{Definition}

\exampleEng
If $\Sigma = \{ \texttt{a}, \texttt{b}, \texttt{c} \}$ and $L_1$ and $L_2$ are defined as
\\[0.2cm]
\hspace*{1.3cm}
$L_1 = \{ \texttt{ab}, \texttt{bc} \}$ \quad and \quad
$L_2 = \{ \texttt{ac}, \texttt{cb} \}$. 
\\[0.2cm]
Then the product of $L_1$ and $L_2$ is given as
\\[0.2cm]
\hspace*{1.3cm}
$L_1 \cdot L_2 = \{ \texttt{abac}, \texttt{abcb}, \texttt{bcac}, \texttt{bccb} \}$.  \eox

\begin{Definition}[Power of a Language] 
Assume $\Sigma$ is an  alphabet, $L \subseteq \Sigma^*$ is a formal language and $n\in\mathbb{N}_0$.
The  \emph{$n$-th power} of $L$ is written as  $L^n$ and is definition by induction on  $n$. 
\begin{enumerate}
\item[B.C.:] $n = 0$: 

      $L^0 := \{ \varepsilon \}$.

      Here $\varepsilon$ denotes the empty string.  If we would write a string as a list of its characters we would have
      $\varepsilon = []$.
\item [I.S.:] $n \mapsto n + 1$:

      $L^{n+1} = L^n \cdot L$  \eox
\end{enumerate}
\end{Definition}

\exampleEng
If $\Sigma = \{ \texttt{a}, \texttt{b} \}$ and $L = \{ \texttt{ab}, \texttt{ba} \}$, we have
\begin{enumerate}
\item $L^0 = \{ \varepsilon \}$,
\item $L^1 = \{ \varepsilon \} \cdot \{ \texttt{ab}, \texttt{ba} \} = \{ \texttt{ab}, \texttt{ba} \}$,
\item $L^2 = \{ \texttt{ab}, \texttt{ba} \} \cdot \{ \texttt{ab}, \texttt{ba} \} = 
             \{ \texttt{abab}, \texttt{abba}, \texttt{baab}, \texttt{baba} \}$.  \eox
\end{enumerate}

\begin{Definition}[Kleene Closure]
  Assume that $\Sigma$ is an Alphabet and $L \subseteq \Sigma^*$ is some formal language. Then the
  \emph{Kleene closure} of $L$ is written as $L^*$ and is defined to be the union of all powers
  $L^n$ for all $n \in \mathbb{N}_0$: 
  \\[0.2cm]
  \hspace*{1.3cm}
  $L^* := \bigcup\limits_{n \in \mathbb{N}_0} L^n = L^0 \cup L^1 \cup L^2 \cup L^3 \cup \cdots$.
  \\[0.2cm]
  Note that $\mathbb{N}_0 = \{0\} \cup \mathbb{N}$. Therefore, $\varepsilon \in L^*$.
  \qed  
\end{Definition}

\example
Assume $\Sigma = \{ \texttt{a}, \texttt{b} \}$ and  $L = \{ \texttt{a} \}$.  Then we have
\\[0.2cm]
\hspace*{1.3cm}
$L^* = \{ \texttt{a}^n \mid n \in \mathbb{N}_0 \}$.
\\[0.2cm]
Here $\texttt{a}^n$ is the string of length  $n$, that only contains the letter \texttt{a}.  Hence, we have 
\\[0.2cm]
\hspace*{1.3cm}
$\texttt{a}^n = \underbrace{\texttt{a} \cdots \texttt{a}}_n$.  \eox 


Formally, given a string $s$ and an non-negative integer Zahl $n \in \mathbb{N}_0$, we define the expression
 $s^n$ by induction on  $n$:
\begin{enumerate}
\item[B.C.:] $n = 0$

             $s^0 := \varepsilon$. 
\item[I.S.:] $n \mapsto n + 1$

             $s^{n+1} := s^n s$, \quad where $s^n s$ denotes the concatenation of the strings $s^n$ and $s$.
             \eox
\end{enumerate}

The previous example shows that the Kleene closure of a finite language can be infinite.
It is easy to see that the Kleene closure of a language $L$ is infinite,
if $L$ contains at least one string $s$ such that $|s| > 0$.
\vspace*{0.3cm}

We proceed to define the set of regular expressions given an  alphabet $\Sigma$.  This set is
denoted as $\texttt{RegExp}_\Sigma$.  This set is defined by induction.  Simultaneously,  we define
the function
\\[0.2cm]
\hspace*{1.3cm}
$L: \texttt{RegExp}_\Sigma \rightarrow 2^{\Sigma^*}$
\\[0.2cm]
which interprets every regular expression  $r$ as a formal language $L(r) \subseteq \Sigma^*$.\footnote{
  Given a set $M$ the power set of $M$, i.e.~the set of all subsets of $M$, is denoted as $2^M$.
}

\begin{Definition}[Regular Expressions]
  The set $\texttt{RegExp}_\Sigma$ of \emph{regular expression} on the alphabet  $\Sigma$ is defined
  by induction as follows:
  \begin{enumerate}
  \item $\emptyset \in \texttt{RegExp}_\Sigma$

        The regular expression $\emptyset$ denotes the empty language, we have
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(\emptyset) := \{\}$.

        In order to avoid confusion we assume that the symbol $\emptyset$ is not a member of the
        alphabet $\Sigma$, i.e.~we have $\emptyset \not\in \Sigma$.
  \item $\varepsilon \in \texttt{RegExp}_\Sigma$

        The regular expression $\varepsilon$ denotes the language that only contains the empty
        string $\varepsilon$: 
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(\varepsilon) := \{ \varepsilon \}$
        \\[0.2cm]
        Observe that in this equation the two occurrences of $\varepsilon$ are interpreted differently:
        The occurrence of $\varepsilon$ on the left hand side of this equation denotes a regular
        expression, while the occurrence of $\varepsilon$ on the right hand side denotes the empty
        string.
  \item $c \in \Sigma \rightarrow c \in \texttt{RegExp}_\Sigma$.

        Every character from the alphabet $\Sigma$ is a regular expression.  This expression denotes
        the language that contains only the string $c$:
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(c) := \{ c \}$
        \\[0.2cm]
        Observe that we identify characters with strings of length one.
  \item $r_1 \in \texttt{RegExp}_\Sigma \wedge r_2 \in \texttt{RegExp}_\Sigma
         \rightarrow r_1 + r_2 \in \texttt{RegExp}_\Sigma$

        Starting from two regular expressions $r_1$ and $r_2$ we can use the  infix operator
        ``$+$'' to build a new regular expression.  This regular expression denotes the union of 
        the languages described by $r_1$ and $r_2$:
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(r_1 + r_2) := L(r_1) \cup L(r_2)$.

        In order to avoid confusion we have to assume that the symbol  ``\texttt{+}'' does not occur
        in the alphabet $\Sigma$, i.e.~we have  $\squoted{+} \not\in \Sigma$.
  \item $r_1 \in \texttt{RegExp}_\Sigma \wedge r_2 \in \texttt{RegExp}_\Sigma 
         \rightarrow r_1 \cdot r_2 \in \texttt{RegExp}_\Sigma$

        Starting from the regular expression $r_1$ and $r_2$ we can use the  infix operator
        ``$\cdot$'' to build s new regular expression.  This regular expression denotes
        the product of the languages of $r_1$ and $r_2$:
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(r_1 \cdot r_2) := L(r_1) \cdot L(r_2)$.

        Again, in order to avoid confusion we have to assume that the symbol ``$\cdot$'' does not
        occur in the alphabet $\Sigma$, i.e.~we have $\squoted{$\cdot$} \not\in \Sigma$.
  \item $r \in \texttt{RegExp}_\Sigma \rightarrow r^* \in \texttt{RegExp}_\Sigma$

        Given a regular expression $r$, the postfix operator
        ``$^*$'' can be used to create a new regular expression.  This new regular expression
        denotes the Kleene closure of the language described by  $r$:
        \\[0.2cm]
        \hspace*{1.3cm}
        $L(r^*) := \bigl(L(r)\bigr)^*$.

        We have to assume that $\squoted{$^*$} \not\in \Sigma$. 
  \item $r \in \texttt{RegExp}_\Sigma \rightarrow (r) \in \texttt{RegExp}_\Sigma$

        Regular expressions my be surrounded by parentheses.  This does not change the language
        denoted by the regular expression:
        \\[0.2cm]
        \hspace*{1.3cm}
        $L\bigl((r)\bigr) := L(r)$. 

        We have to assume that the parentheses  \qote{(} and \qote{)} do not occur
        in the alphabet $\Sigma$, i.e.~we have $\squoted{(} \not\in \Sigma$  and $\squoted{)} \not\in \Sigma$. \eox
  \end{enumerate}
\end{Definition}
In order to save parentheses and to increase the readability we agree to use the following operator
precedences:
\begin{enumerate}
\item The postfix operator ``$^*$'' has the highest precedence.
\item The precedence of the infix operator ``$\cdot$'' is lower than the precedence of  ``$^*$'' but
      stronger than the precedence of ``$+$''.
\item The operator ``$+$'' has the lowest precedence.
\end{enumerate}
using these conventions, the regular expression 
\\[0.2cm]
\hspace*{1.3cm}
$a + b \cdot c^*$ \quad is interpreted as  \quad $a + \bigl(b \cdot (c^*)\bigr)$.

\examplesEng
In the following examples, the alphabet  $\Sigma$ is defined as
\\[0.2cm]
\hspace*{1.3cm}
$\Sigma := \{ \texttt{a}, \texttt{b}, \texttt{c} \}$.
\begin{enumerate}
\item $r_1 := (\texttt{a} + \texttt{b} + \texttt{c}) \cdot (\texttt{a} + \texttt{b} + \texttt{c})$

      The expression  $r_1$ denotes the set of all strings that have the length $2$:
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r_1) = \bigl\{ w \in \Sigma^* \,\big|\; |w| = 2 \bigr\}$.
\item $r_2 := (\texttt{a} + \texttt{b} + \texttt{c}) \cdot (\texttt{a} + \texttt{b} + \texttt{c})^*$

      The expression  $r_2$ denotes the set of all strings that have at least length $1$:
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r_2) = \bigl\{ w \in \Sigma^* \,\big|\; |w| \geq 1 \bigr\}$.
\item $r_3 := (\texttt{b} + \texttt{c})^* \cdot \texttt{a} \cdot 
              (\texttt{b} + \texttt{c})^*$

      The expression $r_3$ denotes the set of all those strings that have exactly one occurrence of
      the letter ``\texttt{a}'''.  A string containing exactly one ``\texttt{a}''
      is a string that starts with an arbitrary amount of the letters \texttt{b} and \texttt{c} 
      (this is what $(\texttt{b} + \texttt{c})^*$ denotes), followed by the letter ``\texttt{a}'',
      followed by anothe substring containing only the letters \texttt{b} and \texttt{c}.
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r_3) = \Bigl\{ w \in \Sigma^* \;\Big|\;\; 
                        \#\bigl\{i \in  \mathbb{N}_0 \,\big|\; w[i] = \texttt{a} \bigl\} \,= 1 \Bigr\}$.
\item $r_4 :=  (\texttt{b} + \texttt{c})^* \cdot \texttt{a} \cdot (\texttt{b} + \texttt{c})^* +
               (\texttt{a} + \texttt{c})^* \cdot \texttt{b} \cdot (\texttt{a} + \texttt{c})^*$

      The regular expression $r_4$ denotes the set of all those strings that either contain exactly
      one occurrence of the letter ``\texttt{a}'' or exactly one occurrence of the letter ``\texttt{b}''.
      \\[0.2cm]
      \hspace*{0.3cm}
      $L(r_4) = \Bigl\{ w \in \Sigma^* \;\Big|\;\; 
                        \#\bigl\{i \in \mathbb{N}_0 \,\big|\; w[i] = \texttt{a} \bigl\} \,=
                        1 \Bigr\} \;\cup\;
                \Bigl\{ w \in \Sigma^* \;\Big|\;\; 
                        \#\bigl\{i \in \mathbb{N}_0 \,\big|\; w[i] = \texttt{b} \bigl\} \,=
                        1 \Bigr\}$.  \eox 
\end{enumerate}

\remarkEng 
The syntax of regular expressions given here is the same as the syntax used in  \cite{hopcroft:06}
and \cite{sipser:2006}.   However, the syntax used for regular expression in programming languages
like  \textsl{Java} is different.  We will discuss these differences later when we introduce \textsl{JFlex}.

\exercise
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item Assume $\Sigma = \{ \mathtt{a}, \mathtt{b}, \mathtt{c} \}$.  Define a regular expression for the language
      $L \subseteq \Sigma^*$ that consists of those strings that contain at least one occurrence of
      the letter ``\texttt{a}'' and one occurrence of the letter ``\texttt{b}''.
\item Assume $\Sigma = \{ 0, 1 \}$.   Specify a regular expression for the language 
      $L \subseteq \Sigma^*$ that consists of those strings $s$ such that the antepenultimate
      character is the symbol  ``$1$''.
\item Again, we have $\Sigma = \{ 0, 1 \}$.   Define a regular expression for the language
      $L \subseteq \Sigma^*$ containing all those strings that do not contain the substring  $110$.

      % \solutionEng
      % The regular expression $r$ that is sought for can be defined as 
      % \\[0.2cm]
      % \hspace*{1.3cm}
      % $r = (0 + 1 \cdot 0)^* \cdot 1^*$.
      % \\[0.2cm]
      % First, it is quite obvious that the language $L(r)$ does not contain a string $w$ such that
      % $w$ contains the substring $110$.  This is so because a character $1$ that is generated by the
      % part $(0 + 1 \cdot 0)^*$ is immediately followed by a $0$.  Hence if $w$ contains the
      % substring $110$, the first $1$ cannot originate from the regular expression $(0 + 1 \cdot 0)^*$.
      % Furthermore, if the first $1$ of the substring 110 originates from the regular expression
      % $1^*$, then there cannot be a $0$ following since the language generated by $1^*$ contains
      % only ones.

      % Second, assume that the string $w$ does not contain the substring $110$.  We have to show that
      % $w \in L(r)$.  Now if the character $1$ does not occur in the
      % string $w$, then $w$ is just a bunch of zeros and therefore $w$ can be generated by the
      % regular expression $(0+1\cdot 0)^*$ and hence also by $(0 + 1  \cdot 0)^* \cdot 1^*$.  If the string $w$ does contain the character $1$,
      % there are two cases.
      % \begin{enumerate}
      % \item The first occurrence of $1$ is followed by a $0$.  Then the prefix of $w$ upto and
      %       including this $0$ is generated by the regular expression $(0 + 1 \cdot 0)^*$.  The
      %       remaining part of $w$ is shorter and, by induction, can be shown to be generated by 
      %       $(0 + 1 \cdot 0)^* \cdot 1^*$.
      % \item The first occurrence of $1$ is followed by another $1$.  In this case, the rest of $w$
      %       must be made up of ones.  Hence, the part of $w$ starting with the first $1$ is
      %       generated by $1^*$ and obviously the preceding zeros can all be generated by 
      %       $(0 + 1 \cdot 0)^*$.
      % \end{enumerate}
\item Again, assume $\Sigma = \{0,1\}$.  What is the language $L$ generated by the regular expression 
      \\[0.2cm]
      \hspace*{1.3cm}
      $(1 + \varepsilon)\cdot(0\cdot 0^* \cdot 1)^* \cdot 0^*$?  \eox

      % \solutionEng
      % This is the language $L$ such that the strings in $L$ do not contain the substring $11$.
\end{enumerate}
\renewcommand{\labelenumi}{\arabic{enumi}.}

\section{Algebraic Simplifications of Regular Expressions$^*$}
Given two regular expressions $r_1$ and $r_2$, we write
\\[0.2cm]
\hspace*{1.3cm}
$r_1 \doteq r_2$ \quad iff $L(r_1) = L(r_2)$
\\[0.2cm]
If $r_1 \doteq r_2$, then we call $r_1$ and $r_2$ \emph{equivalent}.
The following laws apply:
\begin{enumerate}
\item $r_1 + r_2 \doteq r_2 + r_1$

      Der Beweis dieser Gleichung folgt aus der Definition und der Kommutativität der
      Vereinigung von Mengen:
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r_1 + r_2) = L(r_1) \cup L(r_2) = L(r_2) \cup L(r_1) = L(r_2 + r_1)$.
\item $(r_1 + r_2) + r_3 \doteq r_1 + (r_2 + r_3)$

      Diese Gleichung folgt aus der Assoziativität der Vereinigung.
\item $(r_1 \cdot r_2) \cdot r_3 \doteq r_1 \cdot (r_2 \cdot r_3)$

      Diese Gleichung folgt aus der Tatsache, dass die Konkatenation von Worten assoziativ
      ist, für beliebige Wörter $u$, $v$ und $w$ gilt 
      \\[0.2cm]
      \hspace*{1.3cm}
      $(u v) w = u (v w)$.
      \\[0.2cm]
      Daraus folgt 
      \\[0.2cm]
      \hspace*{1.3cm}
      $
      \begin{array}[t]{lcl}
        L\bigl( (r_1 \cdot r_2) \cdot r_3\bigr) 
        & = & \bigl\{ x w \mid x \in L(r_1 \cdot r_2) \wedge w \in L(r_3)\bigr) \\[0.1cm]
        & = & \bigl\{ (u v) w \mid u \in L(r_1) \wedge v \in L(r_2) \wedge w \in L(r_3)\bigr) \\[0.1cm]
        & = & \bigl\{ u (v w) \mid u \in L(r_1) \wedge v \in L(r_2) \wedge w \in L(r_3)\bigr) \\[0.1cm]
        & = & \bigl\{ u y \mid u \in L(r_1) \wedge y \in L(r_2 \cdot r_3)\bigr) \\[0.1cm]
        & = & L\bigl( r_1 \cdot (r_2 \cdot r_3)\bigr).
      \end{array}
      $
\item $\emptyset \cdot r \doteq r \cdot \emptyset \doteq \emptyset$
\item $\varepsilon \cdot r \doteq r \cdot \varepsilon \doteq r$
\item $\emptyset + r \doteq r + \emptyset \doteq r$
\item $(r_1 + r_2) \cdot r_3 \doteq r_1 \cdot r_3 + r_2 \cdot r_3$
\item $r_1 \cdot (r_2 + r_3) \doteq r_1 \cdot r_2 + r_1 \cdot r_3$
\item $r + r \doteq r$, denn
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r+r) = L(r) \cup L(r) = L(r)$.
\item $(r^*)^* \doteq r^*$      

      Wir haben
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r^*) = \bigcup\limits_{n \in \mathbb{N}_0} L(r)^n$ 
      \\[0.2cm]
      und daraus folgt allgemein $L(r) \subseteq L(r^*)$.   Ersetzen wir in dieser
      Beziehung $r$ durch $r^*$, so sehen wir, dass 
      \\[0.2cm]
      \hspace*{1.3cm}
      $L(r^*) \subseteq L\bigl((r^*)^*\bigr)$
      \\[0.2cm]
      gilt. Um die Umkehrung 
      \\[0.2cm]
      \hspace*{1.3cm}
      $L\bigl((r^*)^*\bigr) \subseteq L(r^*)$
      \\[0.2cm]
      zu beweisen, betrachten wir zunächst die Worte $w \in L\bigl((r^*)^*\bigr)$.
      Wegen 
      \\[0.2cm]
      \hspace*{1.3cm}
      $L\bigl((r^*)^*\bigr) = \bigcup\limits_{n \in \mathbb{N}_0} L(r^*)^n$
      \\[0.2cm]
      gilt $w \in L\bigl((r^*)^*\bigr)$ genau dann, wenn es ein $n \in \mathbb{N}_0$
      gibt, so dass es Wörter $u_1, \cdots,u_n \in L(r^*)$ gibt, so dass 
      \\[0.2cm]
      \hspace*{1.3cm}
      $w = u_1 \cdots u_n$.
      \\[0.2cm]
      Wegen $u_i \in L(r^*)$ gibt es für jedes $i \in \{1,\cdots,n\}$ eine Zahl
      $m(i) \in \mathbb{N}_0$, so dass es für $j=1,\cdots, m(i)$ Wörter 
      $v_{i,j} \in L(r)$ gibt, so dass
      \\[0.2cm]
      \hspace*{1.3cm}
      $u_i = v_{1,i} \cdots v_{m(i),i}$
      \\[0.2cm]
      gilt.  Insgesamt gilt dann
      \\[0.2cm]
      \hspace*{1.3cm}
      $w = v_{1,1} \cdots v_{m(1),1} v_{1,2} \cdots v_{m(2),2} \cdots v_{1,n} \cdots v_{m(n),n}$.
      \\[0.2cm]
      Also ist $w$ eine Konkatenation von Wörtern der Sprache $L(r)$ und das heißt
      \\[0.2cm]
      \hspace*{1.3cm}
      $w \in L\bigl(r^*\bigr)$
      \\[0.2cm]
      und damit ist die Inklusion
      $L\bigl((r^*)^*\bigr) \subseteq L(r^*)$
      gezeigt.
\item $\emptyset^* \doteq \varepsilon$
\item $\varepsilon^* \doteq \varepsilon$
\item $r^* \doteq \varepsilon + r^* \cdot r$
\item $r^* \doteq (\varepsilon + r)^*$
\end{enumerate}
Leider gibt es kein System von Gleichungen, aus denen man alle anderen Gleichungen für
reguläre Ausdrücke ableiten kann.  Es gibt aber eine Ableitungs-Regel, die zusammen mit den oben 
angegeben Gleichungen vollständig ist.  Diese Regel lautet
\\[0.2cm]
\hspace*{1.3cm}
$\bruch{\;r \doteq r \cdot s + t \quad \varepsilon \not\in L(s)\;}{r \doteq t \cdot s^*}$
\\[0.2cm]
Wir werden diese Regel im Folgenden als \emph{Salomaa-Regel} bezeichnen.
Die Korrektheit der Salomaa-Regel ist der Inhalt des folgenden Lemmas.

\begin{Lemma}
  Es seien $r$, $s$ und $t$ reguläre Ausdrücke, für welche die Gleichung
  \\[0.2cm]
  \hspace*{1.3cm}
  $r \doteq r \cdot s + t$
  \\[0.2cm]
  gilt.  Außerdem gelte $\varepsilon \not\in L(s)$.  Dann gilt
  \\[0.2cm]
  \hspace*{1.3cm}
  $r \doteq t \cdot s^*$.
\end{Lemma}

\proof
Nach Voraussetzung wissen wir, dass
\begin{equation}
  \label{eq:r1}
  L(r) = L(r) \cdot L(s) + L(t)  
\end{equation}
gilt.  Wir müssen die Gleichung
\begin{equation}
  \label{eq:r2}
  L(r) = L(t) \cdot L(s^*)  
\end{equation}
nachweisen.  Wir spalten diesen Nachweis in zwei Teile auf und zeigen zunächst, dass
\begin{equation}
  \label{eq:r3}
  L(r) \subseteq L(t) \cdot L(s^*)  
\end{equation}
gilt.  Es sei also $x \in L(r)$ gegeben.  Wir zeigen durch Induktion über die Länge von $x$, dass
daraus $x \in L(t) \cdot L(s^*)$ folgt.   Nach der Voraussetzung $(\ref{eq:r1})$ gibt es zwei Möglichkeiten:
\\[0.2cm]
\hspace*{1.3cm}
$x \in L(r) \cdot L(s)$ \quad oder \quad $x \in L(t)$.
\\[0.2cm]
Wir betrachten die Fälle getrennt und beginnen mit dem einfacheren Fall.
\begin{enumerate}
\item $x \in L(t)$.

      Wegen $\varepsilon \in L(s^*)$ folgt dann sofort
      \\[0.2cm]
      \hspace*{1.3cm}
      $x = x\varepsilon \in L(t) \cdot L(s^*)$.
\item $x \in L(r) \cdot L(s)$.

      Dann lässt sich $x$ in zwei Teilstrings $y$ und $z$ aufspalten, so dass gilt
      \\[0.2cm]
      \hspace*{1.3cm}
      $x = yz$, \quad $y \in L(r)$ \quad und \quad  $z \in L(s)$.
      \\[0.2cm]
      Da $\varepsilon \not\in L(s)$ vorausgesetzt ist, folgt $|z|>0$ und damit gilt $|y| < |x|$, so dass
      wir auf $y$ die  Induktions-Voraussetzung anwenden können und damit
      \\[0.2cm]
      \hspace*{1.3cm}
      $y \in L(t) \cdot L(s^*)$
      \\[0.2cm]
      schließen können.        Für $x$ heißt dies
      \\[0.2cm]
      \hspace*{1.3cm}
      $x = yz \in L(t) \cdot L(s^*) \cdot L(s) \subseteq L(t) \cdot L(s^*)$
      \\[0.2cm]
      und damit ist der Beweis von $L(r) \subseteq L(t) \cdot L(s^*)$ abgeschlossen.
\end{enumerate}
Als nächstes zeigen wir, dass
\begin{equation}
  \label{eq:r4}
  L(t \cdot s^*) \subseteq L(r)
\end{equation}
gilt.  Es sei also ein String  $x \in L(t \cdot s^*)$ gegeben und wir müssen nachweisen, dass 
$x \in L(r)$ liegt.  Wenn $x \in L(t \cdot s^*)$ ist, dann muss $x$ die Form
\\[0.2cm]
\hspace*{1.3cm}
$x = y z_1 \cdots z_m$ \quad mit $y \in L(t)$ und $z_i \in L(s)$ für alle $i=1,\cdots,m$
\\[0.2cm]
haben.  Wir zeigen durch Induktion über $m \in \mathbb{N}_0$, dass 
\\[0.2cm]
\hspace*{1.3cm}
$x = y z_1 \cdots z_m \in L(r)$ \quad für alle $m \in \mathbb{N}_0$ gilt.
\begin{enumerate}
\item[I.A.:] $m= 0$.

             Dann gilt $x = y \in L(t)$ und aus der Voraussetzung (\ref{eq:r1}) folgt
             $y \in L(r)$.
\item[I.S.:] $m \mapsto m + 1$.

             Nach Induktions-Voraussetzung gilt bereits
             \\[0.2cm]
             \hspace*{1.3cm}
             $y z_1 \cdots z_m \in L(r)$.
             \\[0.2cm]
             Nach Gleichung (\ref{eq:r1}) haben wir dann
             \\[0.2cm]
             \hspace*{1.3cm}
             $y z_1 \cdots z_m z_{m+1} \in L(r) \cdot L(s) \subseteq L(r)$
             \\[0.2cm]
             und damit ist die Induktion abgeschlossen.
\end{enumerate}
Damit ist die Gleichung $L(r) = L(t) \cdot L(s^*)$ nun vollständig bewiesen.
\qed



\remark
Der Beweis der Tatsache, dass die oben angegebenen Gleichungen zusammen mit der Salomaa-Regel ausreichen,
um jede gültige Gleichung zweier regulären Ausdrücke nachzuweisen, geht über den Rahmen der Vorlesung
hinaus.  Der Beweis findet sich in einem Papier von Arto Salomaa \cite{salomaa:66}.

\exercise
Zeigen Sie die folgende Gleichung mit Hilfe algebraischer Umformungen und der Salomaa-Regel:
\\[0.2cm]
\hspace*{1.3cm}
$1 \cdot 0 \cdot (1 \cdot 0)^* \doteq  1 \cdot (0 \cdot 1)^* \cdot 0$.
\vspace*{0.1cm}

\solution Wir weisen die Gleichung mit Hilfe der Salomaa-Regel
\\[0.2cm]
\hspace*{1.3cm} $\bruch{\;r \doteq r \cdot s + t \quad \varepsilon \not\in L(s)\;}{r \doteq t \cdot s^*}$
\\[0.2cm]
nach.  Wir definieren zunächst
\\[0.2cm]
\hspace*{1.3cm} $t := 1 \cdot 0$, \quad $s := 1 \cdot 0$ \quad und \quad 
$r := 1 \cdot (0 \cdot 1)^* \cdot 0$.
\\[0.2cm]
Als nächstes zeigen wir, dass $r \doteq r \cdot s + t$ gilt.  Einsetzen der oben definierten Werte liefert
\\[0.2cm]
\hspace*{1.3cm}
$1 \cdot (0 \cdot 1)^* \cdot 0 \eqmark 1 \cdot (0 \cdot 1)^* \cdot 0  \cdot (1 \cdot 0) + 1 \cdot 0$. 
\hspace*{\fill} $(\star)$
\\[0.2cm]
Um $(\star)$ nachzuweisen, formen wir die rechte Seite dieser Gleichung wie folgt um:
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{cll}
       & 1 \cdot (0 \cdot 1)^* \cdot 0  \cdot (1 \cdot 0) + 1 \cdot 0                 \\
\doteq & 1 \cdot (0 \cdot 1)^* \cdot (0  \cdot 1) \cdot 0 + 1 \cdot 0               & 
         \mbox{(Assoziativ-Gesetz)} \\
\doteq & 1 \cdot \bigl( (0 \cdot 1)^* \cdot (0  \cdot 1) + \varepsilon\bigr)\cdot 0 & 
         \mbox{(Distributiv-Gesetz)} \\
\doteq & 1 \cdot (0 \cdot 1)^* \cdot 0 & 
         \mbox{(Regel Nummer 13)} \\
\end{array}
$
\\[0.2cm]
Das ist aber genau die linke Seite von Gleichung $(\star)$, so dass wir damit $(\star)$ bewiesen haben.
Weiterhin gilt $\varepsilon \not\in L(1 \cdot 0)$.  Damit sind die Voraussetzungen der Salomaa-Regel
erfüllt und wir können schließen, dass die Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$r \doteq t \cdot s^*$
\\[0.2cm]
gültig ist.  Einsetzen der Werte von $r$, $s$ und $t$ liefert dann die Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$1 \cdot (0 \cdot 1)^* \cdot 0 \doteq (1 \cdot 0) \cdot (1 \cdot 0)^*$
\\[0.2cm]
und das ist die Behauptung.  \qed

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "formal-languages.tex"
%%% End: 
