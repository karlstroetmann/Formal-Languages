\chapter{Using \textsc{Ply} as a Parser Generator  \label{chapter:ply}}
Most\footnote{The programming language \texttt{C++} is a noteable exception.} modern programming languages can
be parsed using an LALR-Parser.  As this lesson is based on the programming language \textsl{Python}, this
chapter discusses how the parser generator \href{https://www.dabeaz.com/ply/}{\textsc{Ply}} can be used to
generate a parser for any LALR grammar.  In Chapter \ref{chapter:ply-lex} we have already seen how \textsc{Ply}
can be used to generate a scanner.  This chapter focuses on the parser-generating aspect of \textsc{Ply}. 
If you haven't done so already, you can install \textsc{Ply} via \texttt{anaconda} as follows:
\\[0.2cm]
\hspace*{1.3cm}
\texttt{conda install -c anaconda ply}


\section{A Simple Example}
Figure \ref{fig:calculator.g} on page \pageref{fig:calculator.g} shows the grammar of a simple 
\blue{symbolic calculator}.  This grammar is similar to the grammar shown in Figure \ref{fig:Program.g4} on page
\pageref{fig:Program.g4} in Chapter \ref{chapter:antlr}. 

\begin{figure}[!ht]

  \begin{center}    
  \framebox{
  \framebox{
  \begin{minipage}[t]{9cm}
  \begin{eqnarray*}
  \textsl{stmnt}   & \rightarrow & \;\textsc{Identifier} \quoted{:=} \textsl{expr} \quoted{;}\\
                   & \mid        & \;\textsl{expr} \quoted{;}                   \\[0.2cm]
  \textsl{expr}    & \rightarrow & \;\textsl{expr} \quoted{+} \textsl{product}  \\
                   & \mid        & \;\textsl{expr} \quoted{-} \textsl{product}  \\
                   & \mid        & \;\textsl{product}                           \\[0.2cm]
  \textsl{product} & \rightarrow & \;\textsl{product} \quoted{*} \textsl{factor}\\
                   & \mid        & \;\textsl{product} \quoted{/} \textsl{factor}\\
                   & \mid        & \;\textsl{factor}                            \\[0.2cm]
  \textsl{factor}  & \rightarrow &   \quoted{(} \textsl{expr} \quoted{)}        \\
                   & \mid        & \;\textsc{Number}                            \\
                   & \mid        & \;\textsc{Identifier}                        
  \end{eqnarray*}
  \vspace*{-0.5cm}
  \end{minipage}}}
  \end{center}
  \caption{A grammar for a symbolic calculator.}
  \label{fig:calculator.g}
\end{figure}

In order to generate a symbolic calculator that is based on this grammar we first need to implement a scanner.
Figure \ref{fig:Symbolic-Calculator.ipynb:lex} shows how to specify an appropriate scanner with \textsc{Ply}.
As we have discussed scanner generation with \textsc{Ply} at length in Chapter \ref{chapter:ply-lex} there is
no need for further discussions here.

\begin{figure}[!ht]
\centering
\begin{minted}[ frame        = lines, 
                framesep     = 0.3cm, 
                bgcolor      = sepia,
                numbers      = left,
                numbersep    = -0.2cm,
                xleftmargin  = 0.8cm,
                xrightmargin = 0.8cm,
              ]{python3}
    import ply.lex as lex
    
    tokens = [ 'NUMBER', 'IDENTIFIER', 'ASSIGN_OP' ]
    
    def t_NUMBER(t):
        r'0|[1-9][0-9]*(\.[0-9]+)?(e[+-]?([1-9][0-9]*))?'
        t.value = float(t.value)
        return t
    
    def t_IDENTIFIER(t):
        r'[a-zA-Z][a-zA-Z0-9_]*'
        return t
    
    def t_ASSIGN_OP(t):
        r':='
        return t
    
    literals = ['+', '-', '*', '/', '(', ')', ';']
    
    t_ignore  = ' \t'
    
    def t_error(t):
        print(f"Illegal character '{t.value[0]}'")
        t.lexer.skip(1)
    
    lexer = lex.lex()
\end{minted}
\vspace*{-0.3cm}
\caption{A scanner for the symbolic calculator.}
\label{fig:Symbolic-Calculator.ipynb:lex}
\end{figure}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame        = lines, 
                framesep     = 0.3cm, 
                bgcolor      = sepia,
                numbers      = left,
                numbersep    = -0.2cm,
                xleftmargin  = 0.8cm,
                xrightmargin = 0.8cm,
              ]{python3}
    import ply.yacc as yacc
    
    start = 'stmnt'
    
    def p_stmnt_assign(p):
        "stmnt : IDENTIFIER ASSIGN_OP expr ';'"
        Names2Values[p[1]] = p[3]
    
    def p_stmnt_expr(p):
        "stmnt : expr ';'"
        print(p[1])
    
    def p_expr_plus(p):
        "expr : expr '+' prod"
        p[0] = p[1] + p[3]
        
    def p_expr_minus(p):
        "expr : expr '-' prod"
        p[0] = p[1] - p[3]
        
    def p_expr_prod(p):
        "expr : prod"
        p[0] = p[1]
    
    def p_prod_mult(p):
        "prod : prod '*' factor"
        p[0] = p[1] * p[3]
        
    def p_prod_div(p):
        "prod : prod '/' factor"
        p[0] = p[1] / p[3]
        
    def p_prod_factor(p):
        "prod : factor"
        p[0] = p[1]
    
    def p_factor_group(p):
        "factor : '(' expr ')'"
        p[0] = p[2]
    
    def p_factor_number(p):
        "factor : NUMBER"
        p[0] = p[1]
    
    def p_factor_id(p):
        "factor : IDENTIFIER"
        p[0] = Names2Values.get(p[1], float('nan'))
\end{minted}
\vspace*{-0.3cm}
\caption{A scanner for the symbolic calculator, part 1.}
\label{fig:Symbolic-Calculator.ipynb:yacc}
\end{figure}

Figure \ref{fig:Symbolic-Calculator.ipynb:yacc} on page \pageref{fig:Symbolic-Calculator.ipynb:yacc} shows how the
grammar is implemented in \textsc{Ply}.  We discuss it line by line.
\begin{enumerate}
\item Line 1 imports the module \texttt{ply.yacc}.  This module contains the function \texttt{ply.yacc.yacc}
      which is responsible for computing the parse table. The name \blue{yacc} is a homage to the Unix tool
      \href{https://en.wikipedia.org/wiki/Yacc}{\textsc{Yacc}}, which is a popular parser generator for the language
      \texttt{C} and, furthermore, is part of the standard utilities of the Unix operating system.
\item Line 3 specifies that the syntactical variable \texttt{stmnt} is the \blue{start symbol} of the grammar.
\item Line 5 -- 7 define the function \texttt{p\_stmnt\_assign} which implements the grammar rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{stmnt} \rightarrow \textsc{Identifier} \quoted{:=} \textsl{expr}$.
      \\[0.2cm]
      Note that this grammar rule itself is represented by the \blue{document string} of the function
      \texttt{p\_stmnt\_assign}.  In general, if
      \\[0.2cm]
      \hspace*{1.3cm}
      $v \rightarrow \alpha$
      \\[0.2cm]
      is a grammar rule, then this grammar rule is represented by a function that has the name
      \texttt{p\_$v$\_$s$}.  Here, the prefix ``\texttt{p\_}'' specifies that the function implements 
      a grammar rule (the \texttt{p} is short for \blue{parser}), $v$ should\footnote{
        This is just a convention. Technically, $v$ can be any string that is a valid \textsl{Python}
        identifier.
      }
      be the name of the variable
      defined by this grammar rule, and $s$ is a string chosen by the user to distinguish between different
      grammar rules for the same variable.  Of course, $s$ has to be chosen in a way such that the string
      \texttt{p\_$v$\_$s$} is a legal \textsl{Python} identifier.

      The function always takes one argument \texttt{p}.  This argument is a sequence of objects that can be
      indexed with array notation. If the grammar rule defining $v$ has the form
      \\[0.2cm]
      \hspace*{1.3cm}
      $v \rightarrow X_1 \cdots X_n$,
      \\[0.2cm]
      then this sequence has a length of $n+1$.  If $X_i$ is a token, then \texttt{p[$i$]} is the property
      with name \texttt{value} that is associated with this token.  Often, this value is just a string, but it
      can also be a number.  If $X_i$ is a variable, then  \texttt{p[$i$]} is the value that is returned
      when $X_i$ is recognized.  The value associated with the variable $v$ is stored in the location
      \texttt{p[0]}.  In the grammar rule shown in line 5--7, we have not assigned any value to \texttt{p[0]} and
      therefore there is no value associated with the syntactical variable \texttt{stmnt} that is defined by
      this grammar rule.

      \underline{\textbf{Note:}} Line 6 shows how a grammar rule is represented for \textsc{Ply}.
      A grammar rule of the form 
      \\[0.2cm]
      \hspace*{1.3cm}
      $v \rightarrow X_1 \cdots X_n$
      \\[0.2cm]
      is represented as the string:
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{"$v$ : $X_1$ $\cdots$ $X_n$"}
      \\[0.2cm]
      It is very \red{\underline{im}p\underline{ortant}} to note that the character ``\texttt{:}'' has to be
      surrounded by space characters.  Otherwise, the parser generator does not work but rather generates error
      messages that are difficult to understand. 

      The function \texttt{p\_stmnt\_assign} has the task of evaluating the expression that is on the right
      hand side of the assignment operator ``\texttt{:=}''.  The result of this evaluation is then stored in the
      dictionary \texttt{Names2Values}.  The key that is used is the name of the identifier to the left of the
      assignment operator.
\item The function in line 9 -- 11 implements the grammar rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{stmnt} \rightarrow \textsl{expr} \quoted{;}$.
      \\[0.2cm]
      The rule is implemented by evaluating the expression and then printing it.
\item The function \texttt{p\_expr\_plus} implements the grammar rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{expr} \rightarrow \textsl{expr} \quoted{+} \textsl{prod}$.
      \\[0.2cm]
      It is implemented by evaluating the expression to the left of the operator ``\texttt{+}'', which is
      stored in \texttt{p[1]}, and the product to the right of this operator, which is stored in \texttt{p[3]},
      and then adding the corresponding values.  Finally, the resulting sum is stored in \texttt{p[0]} so that
      it is available later as the value of the expression that has been parsed.

      The remaining functions are similar to the ones that are discussed above.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame        = lines, 
                framesep     = 0.3cm, 
                bgcolor      = sepia,
                numbers      = left,
                numbersep    = -0.2cm,
                xleftmargin  = 0.8cm,
                xrightmargin = 0.8cm,
              ]{python3}
    def p_error(p):
        if p:
            print(f'Syntax error at {p.value}.')
        else:
            print('Syntax error at end of input.')
        
    parser = yacc.yacc(write_tables=False, debug=True)

    Names2Values = {}
    
    def main():
        while True:
            s = input('calc > ')
            if s == '':
                break
            yacc.parse(s)
\end{minted}
\vspace*{-0.3cm}
\caption{A scanner for the symbolic calculator, part 2.}
\label{fig:Symbolic-Calculator.ipynb:yacc2}
\end{figure}

\noindent
Figure \ref{fig:Symbolic-Calculator.ipynb:yacc2} on page \pageref{fig:Symbolic-Calculator.ipynb:yacc2}
is discussed next.
\begin{enumerate}
\item Line 1 -- 7 shows the function \texttt{p\_error} which is used to print error messages in the case that
      the input can not be parsed because of a syntax error.  The argument \texttt{p} is the token $t$ that
      caused the entry $\texttt{action}(s, t)$ in the action table to be undefined.
      If the syntax error happens at the end of the input, \texttt{p} has the value \texttt{None}.

      In a more serious application, the parser would also print both the line and column numbers of the
      offending token, but in order to keep this example small, this is not done here.
\item Line 7 generates the parser.
      \begin{enumerate}[(a)]
      \item The first argument \texttt{write\_tables} has to be set to \texttt{False} to prevent an
            obscure bug from happening.
      \item The argument \texttt{debug} has to be set to \texttt{True} if we want to dump the parse table
            to the disk.  The parse table is then written to the file \texttt{parser.out}.
      \end{enumerate}
\item Line 9 initializes the dictionary \texttt{Names2Values}.  For every identifier $x$ defined interactively,
      \texttt{Names2Values[$x$]} is the value associated with $x$.
\item The function \texttt{main} is used as a driver for the parser.  It reads a string \texttt{s}
      from the command line and tries to parse \texttt{s} using the function \texttt{yacc.parse}.
      The function \texttt{yacc.parse} is generated behind the scenes when the function \texttt{yacc.yacc} is
      invoked in line 7. 
\end{enumerate}


\section{Shift/Reduce und Reduce/Reduce-Konflikte}
\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                  commandchars  = \\\{\}
                ]
    import java_cup.runtime.*;
    
    terminal           PLUS, MINUS, TIMES, DIVIDE, MOD;
    terminal           UMINUS, LPAREN, RPAREN;
    terminal Integer   NUMBER;
    
    nonterminal Integer expr;
    
    expr ::= expr PLUS   expr
          |  expr MINUS  expr
          |  expr TIMES  expr
          |  expr DIVIDE expr
          |  expr MOD    expr
          |  NUMBER               
          |  MINUS expr
          |  LPAREN expr RPAREN   
          ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{\textsc{Cup}-Spezifikation eines Parsers für arithmetische Ausdrücke}
\label{fig:calc-ambiguous.cup}
\end{figure}

Wir betrachten nun ein weiteres Beispiel.  Abbildung \ref{fig:calc-ambiguous.cup} zeigt eine 
\textsc{Cup}-Spezifikation einer Grammatik, die offenbar mehrdeutig ist, da die Präzedenzen der
arithmetischen Operatoren durch diese Grammatik nicht festgelegt werden.
  Mit dieser Grammatik ist beispielsweise nicht klar, ob der String
\\[0.2cm]
\hspace*{1.3cm} 
``\texttt{1 + 2 * 3}'' \quad als \quad  ``\texttt{(1 + 2) * 3}'' \quad oder als \quad ``\texttt{1 + (2 * 3)}''
\\[0.2cm]
interpretiert werden soll.   Wir hatten im letzten Kapitel schon gesehen, dass es in einer
mehrdeutigen Grammatik immer Shift/Reduce- oder Reduce/Reduce-Konflikte geben muss, denn jede
LALR-Grammatik ist eindeutig.  Wenn wir versuchen, die Grammatik aus Abbildung
\ref{fig:calc-ambiguous.cup} mit \textsc{Cup} zu übersetzen und wenn wir dabei zusätzlich die Option 
``\texttt{-dump}'' angeben, der Aufruf von \textsc{Cup} hat dann die Form
\\[0.2cm]
\hspace*{1.3cm}
\texttt{cup -dump calc.cup}
\\[0.2cm]
so erhalten wir eine große Zahl von Shift/Reduce-Konflikten angezeigt.
Beispielsweise erhalten wir die folgende Fehlermeldung:
\begin{verbatim}
    Warning : *** Shift/Reduce conflict found in state #12
      between expr ::= expr MINUS expr (*) 
      and     expr ::= expr (*) PLUS expr 
      under symbol PLUS
      Resolved in favor of shifting.
\end{verbatim}
Statt des Zeichens ``$\bullet$'' benutzt \textsc{Cup} den String
``\texttt{(*)}'' zur Darstellung der Position in einer markierten Regel.
Die obige Fehlermeldung zeigt uns an, dass es zwischen der markierten Regel
\\[0.2cm]
\hspace*{1.3cm}
$R_1 \;:=\; 
\Bigl(\textsl{expr} \rightarrow \textsl{expr} \quoted{-} \textsl{expr}\;\bullet\Bigr)$
\\[0.2cm]
und der markierten Regel
\\[0.2cm]
\hspace*{1.3cm}
$R_2 \; := \; 
\Bigl(\textsl{expr} \rightarrow \textsl{expr} \bullet \quoted{+} \textsl{expr}\Bigr)$
\\[0.2cm]
einen Shift/Reduce-Konflikt gibt:  Die beiden markierten  Regeln $R_1$ und $R_2$
sind Elemente eines Zustands, der von \textsc{Cup} intern mit der Nummer 12 versehen
worden ist.  Der Zustand mit der Nummer 12 hat folgende Form:
\begin{verbatim}
    lalr_state [12]: {
      [expr ::= expr (*) MOD expr ,    {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
      [expr ::= expr (*) MINUS expr ,  {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
      [expr ::= expr (*) DIVIDE expr , {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
      [expr ::= expr (*) TIMES expr ,  {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
      [expr ::= expr (*) PLUS expr ,   {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
      [expr ::= expr MINUS expr (*) ,  {EOF PLUS MINUS TIMES DIVIDE MOD RPAREN }]
    }
\end{verbatim}
Damit können wir jetzt den
Shift/Reduce-Konflikt interpretieren: Im Zustand 12 ist der Parser entweder dabei, die
Eingabe mit der Regel 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{expr} \rightarrow \textsl{expr} \quoted{-} \textsl{expr}$
\\[0.2cm]
zu reduzieren, oder der Parser ist gerade dabei, die rechte Seite der Regel 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{expr} \rightarrow \textsl{expr} \quoted{+} \textsl{expr}$
\\[0.2cm]
zu erkennen, wobei er bereits eine \textsl{expr} erkannt hat und nun als nächstes das
Token ``\texttt{+}'' erwartet wird.  Da das Token ``\texttt{+}'' auch in der Follow-Menge der
erweiterten markierten Regel $R_1$ liegen kann, ist an dieser Stelle unklar, ob das Token
``\texttt{+}'' auf den 
Stack geschoben werden soll, oder ob stattdessen mit der Regel $R_1$ reduziert werden
muss.  Bei einem Shift/Reduce-Konflikt entscheidet sich der von \textsc{Cup} erzeugte
Parser immer dafür, das Token auf den Stack zu schieben.


\section{Operator-Präzendenzen \label{section:operator-precedence}}
Es ist mit   \textsc{Cup} möglich, Shift/Reduce-Konflikte durch die Angabe von
\emph{Operator-Präzedenzen} 
aufzulösen.  Abbildung \ref{fig:calc-precedence.cup} zeigt die Spezifikation einer Grammatik zur
Erkennung arithmetischer Ausdrücke, die aus Zahlen und den binären Operatoren ``\texttt{+}'',
``\texttt{-}'', ``\texttt{*}'', ``\texttt{/}'' und ``\texttt{\symbol{94}}'' aufgebaut sind.   Mit
Hilfe der Schlüsselwörter 
\\[0.2cm]
\hspace*{1.3cm}
``\texttt{precedence left}'' \quad und \quad ``\texttt{precedence right}'' 
\\[0.2cm]
haben wir festgelegt, dass die Operatoren ``\texttt{+}'', ``\texttt{-}'', ``\texttt{*}'' und
``\texttt{/}'' \emph{links-assoziativ} sind, ein Ausdruck der Form 
\\[0.2cm]
\hspace*{1.3cm}
$3 - 2 - 1$ \quad wird also als \quad $(3 - 2) - 1$ \quad und nicht als \quad $3 - (2-1)$
\\[0.2cm]
gelesen.  Demgegenüber ist der Operator ``\texttt{\symbol{94}}'', der in der \textsc{Cup}-Grammatik
mit ``\texttt{POW}'' bezeichnet wird und die Potenzbildung bezeichnet,
\emph{rechts-assoziativ}, der Ausdruck 
\\[0.2cm]
\hspace*{1.3cm}
$4 \texttt{\symbol{94}} 3 \texttt{\symbol{94}} 2$ \quad wird daher als \quad
$4^{\mbox{(}3^2\mbox{)}}$ \quad  und nicht als \quad $\bigl(4^3\bigr)^2$
\\[0.2cm]
interpretiert.   Die Reihenfolge, in der die Assoziativität der Operatoren spezifiziert werden, legt die
\emph{Präzedenzen}, die auch als \emph{Bindungsstärken} bezeichnet werden, fest.  Dabei ist die
Bindungsstärke umso größer, je später der Operator spezifiziert wird.  In unserem konkreten Beispiel bindet
der Exponentiations-Operator ``\texttt{\symbol{94}}'' also am stärksten, während die Operatoren ``\texttt{+}'' und
``\texttt{-}'' am schwächsten binden.  Bei der in Abbildung \ref{fig:calc-precedence.cup} gezeigten Grammatik
ordnet \textsc{Cup} den Operatoren die Bindungsstärke nach der folgenden Tabelle zu:

\begin{center}
\begin{tabular}[t]{|c|c|c|}
\hline
Operator       & Bindungsstärke & Assoziativität \\
\hline
\hline
``\texttt{+}''  & 1             &  links         \\
\hline
``\texttt{-}''  & 1             &  links         \\
\hline
``\texttt{*}''  & 2             &  links         \\
\hline
``\texttt{/}''  & 2             &  links         \\
\hline
``\texttt{\symbol{94}}'' & 3             &  rechts        \\
\hline
\end{tabular}
\end{center}


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    import java_cup.runtime.*;
    class  ExprParser;
    
    terminal         SEMI, PLUS, MINUS, TIMES, DIVIDE, MOD, POW;
    terminal         UMINUS, LPAREN, RPAREN;
    
    terminal Double  NUMBER;
    
    nonterminal        expr_list, expr_part;
    nonterminal Double expr;
    
    precedence left   PLUS, MINUS;
    precedence left   TIMES, DIVIDE, MOD;
    precedence right  UMINUS, POW;
    
    start with expr_list;
    
    expr_list ::= expr_list expr_part 
               |  expr_part
               ;
    
    expr_part ::= expr:e {: System.out.println("result = " + e); :} SEMI 
               ;
    
    expr ::= expr:e1 PLUS   expr:e2 {: RESULT = e1 + e2; :} 
          |  expr:e1 MINUS  expr:e2 {: RESULT = e1 - e2; :} 
          |  expr:e1 TIMES  expr:e2 {: RESULT = e1 * e2; :}
          |  expr:e1 DIVIDE expr:e2 {: RESULT = e1 / e2; :} 
          |  expr:e1 MOD    expr:e2 {: RESULT = e1 % e2; :} 
          |  expr:e1 POW    expr:e2 {: RESULT = Math.pow(e1, e2); :} 
          |  NUMBER:n               {: RESULT = n;       :} 
          |  MINUS expr:e           {: RESULT = - e;     :} %prec UMINUS
          |  LPAREN expr:e RPAREN   {: RESULT = e;       :} 
          ;
\end{Verbatim}
%$
\vspace*{-0.3cm}
\caption{Auflösung der Shift/Reduce-Konflikte durch Operator-Präzedenzen.}
\label{fig:calc-precedence.cup}
\end{figure}

Wie erläutern nun, wie diese Bindungsstärken benutzt werden, um Shift/Reduce-Konflikte aufzulösen.
\textsc{Cup} geht folgendermaßen vor:
\begin{enumerate}
\item Zunächst wird jeder Grammatik-Regel eine \emph{Präzedenz} zugeordnet.
      Die Präzedenz ist dabei die Bindungsstärke des letzten in der Regel auftretenden Operators.
      Für den Fall, dass eine Regel mehrere Operatoren enthält, für die eine Bindungsstärke spezifiziert
      wurde, wird zur Festlegung der Bindungsstärke also der Operator herangezogen, der in
      der Regel am weitesten 
      rechts steht.  In unserem Beispiel haben die einzelnen Regeln damit die folgenden Präzedenzen:
      \begin{center}
        \begin{tabular}[t]{|l|c|}
          \hline
          Regel                          & Präzedenz  \\
          \hline
          \hline
          $E \rightarrow E \quoted{+} E$ & 1          \\
          \hline
          $E \rightarrow E \quoted{-} E$ & 1          \\
          \hline
          $E \rightarrow E \quoted{*} E$ & 2          \\
          \hline
          $E \rightarrow E \quoted{/} E$ & 2          \\
          \hline
          $E \rightarrow E \quoted{\symbol{94}} E$ & 3 \\
          \hline
          $E \rightarrow \quoted{(} E \quoted{)}$ & --- \\
          \hline
          $E \rightarrow N$ & --- \\
          \hline
        \end{tabular}
      \end{center}
      Für die Regeln, die keinen Operator enthalten, für den eine Bindungsstärke spezifiziert ist,
      bleibt die Präzedenz unspezifiziert.
\item Ist $s$ ein Zustand, in dem zwei Regeln $r_1$ und $r_2$ der Form
      \\[0.2cm]
      \hspace*{1.3cm}
      $r_1 = (a \rightarrow \beta \bullet o \;\delta:L_1)$ \quad und \quad
      $r_2 = (c \rightarrow \gamma \bullet : L_2)$ \quad mit \quad $o \in L_2$
      \\[0.2cm]
      vorkommen, so gibt es bei der Berechnung von 
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{action}(s, o)$
      \\[0.2cm]
      zunächst einen Shift/Reduce-Konflikt.  Falls dem Operator $o$ die Präzedenz $p(o)$
      zugeordnet worden ist und wenn außerdem die Regel $r_2$, mit der reduziert werden würde, die
      Präzedenz  $p(r_2)$ hat, so wird der Shift/Reduce-Konflikt in Abhängigkeit von der relativen
      Größe   der beiden Zahlen $p(o)$ und $p(r_2)$ aufgelöst.  Hier werden fünf Fälle unterschieden:
      \begin{enumerate}
      \item $p(o) > p(c \rightarrow \gamma)$: 
            In diesem Fall bindet der Operator $o$ stärker.  Daher wird das Token $o$  
            in diesem Fall auf den Stack geschoben:
            \hspace*{1.3cm}
            \\[0.2cm]
            $\textsl{action}(s,o) = \langle \texttt{shift}, \textsl{goto}(s,o) \rangle$.
            \\[0.2cm]
            Dass diese Regel sinnvoll ist, sehen wir, wenn wir beispielsweise den Eingabe-String
            \\[0.2cm]
            \hspace*{1.3cm}
            $\texttt{1+2*3}$
            \\[0.2cm]
            mit den Grammatik-Regeln 
            \\[0.2cm]
            \hspace*{1.3cm}
            $E \rightarrow E \quoted{+} E \mid E \quoted{*} E \mid \textsc{Number}$
            \\[0.2cm]
            parsen.  Betrachten wir die Situation, bei der der Teilstring ``\texttt{1+2}''
            bereits gelesen wurde und nun als nächstes das Token ``\texttt{*}''
            verarbeitet werden soll.  Der LALR-Parser ist dann in dem folgenden Zustand:
            \\[0.2cm]
            \hspace*{1.3cm}
            $ 
            \begin{array}[t]{llcll}
            \bigl\{ 
            & E & \rightarrow & E \bullet \squoted{*} E: \{\symbol{36}, \squoted{*}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \bullet \squoted{+} E: \{\symbol{36}, \squoted{*}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \squoted{+} E \;\bullet: \{\symbol{36}, \squoted{*}, \squoted{+} \}
            & \bigr\}.
            \end{array}
            $
            \\[0.2cm]
            Wenn in diesem Zustand als nächstes Zeichen ein ``\texttt{*}'' gelesen wird, so darf der
            bisher gelesene String ``\texttt{1+2}'' nicht mit der Regel 
            $E \rightarrow E \squoted{+} E$ reduziert werden, denn wir wollen die 2 ja zunächst mit 3 
            multiplizieren.  Stattdessen muss also das Zeichen 
            ``\texttt{*}'' auf den Stack geschoben werden.
      \item $p(o) < p(c \rightarrow \gamma)$: 
            Jetzt bindet der Operator, der in der Regel $r_2$ auftritt, stärker als der
            Operator $o$.  Daher wird in diesem Fall zunächst mit der Regel $r_2$ reduziert, wir haben 
            also 
            \\[0.2cm]
            \hspace*{1.3cm}
            $\textsl{action}(s,o) = \langle \texttt{reduce}, r_2 \rangle$.
            \\[0.2cm]
            Dass diese Regel sinnvoll ist, sehen wir, wenn wir beispielsweise den Eingabe-String
            \\[0.2cm]
            \hspace*{1.3cm}
            $\texttt{1*2+3}$
            \\[0.2cm]
            mit den Grammatik-Regeln 
            \\[0.2cm]
            \hspace*{1.3cm}
            $E \rightarrow E \quoted{+} E \mid E \quoted{*} E \mid \textsc{Number}$
            \\[0.2cm]
            parsen.  Betrachten wir die Situation, bei der der Teilstring ``\texttt{1*2}''
            bereits gelesen wurde und nun als nächstes das Token ``\texttt{+}''
            verarbeitet werden soll.  Der LALR-Parser ist dann in dem folgenden Zustand:
            \\[0.2cm]
            \hspace*{1.3cm}
            $ 
            \begin{array}[t]{llcll}
         \bigl\{ 
            & E & \rightarrow & E \bullet \squoted{*} E: \{\symbol{36}, \squoted{*}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \bullet \squoted{+} E: \{\symbol{36}, \squoted{*}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \squoted{*} E \;\bullet: \{\symbol{36}, \squoted{*}, \squoted{+} \}
            & \bigr\}.
            \end{array}
            $
            \\[0.2cm]
            Wenn in diesem Zustand als nächstes Zeichen ein ``\texttt{+}'' gelesen wird, so soll
            der bisher gelesene String ``\texttt{1*2}''  mit der Regel 
            $E \rightarrow E \squoted{*} E$ reduziert werden, denn wir wollen die 1 ja zunächst mit 2 
            multiplizieren.  
      \item $p(o) = p(c \rightarrow \gamma)$ und der Operator $o$ ist links-assoziativ:
            Dann wird zunächst mit der Regel $r_2$ reduziert, wir haben
            also 
            \\[0.2cm]
            \hspace*{1.3cm}
            $\textsl{action}(s,o) = \langle \texttt{reduce}, r_2 \rangle$.
            \\[0.2cm]
            Dass diese Regel sinnvoll ist, sehen wir, wenn wir beispielsweise den Eingabe-String
            \\[0.2cm]
            \hspace*{1.3cm}
            $\texttt{1-2-3}$
            \\[0.2cm]
            mit den Grammatik-Regeln 
            \\[0.2cm]
            \hspace*{1.3cm}
            $E \rightarrow E \quoted{+} E \mid E \quoted{-} E \mid \textsc{Number}$
            \\[0.2cm]
            parsen.  Betrachten wir die Situation, bei der der Teilstring ``\texttt{1-2}''
            bereits gelesen wurde und nun als nächstes das Token ``\texttt{-}''
            verarbeitet werden soll.  Der LALR-Parser ist dann in dem folgenden Zustand:
            \\[0.2cm]
            \hspace*{1.3cm}
            $ 
            \begin{array}[t]{llcll}
         \bigl\{ 
            & E & \rightarrow & E \bullet \squoted{-} E: \{\symbol{36}, \squoted{-}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \bullet \squoted{+} E: \{\symbol{36}, \squoted{-}, \squoted{+} \}, 
            & \\
            & E & \rightarrow & E \squoted{-} E \;\bullet: \{\symbol{36}, \squoted{-}, \squoted{+} \}
            & \bigr\}.
            \end{array}
            $
            \\[0.2cm]
            Wenn in diesem Zustand als nächstes Zeichen ein ``\texttt{-}'' gelesen wird, so soll
            der bisher gelesene String ``\texttt{1-2}'' mit der Regel 
            $E \rightarrow E \squoted{-} E$ reduziert werden, denn wir wollen von der Zahl 1 ja
            zunächst die Zahl 2 subtrahieren.  
      \item $p(o) = p(c \rightarrow \gamma)$ und der Operator $o$ ist rechts--assoziativ:
            In diesem Fall wird $o$ auf den
            Stack geschoben:
            \\[0.2cm]
            \hspace*{1.3cm}
            $\textsl{action}(s,o) = \langle \texttt{shift}, \textsl{goto}(s,o) \rangle$.
            \\[0.2cm]
            Wenn wir diesen Fall verstehen wollen, reicht es aus, den String
            \\[0.2cm]
            \hspace*{1.3cm}
            $\texttt{2\symbol{94}3\symbol{94}4}$
            \\[0.2cm]
            mit den Grammatik-Regeln
            \\[0.2cm]
            \hspace*{1.3cm}
            $E \rightarrow E \,\texttt{\symbol{94}}\, E \mid \textsc{Number}$
            \\[0.2cm]
            zu parsen und die Situation zu betrachten, bei der der Teilstring
            ``\texttt{1\symbol{94}2}'' bereits verarbeitet wurde und als nächstes Zeichen nun
            der Operator ``\texttt{\symbol{94}}'' gelesen wird.
            Der LALR-Parser ist dann in dem folgenden Zustand:
            \\[0.2cm]
            \hspace*{1.3cm}
            $\bigl\{ 
             E  \rightarrow E \bullet \quoted{\texttt{\symbol{94}}} E:
             \{\symbol{36},\quoted{\texttt{\symbol{94}}} \},\;  E \rightarrow  E
             \squoted{\texttt{\symbol{94}}} E \;\bullet: \{\symbol{36},\quoted{\texttt{\symbol{94}}}\}
            \bigr\}.
            $
            \\[0.2cm]
            Hier muss als nächstes das Token \quoted{\texttt{\symbol{94}}} auf den Stack geschoben
            werden, denn wir wollen ja zunächst den Ausdruck ``$3 \texttt{\symbol{94}} 4$'' berechnen.
      \item $p(o) = p(c \rightarrow \gamma)$ und der Operator $o$ hat keine Assoziativität:
            In diesem Fall liegt ein Syntax-Fehler vor:
            \\[0.2cm]
            \hspace*{1.3cm}
            $\textsl{action}(s,o) = \textsl{error}$.
            \\[0.2cm]
            Diesen Fall verstehen Sie, wenn Sie versuchen, einen String der Form
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{1 < 1 < 1}
            \\[0.2cm]
            mit den Grammatik-Regeln
            \\[0.2cm]
            \hspace*{1.3cm}
            $E \rightarrow E \quoted{<} E \mid E \quoted{+} E \mid \textsc{Number}$
            \\[0.2cm]
            %$
            zu parsen.  In dem Moment, in dem Sie den Teilstring ``\texttt{1 < 1}'' gelesen haben
            und nun das nächste Token das Zeichen ``\texttt{<}'' ist, erkennen Sie, 
            dass es ein Problem gibt.  

            \remark
            Beachten Sie, dass auch in diesem Fall der Shift/Reduce-Konflikt aufgelöst
            wird, denn den Syntax-Fehler erhalten Sie erst beim Parsen,  während die
            Erstellung des Parsers selber fehlerfrei (sprich: ohne verbleibende Konflikte)
            verläuft.

            Um in \textsc{Cup} einen Operator $o$ als nicht-assoziativ zu deklarieren, 
            schreiben Sie:
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{precedence nonassoc $o$}
      \item $p(o)$ ist undefiniert oder $p(c \rightarrow \gamma)$ ist undefiniert.

            In diesem Fall erzeugt \textsc{Cup} einen Shift/Reduce-Konflikt und gibt bei der
            Erzeugung des Parsers eine entsprechende Warnung aus.  Diese Warnung wird als Fehler
            gewertet,  wenn sie nicht durch Angabe der Option 
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{-expect} $n$
            \\[0.2cm]
            beim Aufruf von \textsc{Cup} unterdrückt wird.  Bei dieser Option ist $n$ die Anzahl der
            vom Benutzer erwarteten Konflikte. In diesem Fall wird der Konflikt dann per Default
            dadurch aufgelöst,  dass das betreffende Token auf den Stack geschoben wird. 
            Wir werden dieses Verhalten im nächsten Abschnitt anhand eines Beispiels im Detail 
            diskutieren. 
      \end{enumerate}

\end{enumerate}
Die von \textsc{Cup} mit der Option ``\texttt{-dump}'' erzeugte Ausgabe zeigt im Detail, wie die
Shift/Reduce-Konflikt Konflikte aufgelöst worden sind.  Wir betrachten exemplarisch zwei Zustände in
der Datei, die für die in Abbildung \ref{fig:calc-precedence.cup} gezeigte Grammatik erzeugt wird.
\begin{enumerate}
\item Der Zustand Nummer 14 hat die in Abbildung \ref{fig:state14} gezeigte Form.
      Hier gibt es unter anderem einen Shift/Reduce-Konflikt zwischen den beiden markierten Regeln
      \\[0.2cm]
      \hspace*{1.3cm}
      $E \rightarrow E \bullet \quoted{+} E$ \quad und \quad
      $E \rightarrow E \quoted{*} E \bullet$, 
      \\[0.2cm]
      denn die erste Regel verlangt nach einem Shift, während die zweite Regel eine Reduktion fordert.
      Da die Regel $E \rightarrow E \quoted{*} E$ dieselbe Präzedenz wie der Operator ``\texttt{*}''
      und dieser eine höhere Präzedenz als $\quoted{+}$ hat, wird beispielsweise beim Lesen des Zeichens
      ``\texttt{+}'' mit der Regel $E \rightarrow E \quoted{*} E$ reduziert.
      Wird hingegen das Zeichen ``\texttt{\^}'' gelesen, so wird dieses geshiftet, denn
      dieses Zeichen hat eine höhere Priorität als die Regel
       $E \rightarrow E \quoted{*} E$.
    \begin{figure}[!ht]
    \centering
    \begin{Verbatim}[ frame         = lines, 
                      framesep      = 0.3cm, 
                      labelposition = bottomline,
                      numbers       = left,
                      numbersep     = -0.2cm,
                      xleftmargin   = 0.8cm,
                      xrightmargin  = 0.8cm,
                    ]
    lalr_state [14]: {
      [expr ::= expr (*) PLUS expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr TIMES expr (*) , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) POW expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) TIMES expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) MOD expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) MINUS expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) DIVIDE expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
    }

    From state #14
     [term 2:REDUCE(with prod 7)] [term 3:REDUCE(with prod 7)]
     [term 4:REDUCE(with prod 7)] [term 5:REDUCE(with prod 7)]
     [term 6:REDUCE(with prod 7)] [term 7:REDUCE(with prod 7)]
     [term 8:SHIFT(to state 9)] [term 11:REDUCE(with prod 7)]
    \end{Verbatim} 
    %$
    \vspace*{-0.3cm}
    \caption{Der Zustand Nummer 14.}
    \label{fig:state14}
  \end{figure}
      Weiterhin gibt es einen Shift/Reduce-Konflikt zwischen den beiden markierten Regeln
      \\[0.2cm]
      \hspace*{1.3cm}
      $E \rightarrow E \bullet \quoted{*} E$ \quad und \quad
      $E \rightarrow E \quoted{*} E \bullet$.
      \\[0.2cm]
      Hier haben beide Regeln die gleiche Präzedenz.  Daher entscheidet die  Assoziativität.
      Da der Operator ``\texttt{*}'' links-assoziativ ist, wird mit der Regel
      $E \rightarrow E \quoted{*} E$ reduziert, falls das nächste Zeichen ein Multiplikations-Operator
      ``\texttt{*}'' ist.
\item Der Zustand Nummer 18 hat die in Abbildung \ref{fig:state18} gezeigte Form.
      Zunächst gibt es hier einen Shift/Reduce-Konflikt zwischen den Regeln
      \\[0.2cm]
      \hspace*{1.3cm}
      $E \rightarrow E \bullet \quoted{\symbol{94}} E$ \quad und \quad
      $E \rightarrow E \quoted{\symbol{94}} E  \bullet$,
      \\[0.2cm]
      wenn das nächste Token der Operator ``\texttt{\symbol{94}}'' ist.  Da der Operator 
      dieselbe Präzedenz 
      hat wie die Regel, entscheidet die Assoziativität.  Nun ist der Operator
      ``\texttt{\symbol{94}}'' rechts-assoziativ, daher wird in diesem Fall geshiftet.

    \begin{figure}[!ht]
    \centering
    \begin{Verbatim}[ frame         = lines, 
                      framesep      = 0.3cm, 
                      labelposition = bottomline,
                      numbers       = left,
                      numbersep     = -0.2cm,
                      xleftmargin   = 0.8cm,
                      xrightmargin  = 0.8cm,
                    ]
    lalr_state [18]: {
      [expr ::= expr POW expr (*) , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) PLUS expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) POW expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) TIMES expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) MOD expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) MINUS expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
      [expr ::= expr (*) DIVIDE expr , {SEMI PLUS MINUS TIMES DIVIDE MOD POW RPAREN }]
    }

    From state #18
     [term 2:REDUCE(with prod 10)] [term 3:REDUCE(with prod 10)]
     [term 4:REDUCE(with prod 10)] [term 5:REDUCE(with prod 10)]
     [term 6:REDUCE(with prod 10)] [term 7:REDUCE(with prod 10)]
     [term 8:SHIFT(to state 9)] [term 11:REDUCE(with prod 10)]
    \end{Verbatim} 
    %$
    \vspace*{-0.3cm}
    \caption{Der Zustand Nummer 18.}
    \label{fig:state18}
  \end{figure}

      Hier gibt es noch viele andere Shift/Reduce-Konflikte, die aber alle dieselbe Struktur haben.
      Exemplarisch betrachten wir den Shift/Reduce-Konflikt zwischen den Regeln
      \\[0.2cm]
      \hspace*{1.3cm}
      $E \rightarrow E \bullet \quoted{+} E$ \quad und \quad
      $E \rightarrow E \quoted{\symbol{94}} E  \bullet$,
      \\[0.2cm]
      der auftritt, wenn das nächste Token ein ``\texttt{+}'' ist.  Da die Regel 
      $E \rightarrow E \quoted{\symbol{94}} E$ die Präzedenz 3 hat, die größer ist als die Präzedenz 1 des
      Operators ``\texttt{+}'' wird dieser Konflikt dadurch aufgelöst, dass mit der Regel 
      $E \rightarrow E \quoted{\symbol{94}} E$ reduziert wird. 
\end{enumerate}    
\vspace*{\fill} \pagebreak

\exercise
Implementieren Sie einen \textsc{Cup}-Parser, der in der Lage ist, eine
\textsc{Cup}-Grammatik zu lesen und zusätzlich die folgenden Anforderungen erfüllt:
\begin{enumerate}
\item Die Grammatik soll intern in Form eines abstrakten Syntax-Baums abgespeichert werden.  
      In dem Verzeichnis 
      \\[0.2cm]
      \hspace*{1.3cm}
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Exercises/Grammar2HTML-Cup/}{
\texttt{Exercises/Grammar2HTML-Cup/}}
      \\[0.2cm]
      finden Sie verschiedene \textsl{Java}-Klassen, mit denen Sie einen solchen Syntax-Baum
      darstellen können.  Diese Klassen implementieren eine Methode \texttt{toString()}, mit deren
      Hilfe sich der Syntax-Baum bequem im \textsc{Html}-Format ausgeben lässt.  Außerdem enthält
      das Verzeichnis auch die Datei 
      \href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Exercises/Grammar2HTML-Cup/Grammatik.java}{\texttt{Grammatik.java}},
      welche die Klasse \texttt{Grammatik}
      implementiert.  Diese Klasse enthält eine Methode \texttt{main}, mit der Sie Ihren Parser
      testen können.
\item Die semantischen Aktionen der gelesenen Grammatik sollen unterdrückt werden.
\item Testen Sie Ihr Programm, indem Sie es sowohl auf sich selbst als auch auf die im Unterricht
      vorgestellte Grammatik für arithmetische Ausdrücke anwenden.
      Zusätzlich können Sie es auch auf die \texttt{C}-Grammatik, die Sie unter
      \\[0.2cm]
      \hspace*{1.3cm}
      \href{https://github.com/karlstroetmann/Formal-Languages/blob/master/Cup/Grammars/c-grammar.cup}{https://github.com/karlstroetmann/Formal-Languages/blob/master/Cup/Grammars/c-grammar.cup}
      \\[0.2cm]
      im Netz finden, anwenden.
\end{enumerate}


\section{Das \emph{Dangling-Else}-Problem}
\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    class Dangling;
    
    terminal LPAREN, RPAREN, IF, ELSE, WHILE, LBRACE, RBRACE, ASSIGN, SEMI;
    terminal EQUAL, ID;
    
    nonterminal stmnt, stmntList, expr;
    
    start with stmnt;
    
    stmnt ::= IF LPAREN expr RPAREN stmnt
           |  IF LPAREN expr RPAREN stmnt ELSE stmnt
           |  WHILE LPAREN expr RPAREN stmnt
           |  LBRACE stmntList RBRACE
           |  ID ASSIGN expr SEMI
           ;
      
    stmntList ::= stmntList stmnt
               |  /* epsilon */
               ;
    
    expr ::= ID EQUAL ID
           | ID
           ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Fragment einer Grammatik für die Sprache \texttt{C}}
\label{fig:dangling-else.y}
\end{figure}

\noindent
Bei der syntaktischen Beschreibung von Befehlen der Sprache \texttt{C} tritt bei der Behandlung
von \emph{if-then-else} Konstrukten ein Shift/Reduce-Konflikt auf, den wir jetzt analysieren wollen.
Abbildung \ref{fig:dangling-else.y} zeigt die Grammatik 
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/DanglingElse/dangling.cup}{\texttt{dangling.cup}},
die einen Teil der Syntax von Befehlen der Sprache \texttt{C} beschreibt.  Um uns auf das
Wesentliche konzentrieren zu können, sind dort die Ausdrücke nur Gleichungen und Variablen.  Das
Token ``\texttt{ID}'' (Abkürzung für \textsl{Identifier}) steht für eine Variable, die Grammatik
beschreibt also Befehle, die aus Zuweisungen, \emph{If-Abfragen}, \emph{If-Else-Abfragen} und
\emph{While-Schleifen} aufgebaut sind.  Übersetzen wir diese Grammatik mit \textsc{Cup}, so erhalten
wir den in Abbildung \ref{fig:dangling-else.output} ausschnittsweise gezeigten 
Shift/Reduce-Konflikt. 

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm,
                ]
    Warning : *** Shift/Reduce conflict found in state #10
      between stmnt ::= IF LPAREN expr RPAREN stmnt (*) 
      and     stmnt ::= IF LPAREN expr RPAREN stmnt (*) ELSE stmnt 
      under symbol ELSE
      Resolved in favor of shifting.

    lalr_state [10]: {
      [stmnt ::= IF LPAREN expr RPAREN stmnt (*) , {EOF IF ELSE WHILE LBRACE RBRACE ID }]
      [stmnt ::= IF LPAREN expr RPAREN stmnt (*) ELSE stmnt , {EOF IF ELSE WHILE LBRACE RBRACE ID }]
    }
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Ein Shift/Reduce-Konflikt.}
\label{fig:dangling-else.output}
\end{figure}
%$

Der Konflikt entsteht bei der Berechnung von
 $\texttt{action}(\mbox{``\texttt{state \#10}''}, \mbox{``\texttt{else}''})$ zwischen den
beiden markierten Regeln
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{stmnt} \rightarrow \quoted{if} \quoted{(} \textsl{expr} \quoted{)} \textsl{stmnt}\;\; \bullet$ 
\quad und
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{stmnt} \rightarrow 
\quoted{if} \quoted{(} \textsl{expr} \quoted{)} \textsl{stmnt} \;\bullet \quoted{else} \textsl{stmnt}$.
\\[0.2cm]
Die erste Regel verlangt nach einer Reduktion, die zweite Regel sagt, dass das Token 
\texttt{else} geshiftet werden soll.  Das dem Konflikt zu Grunde liegende Problem ist, dass die in Abbildung
\ref{fig:dangling-else.y} gezeigte Grammatik mehrdeutig ist, denn ein \textsl{stmnt} der Form
\\[0.2cm]
\hspace*{1.3cm}
\texttt{if (a == b) if (c == d) s = t; else u = v;}
\\[0.2cm]
kann auf die folgenden beiden Arten gelesen werden:
\begin{enumerate}
\item Die erste (und nach der Spezifikation der Sprache \texttt{C} auch korrekte) Interpretation 
      besteht darin, dass wir den Befehl wie folgt klammern:
      \begin{verbatim}
      if (a == b) {
          if (c == d) {
              s = t; 
          } else {
              u = v;
          }
      }
      \end{verbatim}
      \vspace*{-0.7cm}
\item Die zweite Interpretation, die nach der in Abbildung
      \ref{fig:dangling-else.y} gezeigten Grammatik ebenfalls zulässig wäre,
      würde den Befehl in der folgenden Form interpretieren:
      \begin{verbatim}
      if (a == b) {
          if (c == d) {
              s = t; 
          }
      } else {
          u = v;
      }
      \end{verbatim}
      \vspace*{-0.5cm}

      Hier wird das ``\texttt{else}'' dem äußeren ``\texttt{if}'' zugeordnet, was nicht der
      Spezifikation der Sprache \texttt{C} entspricht. 
\end{enumerate}
Es gibt vier Möglichkeiten, das Problem zu lösen.
\begin{enumerate}
\item Tritt ein Shift/Reduce-Konflikt auf, der nicht durch Operator-Präzedenzen gelöst wird,
      so ist der Default, dass das nächste Token auf den Stack geschoben wird.  In dem konkreten
      Fall ist dies genau das, was wir wollen, weil dadurch das ``\texttt{else}'' immer mit dem letzten
      ``\texttt{if}'' assoziert wird.  Um die normalerweise bei Konfliken von \textsc{Cup}
      ausgelöste Fehlermeldung zu unterdrücken, müssen wir \textsc{Cup} mit der Option
      ``\texttt{-expect}'' wie folgt aufrufen:
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{cup -expect 1 -dump dangling.cup}
      \\[0.2cm]
      Die Zahl \texttt{1} gibt hier die Anzahl der Konflikte an, die wir erwarten.
      So lange die spezifizierte Zahl der Konflikte mit der tatsächlich gefundenen Zahl übereinstimmt,
      wird von \textsc{Cup} nur eine Warnung und keine Fehlermeldung ausgegeben. Insbesondere wird
      in diesem Fall ein Parser erzeugt.
\item Die zweite Möglichkeit besteht darin, die Grammatik so umzuschreiben, dass die Mehrdeutigkeit
      verschwindet.   Die grundsätzliche Idee ist hier, zwischen zwei Arten von Befehlen zu
      unterscheiden.
      \begin{enumerate}
      \item[(a)] Einerseits gibt es Befehle, bei denen jedem ``\texttt{if}'' auch ein ``\texttt{else}''
            zugeordnet ist.  Zwischen einem ``\texttt{if}'' und einem ``\texttt{else}'' dürfen nur
            solche Befehle auftreten.

            Wir bezeichnen Befehle dieser Form als \emph{geschlossene Befehle}.  Die Idee bei dieser
            Sprechweise besteht darin, dass ``\texttt{if}'' als öffnende Klammer zu interpretieren,
            während das ``\texttt{else}'' einer schließenden Klammer entspricht.  Bei einem
            geschlossenen Befehl entspricht jeder öffnenden Klammer eine schließende Klammer.
     \item[(b)] Andererseits gibt es Befehle, bei denen dem letzten ``\texttt{if}'' kein
            ``\texttt{else}'' zugeordnet ist.  Solche Befehle bezeichnen wir als \emph{offene Befehle}.
            Offene Befehle dürfen nicht zwischen einem ``\texttt{if}'' und einem ``\texttt{else}''
            auftreten, denn dann müsste das ``\texttt{else}'' dem ``\texttt{if}'' des offenen
            Befehls zugeordnet werden und der offene Befehl wäre in Wahrheit geschlossen.
     \end{enumerate}
      Abbildung \ref{fig:dangling-else-correct.cup} zeigt die Grammatik
      \href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/DanglingMatched/dangling.cup}{\texttt{dangling.cup}},
      die diese Idee umsetzt.  In der Abbildung sind nur noch die Grammatik-Regeln gezeigt, denn die
      Deklaration der Terminale und syntaktischen Variablen hat sich gegenüber der ursprünglichen
      Grammatik nicht verändert. Die syntaktische Kategorie \textsl{matchedStmnt} beschreibt dabei
      die Befehle, bei denen jedem ``\texttt{if}'' ein ``\texttt{else}'' zugeordnet ist, während die
      Kategorie \textsl{unMatchedStmnt} die restlichen Befehle erfasst.

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    stmnt ::= matchedStmnt
           |  unmatchedStmnt
           ;
    
    matchedStmnt ::= IF LPAREN expr RPAREN matchedStmnt ELSE matchedStmnt
                  |  WHILE LPAREN expr RPAREN matchedStmnt
                  |  LBRACE stmntList RBRACE
                  |  ID ASSIGN expr SEMI
                  ;
    
    unmatchedStmnt ::= IF LPAREN expr RPAREN stmnt
                    |  IF LPAREN expr RPAREN matchedStmnt ELSE unmatchedStmnt
                    |  WHILE LPAREN expr RPAREN unmatchedStmnt
                    ;
          
    stmntList ::= stmntList stmnt 
               |  /* epsilon */
               ;
    
    expr ::= ID EQUAL ID
           | ID
           ;
    \end{Verbatim}
    \vspace*{-0.3cm}
    \caption{Eine eindeutige Grammatik für \texttt{C}-Befehle.}
    \label{fig:dangling-else-correct.cup}
\end{figure}

      Aus theoretischer Sicht ist das Umschreiben der Grammatik der sauberste Weg.  
      Aus diesem Grund haben die Entwickler der Sprache \textsl{Java} \cite{gosling:96} bei der
      \href{http://titanium.cs.berkeley.edu/doc/java-langspec-1.0/14.doc.html#5991}{Spezifikation}
      der Syntax den oben skizzierten Weg beschritten.   
      Der Nachteil ist allerdings, dass bei diesem Vorgehen die Grammatik aufgebläht wird. 
\item Die nächste Möglichkeit um das \emph{Dangling-Else}-Problem zu lösen, besteht darin, dass
      wir ``\texttt{if}'' und ``\texttt{else}'' als Operatoren auffassen, denen wir eine Präzedenz
      zuordenen.  Abbildung \ref{fig:dangling-else-precedence.cup} zeigt die Grammatik
      \href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/DanglingOperator/dangling.cup}{\texttt{dangling.cup}},
      bei der dieser Weg beschritten wurde.
      \begin{enumerate}
      \item[(a)] Zunächst haben wir in den Zeilen 1 und 2 die Terminale ``\texttt{IF}'' und
            ``\texttt{ELSE}''  als
            nicht-assoziative Operatoren deklariert, wobei ``\texttt{ELSE}'' die höhere Präzedenz
            hat.  Dadurch erreichen wir, dass ein ``\texttt{ELSE}'' auf den Stack geschoben wird,
            wenn der Parser in dem in Abbildung \ref{fig:dangling-else.output} gezeigten Zustand ist.
      \item[(b)] In Zeile 6 haben wir der Regel
            \\[0.2cm]
            \hspace*{1.3cm}
            \textsl{stmnt} \texttt{::=} \texttt{IF} \texttt{LPAREN} \textsl{expr} \texttt{RPAREN} \textsl{stmnt}
            \\[0.2cm]      
            explizit mit Hilfe der nachgestellten Option
            \\[0.2cm]
            \hspace*{1.3cm}
            \texttt{\symbol{37}prec IF}
            \\[0.2cm]
            die Präzedenz des Operators ``\texttt{IF}'' zugewiesen.  Dies ist notwendig, weil 
            der letzte Operator, der in dieser Regel auftritt, die schließende runde Klammer
            ``\texttt{RPAREN}'' ist, der wir keine Priorität zugewiesen haben.  Der Klammer eine Priorität
            zuzuweisen wäre einerseits kontraintuitiv, andererseits problematisch, da die Klammer ja
            auch noch an anderen Stellen verwendet werden könnte.  Mit Hilfe der
            ``\texttt{\symbol{37}prec}''-Deklaration können wir einer Regel unmittelbar die Präzedenz
            eines Operators zuweisen und so das Problem umgehen.

            In dem vorliegenden Fall ist die Präzedenz des Operators ``\texttt{ELSE}''
            höher als die Präzedenz von ``\texttt{IF}'', so dass der Shift/Reduce-Konflikt
            dadurch aufgelöst wird, dass das Token ``\texttt{ELSE}'' auf den Stack
            geschoben wird, wodurch eine ``\texttt{else}''-Klausel tatsächlich mit der unmittelbar davor stehenden
            ``\texttt{if}''-Klausel verbunden wird, wie es die Definition der Sprache \texttt{C} fordert.
      \end{enumerate}


            \begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    precedence nonassoc IF;
    precedence nonassoc ELSE;

    start with stmnt;

    stmnt ::= IF LPAREN expr RPAREN stmnt            %prec IF
           |  IF LPAREN expr RPAREN stmnt ELSE stmnt
           |  WHILE LPAREN expr RPAREN stmnt
           |  LBRACE stmntList RBRACE
           |  ID ASSIGN expr SEMI
           ;
      
    stmntList ::= stmntList stmnt
               |  /* epsilon */
               ;
    
    expr ::= ID EQUAL ID
           | ID
           ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Auflösung des Shift/Reduce-Konflikts mit Hilfe von Operator-Präzedenzen.}
\label{fig:dangling-else-precedence.cup}
\end{figure}

      Operator-Präzedenzen sind ein mächtiges Mittel um eine Grammatik zu strukturieren.  Sie
      sollten allerdings mit Vorsicht eingesetzt werden, denn Sprachen wie die
      Programmier-Sprache \texttt{C}, bei der es 15 verschiedene Operator-Präzendenzen gibt, überfordern
      die meisten Benutzer.
\item Die letzte Möglichkeit, das \emph{Dangling-Else}-Problem zu lösen, besteht darin, dass wir
      fordern, dass die Befehle, die in einem ``\texttt{if}''-Befehl verwendet werden, immer in den geschweiften
      Klammern ``\texttt{\{}'' und ``\texttt{\}}'' eingeschlossen werden.  Dies ist allerdings nur
      dann eine Option, wenn wir die Syntax der Sprache selber definieren können.  Bei der Sprache
      \href{http://randoom.org/Software/SetlX}{\textsc{SetlX}}
      wurde dieser Weg beschritten.  Abbildung \ref{fig:dangling-else-brace.cup} auf Seite
      \pageref{fig:dangling-else-brace.cup} zeigt die Grammatik
      \href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/DanglingBrace/no-dangling.cup}{\texttt{no-dangling.cup}},
      bei der durch die Verwendung von geschweiften Klammern erreicht wurde, dass keine
      Mehrdeutigkeit mehr auftritt. 

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    stmnt ::= IF LPAREN expr RPAREN block            
           |  IF LPAREN expr RPAREN block ELSE block
           |  WHILE LPAREN expr RPAREN stmnt
           |  block
           |  ID ASSIGN expr SEMI
           ;
    
    block ::= LBRACE stmntList RBRACE
           ;
    
    stmntList ::= stmntList stmnt
               |  /* epsilon */
               ;    

    expr ::= ID EQUAL ID
           | ID
           ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Eine Grammatik ohne das \emph{Dangling-Else}-Problem.}
\label{fig:dangling-else-brace.cup}
\end{figure}

\end{enumerate}
 


\section{Auflösung von Reduce/Reduce-Konflikten}
Im Gegensatz zu Shift/Reduce-Konflikten können Reduce/Reduce-Konflikte nicht durch Operator-Präzedenzen
aufgelöst werden.  Wir diskutieren in diesem Abschnitt die Möglichkeiten, die wir haben um
Reduce/Reduce-Konflikte aufzulösen.  Wir beginnen unsere Diskussion damit, dass wir die
Reduce/Reduce-Konflikte in verschiedene Kategorien einteilen. 
\begin{enumerate}
\item \emph{Mehrdeutigkeits-Konflikte} sind Reduce/Reduce-Konflikte, die ihre Ursache in einer Mehrdeutigkeit
      der zu Grunde liegenden Grammatik haben.  Solche Konflikte weisen damit auf ein tatsächliches
      Problem der Grammatik hin.  Wir hatten ein Beispiel für solche Konflikte gesehen, als wir in
      Abbildung \ref{fig:calc-ambiguous.cup} in der Grammatik
      \href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/Calculator-Ambiguous/calc.cup}{\texttt{calc.cup}} 
      versucht hatten, die Syntax arithmetischer Ausdrücke ohne die syntaktischen
      Kategorien \textsl{product} und \textsl{factor} zu beschreiben.

      Wir hatten damals bereits gesehen, dass wir das Problem durch die Einführung von
      Operator-Präzedenzen lösen können.  Falls dies nicht möglich ist, dann bleibt nur das
      Umschreiben der Grammatik.
\item \emph{Look-Ahead-Konflikte} sind Reduce/Reduce-Konflikte, bei denen die Grammatik zwar
      einerseits eindeutig ist, für die aber andererseits
      ein Look-Ahead von einem Token aber nicht ausreichend ist um den Konflikt zu lösen.
\item \emph{Mysteriöse Konflikte} entstehen erst beim Übergang von den LR-Zuständen zu den LALR-Zuständen 
      durch das Zusammenfassen von Zuständen mit dem gleichen Kern.  Diese Konflikte treten also
      genau dann auf, wenn das Konzept einer LALR-Grammatik nicht ausreichend ist um die Syntax der
      zu parsenden Sprache zu beschreiben.
\end{enumerate}
Wir betrachten die letzten beiden Fälle nun im Detail und zeigen Wege auf, wie die Konflikte gelöst
werden können.

\subsection{Look-Ahead-Konflikte}
Ein Look-Ahead-Konflikt liegt dann vor, wenn die Grammatik zwar eindeutig ist, aber ein Look-Ahead von einem
Token nicht ausreicht um zu entscheiden,  mit welcher Regel reduziert werden soll.  Abbildung 
\ref{fig:lr-conflict.g} zeigt die Grammatik 
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/LookAheadConflict/lookAhead.cup}{\texttt{lookAhead.cup}}\footnote{ 
Diese Grammatik habe ich im Netz auf der Seite von Pete Jinks unter der Adresse
\\[0.1cm]
\hspace*{1.3cm}
\href{http://www.cs.man.ac.uk/~pjj/cs212/ho/node19.html}{\texttt{http://www.cs.man.ac.uk/\symbol{126}pjj/cs212/ho/node19.html}}
\\[0.1cm]
gefunden.},
die zwar eindeutig ist, aber nicht die LR(1)-Eigenschaft hat.  

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    terminal    U, V, W, X;
    nonterminal a, b, c;

    a ::= b U V
       |  c U W
       ;    
    b ::= X
       ;
    c ::= X 
       ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Eine eindeutige Grammatik ohne die LR(1)-Eigenschaft.}
\label{fig:lr-conflict.g}
\end{figure}


Berechnen wir die LR-Zustände dieser Grammatik,
so finden wir unter anderem den folgenden Zustand:
\\[0.2cm]
\hspace*{1.3cm}
$\{ b \rightarrow \;\squoted{X} \bullet: \squoted{U},\; c \rightarrow \;\squoted{X} \bullet: \squoted{U} \}$.
\\[0.2cm]
Da die Menge der Folge-Token für beide Regeln gleich sind, haben wir hier einen Reduce/Reduce-Konflikt.
Dieser Konflikt hat seine Ursache darin, dass der Parser mit einem Look-Ahead von nur einem Token nicht
entscheiden kann, ob ein $\squoted{X}$ als ein $b$ oder als ein $c$ zu interpretieren ist, denn dies
entscheidet sich erst, wenn das auf $\squoted{U}$ folgende Zeichen gelesen wird:  Handelt es sich hierbei
um ein $\squoted{V}$, so wird insgesamt die Regel
\\[0.2cm]
\hspace*{1.3cm}
$a \rightarrow b\; \squoted{U} \squoted{V}$
\\[0.2cm]
verwendet werden und folglich ist das $\squoted{X}$ als ein $b$ zu interpretieren. Ist das zweite Token
hinter dem $\squoted{X}$ hingegen ein  $\squoted{W}$, so ist die zu verwendende Regel
\\[0.2cm]
\hspace*{1.3cm}
$a \rightarrow c \;\squoted{U} \squoted{W}$
\\[0.2cm]
und folglich ist das $\quoted{X}$ als  $c$ zu lesen.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    a ::= b V
       |  c W
       ;
    b ::= X U
       ;
    c ::= X U
       ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Eine zu \ref{fig:lr-conflict.g} äquivalente LR(1)-Grammatik.}
\label{fig:lr-conflict-resolved.g}
\end{figure}

Das Problem bei dieser Grammatik ist, dass sie versucht, abhängig vom Kontext ein $\squoted{X}$ wahlweise
als ein $b$ oder als ein $c$ zu interpretieren.  Es ist offensichtlich, wie das Problem gelöst werden
kann:  Wenn der Kontext ``\texttt{U}'', der sowohl auf $b$ als auch auf $c$ folgt, mit in
die Regeln für $b$ und $c$ aufgenommen wird, dann verschwindet der Konflikt, denn dann hat der
Zustand, in dem früher der Konflikt auftrat, die Form
\\[0.2cm]
\hspace*{1.3cm}
$\{ b \rightarrow \;\squoted{X} \squoted{U}\bullet: \squoted{V},\; 
    c \rightarrow \;\squoted{X} \squoted{U}\bullet: \squoted{W} 
\}
$.
\\[0.2cm]  
Hier entscheidet sich nun anhand des nächsten Tokens, mit welcher Regel wir in diesem Zustand
reduzieren müssen:  Ist das nächste Token ein $\squoted{V}$, so reduzieren wir mit der Regel
\\[0.2cm]
\hspace*{1.3cm}
$b \rightarrow \;\squoted{X} \squoted{U}$,
\\[0.2cm]
ist das nächste Token hingegen der Buchstabe $\squoted{W}$, so nehmen wir stattdessen die Regel
\\[0.2cm]
\hspace*{1.3cm}
$c \rightarrow \;\squoted{X} \squoted{U}\bullet: \squoted{W}$.
\\[0.2cm]
Abbildung
\ref{fig:lr-conflict-resolved.g} zeigt die entsprechend modifizierte Grammatik
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/LookAheadConflict/solved.cup}{\texttt{solved.cup}},

\subsection{Mysteriöse Reduce/Reduce-Konflikte}
Wir sprechen dann von einem \emph{mysteriösen Reduce/Reduce-Konflikt}, wenn die gegebene Grammatik eine
LR(1)-Grammatik ist, sich aber beim Übergang von den LR-Zuständen zu den LALR-Zuständen Reduce/Reduce-Konflikte
ergeben.  Die in Abbildung \ref{fig:mysterious.cup} gezeigte Grammatik 
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/MysteriousConflict/mysterious.cup}{\texttt{mysterious.cup}}
habe ich dem 
\href{http://www.gnu.org/software/bison/manual/}{\textsl{Bison}-Handbuch} entnommen. 


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    terminal    ID, COMMA, COLON;
    nonterminal def, param_spec, return_spec, type, name_list, name;
    
    def   
        ::= param_spec return_spec COMMA
         ;
    param_spec
        ::= type
         |  name_list COLON type
         ;    
    return_spec
        ::= type
         |  name COLON type
         ;
    type  
        ::= ID
         ;    
    name
        ::= ID
         ;
    name_list
        ::= name
         |  name COMMA name_list
         ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Eine \textsc{Cup}-Grammatik mit einem mysteriösen Reduce/Reduce-Konflikt.}
\label{fig:mysterious.cup}
\end{figure}
\vspace*{0.3cm}

Übersetzen wir diese Grammatik mit \textsc{Cup}, so erhalten wir unter anderem den folgenden Zustand:
\begin{verbatim}
    lalr_state [1]: {
      [name ::= ID (*) , {COMMA COLON }]
      [type ::= ID (*) , {ID COMMA }]
    }
\end{verbatim}
Da in beiden Mengen von Folgetoken das Token \texttt{COMMA} auftritt, gibt es hier offensichtlich einen
Reduce/Reduce-Konflikt.   Um diesen Konflikt besser zu verstehen, berechnen wir zunächst die Zustände
eines kanonischen LR-Parsers für diese Grammatik.
Wir erhalten dann eine Menge von Zuständen, von denen die für den späteren Konflikt ursächlichen 
Zuständen in Abbildung \ref{fig:mysterious.txt} gezeigt sind.

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    s0 = { S -> <*> def: [$],
           def -> <*> param_spec return_spec ',': [$],
           param_spec -> <*> name_list ':' type: [ID],
           param_spec -> <*> type: [ID],
           name_list -> <*> name: [':'],
           name_list -> <*> name ',' name_list: [':'],
           name -> <*> ID: [',', ':'],
           type -> <*> ID: [ID]
         }
    s2 = { def -> param_spec <*> return_spec ',': [$],
           return_spec -> <*> name ':' type: [','],
           return_spec -> <*> type: [','],
           name -> <*> ID: [':'],
           type -> <*> ID: [',']
         }
    s7 = { name -> ID <*>: [',', ':'],
           type -> ID <*>: [ID]
         }
    s8 = { name -> ID <*>: [':'],
           type -> ID <*>: [',']
         }
\end{Verbatim}
\vspace*{-0.3cm}
\caption{LR-Zustände der in Abbildung \ref{fig:mysterious.cup} gezeigten Grammatik.}
\label{fig:mysterious.txt}
\end{figure} %\$

Analysieren wir die Zustände, so stellen wir fest, dass beim Übergang von LR-Zuständen zu den
LALR-Zuständen die beiden Zustände $s_7$ und $s_8$ zu einem Zustand zusammengefasst werden, denn diese
beiden Zustände haben den selben Kern.  Bei der Zusammenfassung entsteht der Zustand, der von
\textsc{Cup} als ``\texttt{lalr\_state [1]}'' bezeichnet hat.  Die Zustände $s_7$ und $s_8$ selber haben
noch keinen Konflikt, weil dort die Mengen der Folgetoken disjunkt sind.  Der Konflikt tritt erst durch
die Vereinigung dieser beiden Mengen auf, denn dadurch ist das Token ``$\texttt{,}$'' als Folgetoken für
beide in dem Zustand enthaltenen Regeln zulässig.   Um den Konflikt aufzulösen müssen wir verhindern, dass
die beiden Zustände $s_7$ und $s_8$ zusammengefasst werden.  Dazu analysieren wir zunächst, wo diese
Zustände herkommen.
\begin{enumerate}
\item Den Zustand $s_7$ erhalten wir, wenn wir im Zustand $s_0$ das Token \texttt{ID} lesen, denn
      es gilt 
      \\[0.2cm]
      \hspace*{1.3cm}
      $s_7 = \textsl{goto}(s_0, \mathtt{ID})$.
\item Der Zustand $s_8$ entsteht, wenn das Token \texttt{ID} im Zustand $s_2$ gelesen wird, wir haben
      \\[0.2cm]
      \hspace*{1.3cm}
      $s_8 = \textsl{goto}(s_2, \mathtt{ID})$.
\end{enumerate}
Die Idee zur Auflösung des Konflikts ist, dass wir den Zustand $s_2$ so ändern, dass die Kerne von
$s_7 = \textsl{goto}(s_0, \mathtt{ID})$ und $s_8 = \textsl{goto}(s_0, \mathtt{ID})$ unterschiedlich werden.  
Die erweiterten markierten Regeln in den Zuständen $s_0$ und $s_2$, die letztlich für den Konflikt verantwortlich
sind, sind die Grammatik-Regeln für die syntaktische Variablen \textsl{param\_spec} und
\textsl{return\_spec}, denn von diesen Regeln werden die  Zustände $s_7$ und $s_8$ abgeleitet.
Um zu verhindern, dass diese Zustände zusammengefasst werde, ändern wir die Regeln für die
syntaktische Variable \textsl{return\_spec} wie in der in Abbildung \ref{fig:myst-solved.g}
gezeigten Grammatik
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/MysteriousConflict/mysterious-solved.cup}{\texttt{mysterious-solved.cup}}
 ab,
indem wir eine zusätzliche Grammatik-Regel 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{return\_spec} \rightarrow \mathtt{ID}\;\, \mathtt{BOGUS}$
\\[0.2cm]
einführen.  Wenn das Terminal \texttt{BOGUS} nie vom Scanner erzeugt werden kann, dann ändert sich durch
die Hinzunahme dieser Regel die von der Grammatik erzeugte Sprache nicht.  Allerdings ändern sich nun die
LR-Zustände.  Abbildung \ref{fig:myst-solved.txt} zeigt, wie sich die entsprechenden Zustände ändern.
Insbesondere sehen wir, dass der Zustand $s_8$ nun eine weitere markierte Regel enthält, zu der es in dem
Zustand $s_7$ kein äquivalent gibt.  Die Konsequenz ist, dass diese Zustände beim Übergang von den
LR-Zuständen zu den LALR-Zuständen nicht mehr zusammengefasst werden können, da sie unterschiedliche
Kerne haben.  Daher gibt es dann auch keinen Konflikt mehr. 

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    def : param_spec return_spec ','
        ;    
    param_spec
        : type
        |  name_list ':' type
        ;
    return_spec
        : type
        | name ':' type
        | ID BOGUS      // this never happens
        ;
    type: ID
        ;
    name: ID
        ;
    name_list
        : name
        | name ',' name_list
        ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Auflösung des mysteriösen Reduce/Reduce-Konflikts.}
\label{fig:myst-solved.g}
\end{figure}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    s0 = { S -> <*> def: [$],
           def -> <*> param_spec return_spec ',': [$],
           name -> <*> ID: [',', ':'],
           name_list -> <*> name: [':'],
           name_list -> <*> name ',' name_list: [':'],
           param_spec -> <*> name_list ':' type: [ID],
           param_spec -> <*> type: [ID],
           type -> <*> ID: [ID]
         }    
    s2 = { def -> param_spec <*> return_spec ',': [$],
           name -> <*> ID: [':'],
           return_spec -> <*> ID BOGUS: [','],
           return_spec -> <*> name ':' type: [','],
           return_spec -> <*> type: [','],
           type -> <*> ID: [',']
         }
    s7 = { name -> ID <*>: [',', ':'],
           type -> ID <*>: [ID]
         }    
    s8 = { name -> ID <*>: [':'],
           return_spec -> ID <*> BOGUS: [','],
           type -> ID <*>: [',']
         }
\end{Verbatim}
\vspace*{-0.3cm} %\$
\caption{Einige Zustände der in Abbildung \ref{fig:myst-solved.g} gezeigten Grammatik.}
\label{fig:myst-solved.txt}
\end{figure}

\section{Auflösung von Shift/Reduce-Konflikten}
Es gibt im Wesentlichen zwei Arten von Shift/Reduce-Konflikten:
\begin{enumerate}
\item Konflikte, die auf eine Mehrdeutigkeit der Grammatik zurückzuführen sind.

      Solche Mehrdeutigkeits-Konflikte hatten wir beispielsweise in der Grammatik für arithmetische
      Ausdrücke, die in Abbildung \ref{fig:shift-reduce-conflict.grammar} auf Seite
      \pageref{fig:shift-reduce-conflict.grammar} gezeigt ist, diskutiert.  In dem Beispiel waren
      diese Konflikte darauf zurückzuführen, dass durch die Grammatik keine Präzedenzen für die
      arithmetischen Operatoren festgelegt wurde, so dass am Ende nicht klar war, ob ein Ausdruck
      der Form ``\texttt{1+2*3}'' als ``\texttt{1+(2*3)}'' oder als ``\texttt{(1+2)*3}'' zu
      interpretieren ist.

      Wir haben bereits früher in Abschnitt \ref{section:operator-precedence} besprochen, wie solche
      Konflikte durch die Spezifikation von Operator-Präzedenzen aufgelöst werden können.
\item Konflikte, die entstehen, weil ein Look-Ahead von einem Token nicht ausreichend ist um zu
      entscheiden, ob das nächste Token der Eingabe auf den Stack geschoben werden soll, oder 
      ob stattdessen der Stack durch Anwendung einer Grammatik-Regel reduziert werden muss.
      Solche \emph{Look-Ahead}-Konflikte   werden wir in diesem Abschnitt diskutieren.
\end{enumerate}
Als Beispiel für einen Look-Ahead-Konflikt betrachten wir die in Abbildung \ref{fig:lambda.g}
gezeigte Grammatik
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/LambdaExpr/lambda.cup}{\texttt{lambda.cup}}.  
Diese Grammatik beschreibt drei Arten von Ausdrücken:
\begin{enumerate}
\item $\lambda$-Ausdrücke haben syntaktisch die Form
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{[$x_1$, $\cdots$, $x_n$] |-> $e$}.
      \\[0.2cm]
      Ein solcher Ausdruck steht für eine Funktion, die $n$ Argumente $x_1$, $\cdots$, $x_n$
      verarbeitet und als Ergebnis den Ausdruck $e$ zurück liefert, wobei der Ausdruck $e$ im
      Allgemeinen von den Parametern $x_1$, $\cdots$, $x_n$ abhängen wird.   Ein konkretes Beispiel
      wäre etwa der $\lambda$-Ausdruck
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{[x, y] |-> [x, y, x]}.
\item Zusätzlich sind als Ausdrücke Variablen-Namen zugelassen.
\item Außerdem sind auch Listen von Ausdrücken möglich, wobei diese Listen in eckigen Klammern
      eingefasst werden.  Diese Listen können dabei beliebig geschachtelt sein.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    terminal MAPSTO, LBRACKET, RBRACKET, COMMA, IDENTIFIER;
    
    nonterminal expr, exprList, lambdaDefinition, identifierList;
    
    expr ::= lambdaDefinition
          |  IDENTIFIER  
          |  LBRACKET exprList RBRACKET
          ;   
    lambdaDefinition
         ::= LBRACKET identifierList RBRACKET MAPSTO expr
          ;
    identifierList
         ::= IDENTIFIER COMMA identifierList 
          |  IDENTIFIER
          ;
    exprList
         ::= expr COMMA exprList
          |  expr
          ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Eine \textsc{Cup}-Grammatik für $\lambda$-Ausdrücke.}
\label{fig:lambda.g}
\end{figure}

Versuchen wir mit \textsc{Cup} einen Parser für diese Grammatik zu erzeugen, so erhalten wir
verschiedene Shift/Reduce-Konflikte.  Diese Konflikte entstehen in dem Zustand Nummer 6, der in
Abbildung \ref{fig:lambda.g:state6} gezeigt ist.  Da auf eine \textsl{expr} ein ``\texttt{,}''
folgen kann, dieses aber in dem Zustand gleichzeitig auch auf den Stack geschoben werden kann, ist
nicht klar, ob mit der Regel 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{expr} \rightarrow \mathtt{IDENTIFIER}$
\\[0.2cm]
reduziert werden darf, wenn das Look-Ahead-Token ein Komma ist.  Um zu entscheiden, ob der Parser
versucht eine Liste von \texttt{IDENTIFIER}n zu parsen, müsste der Parser bis zu dem Token
\texttt{MAPSTO} schauen können.  Wenn später ein solches Token noch kommt, dann würde der Parser im
Zustand 6 versuchen, eine \texttt{identifierList} zu parsen und das Komma sollte auf den Stack
geschoben werden.  Andernfalls könnte mit der Regel 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{expr} \rightarrow \mathtt{IDENTIFIER}$
\\[0.2cm]
reduziert werden. Leider lässt ein LR-Parser-Generator nicht zu, dass wir den noch ungelesenen Teil
der Eingabe inspizieren.  Wir müssen daher eine andere Lösung suchen.

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    lalr_state [6]: {
      [identifierList ::= IDENTIFIER (*) COMMA identifierList , {RBRACKET }]
      [expr ::= IDENTIFIER (*) , {RBRACKET COMMA }]
      [identifierList ::= IDENTIFIER (*) , {RBRACKET }]
    }
\end{Verbatim}
 \vspace*{-0.3cm}
\caption{Der Zustand mit der Nummer 6 zu der Grammatik aus Abbildung \ref{fig:lambda.g}}
\label{fig:lambda.g:state6}
\end{figure}

Wir können den Shift/Reduce-Konflikt lösen, indem wir die Grammatik wie in der in Abbildung
\ref{fig:lambda-generalized.cup} gezeigten Grammatik
\href{https://github.com/karlstroetmann/Formal-Languages/tree/master/Cup/LambdaExpr/lambda-generalized.cup}{\texttt{lambda-generalized.cup}}
 \textbf{verallgemeinern}.  Diese Grammatik lässt auch
Ausdrücke zu, bei denen in der Argument-Liste nicht nur Variablen-Namen enthält, sondern Ausdrücke
beliebiger Komplexität.  Damit beschreibt diese Grammatik eine Sprache, die eigentlich zu allgemein
ist.  Es ist aber ein leichtes, später den resultierenden Syntax-Baum drauf hin zu untersuchen, ob
in der Parameter-Liste tatsächlich nur Variablen stehen oder nicht.  Daher bietet eine solche
Verallgemeinerung der Grammatik eine praktische Möglichkeit um Shift/Reduce-Konflikte zu lösen.

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm, 
                  xrightmargin  = 0.8cm,
                ]
    terminal    MAPSTO, LBRACKET, RBRACKET, COMMA, IDENTIFIER;
    
    nonterminal expr, exprList, lambdaDefinition;
    
    expr ::= lambdaDefinition
          |  IDENTIFIER  
          |  LBRACKET exprList RBRACKET
          ;
    
    lambdaDefinition
         ::= LBRACKET exprList RBRACKET MAPSTO expr
          ;
    
    exprList
         ::= expr COMMA exprList
          |  expr
          ;
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die verallgemeinerte Grammatik für $\lambda$-Ausdrücke.}
\label{fig:lambda-generalized.cup}
\end{figure}
\vspace*{\fill}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "formal-languages"
%%% End: 
