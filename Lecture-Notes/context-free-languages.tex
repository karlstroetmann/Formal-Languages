\chapter{Context-Free Languages \label{chap:kontextfrei}}

\begin{figure}[h] 
\centering
  \includegraphics[width=10.5cm]{Abbildungen/noam-chomsky.png}
\caption{The father of context-free languages, Noam Chomsky.}
\label{fig:noam-chomsky.png}
\end{figure}

In this chapter we present the notion of a
\href{http://en.wikipedia.org/wiki/Context-free_language}{\emph{context-free language}}.
This concept is much more powerful than the notion of a regular language.  The syntax of most modern
programming languages can be described by a context-free language.  Furthermore, checking whether a
string is a member of a context-free language structures the string into a recursive structure known
as a \blue{parse tree}.  These parse trees are the basis for understanding the meaning of a
string that is to be interpreted as a program fragment.  A program that checks whether a given
string is an element of a context-free language is called a \blue{parser}.  The task of a parser is to build
a \blue{parse tree} from a given string.  Parsing is therefore the first step in an interpreter or a compiler.
In this chapter, we first define the notion of context-free languages.  Next, we discuss parse
trees.  We conclude this chapter by introducing \blue{top down parsing}, which is one of the less complex
algorithms that are available for parsing a string.

\section{Context-Free Grammars \label{context-free}}
Context-free languages are used to describe programming languages.
Context-free languages are formal languages like regular languages, but they are much more expressive than
regular languages.
When we process a program, we not only want
decide whether the program is syntactically correct, but we also want to understand the \emph{structure}
of the program.  The process of \emph{structuring} is also referred to as \blue{parsing}
and the program that does this structuring is called a
\blue{parser}.  As input a parser usually does not receive the
text of a program, but instead a sequence of so-called \blue{terminals}, which are also called
\blue{tokens}.  These tokens are generated by a scanner, which uses regular expressions to split the program text
into single words, which we call tokens in this context.

The parser receives a sequence of tokens from the scanner and has the task of constructing a so-called
\blue{syntax tree}.  For this purpose the parser uses a
grammar which specifies how the input is to be structured.  As an example, consider parsing arithmetic
expressions.  We define the set \textsl{arithExpr} of arithmetic expressions inductively.  
In order to correctly represent the structure of arithmetic expressions, we define
simultaneously the sets \textsl{Product} and \textsl{Factor}.
The set \textsl{Product} encompasses arithmetic expressions representing products and quotients, while the set
\textsl{Factor} includes numbers and parenthesized expressions. Defining these additional sets is crucial for
ensuring the correct precedence of operators.  The basic building blocks of arithmetic expressions are
variables, numbers, the operator symbols 
``\texttt{+}'', ``\texttt{-}'', ``\texttt{*}'', ``\texttt{/}'',
and the bracket symbols ``\texttt{(}'' and ``\texttt{)}''.  Based on these symbols
the inductive definition of the sets \textsl{Factor}, \textsl{Product} and
\textsl{arithExpr} proceeds as follows:
\begin{enumerate}
\item Each number is a factor:
      \\[0.2cm]
      \hspace*{1.3cm}
      $C \in \textsc{Number} \Rightarrow C \in \textsl{factor}$.
\item Each variable is a factor:
      \\[0.2cm]
      \hspace*{1.3cm}
      $V \in \textsc{Variable} \Rightarrow V \in \textsl{factor}$.
\item If $A$ is an arithmetic expression and we enclose this expression in parentheses
      we get an expression that we can use as a factor:
      \\[0.2cm]
      \hspace*{1.3cm}
      $A \in \textsl{arithExpr} \Rightarrow \quoted{(}A\quoted{)} \in \textsl{factor}$. 
      \\[0.2cm]
      A note on notation: In the preceding formula, \( A \) serves as a meta-variable representing an arbitrary
      arithmetic expression. The strings ``\texttt{(}'' and ``\texttt{)}'' should be taken literally and are
      thus enclosed in quotation marks. These quotation marks are not part of the arithmetic expression; they
      are used solely for notational clarity. 
\item If $F$ is a factor, then $F$ is also a product:
      \\[0.2cm]
      \hspace*{1.3cm}
      $F \in \textsl{factor} \Rightarrow F \in \textsl{product}$.
\item If $P$ is a product and if $F$ is a factor, then the strings 
      $P \quoted{*} F$ and $P \quoted{/} F$ are also products:
      \\[0.2cm]
      \hspace*{1.3cm}
      $P \in \textsl{product} \wedge F \in \textsl{factor} \Rightarrow 
       P \squoted{*} F \in \textsl{product} \;\wedge\; P \squoted{/} F \in \textsl{product}$.
\item Each product is also an arithmetic expression
      \\[0.2cm]
      \hspace*{1.3cm}
      $P \in \textsl{product} \Rightarrow P \in \textsl{arithExpr}$.
\item If $A$ is an arithmetic expression and $P$ is a product, then
      the strings $A \quoted{+} P$ and $A \quoted{-} P$ are arithmetic expressions:
      \\[0.2cm]
      \hspace*{1.3cm}
      $A \in \textsl{arithExpr} \wedge P \in \textsl{product} \Rightarrow
       A \squoted{+} P \in \textsl{arithExpr} \;\wedge\; A \squoted{-} P \in \textsl{arithExpr}$.
\end{enumerate}
The sets \textsl{factor}, \textsl{product}, and \textsl{arithExpr} are defined above through mutual
recursion. This definition can be succinctly represented using what are known as \blue{grammar rules}. 
\begin{eqnarray*}
  \textsl{arithExpr} & \rightarrow & \textsl{arithExpr} \quoted{+} \textsl{product}  \\
  \textsl{arithExpr} & \rightarrow & \textsl{arithExpr} \quoted{-} \textsl{product}  \\
  \textsl{arithExpr} & \rightarrow & \textsl{product}                                \\[0.1cm]
  \textsl{product} & \rightarrow & \textsl{product} \quoted{*} \textsl{factor}     \\
  \textsl{product} & \rightarrow & \textsl{product} \quoted{/} \textsl{factor}     \\
  \textsl{product} & \rightarrow & \textsl{factor}                                 \\[0.1cm]
  \textsl{factor} & \rightarrow & \quoted{(} \textsl{arithExpr} \quoted{)}        \\
  \textsl{factor} & \rightarrow & \textsc{Variable}                               \\
  \textsl{factor} & \rightarrow & \textsc{Number} 
\end{eqnarray*}
Expressions on the left hand side of a grammar rule are known as \blue{syntactic variables}\index{syntactic
  variable} or \blue{non-terminals}\index{non-terminal}, while all other expressions are termed
\blue{terminals}\index{terminal}. We adopt the convention of writing syntactic variables in lowercase to align
with the syntax used by the parser generator \blue{\textsc{Ply}}, which we will
explore later. However, it is worth noting that in much of the existing literature, the convention is reversed:
syntactic variables are typically capitalized, and terminals are presented in lowercase. Additionally,
syntactic variables may occasionally be referred to as \blue{syntactic categories}\index{syntactic category}. 

In the example, \textsl{arithExpr}, \textsl{product}, and \textsl{factor} function as the \blue{syntactic
  variables}. The remaining elements, namely \textsc{Number}, \textsc{Variable}, and the symbols
``\texttt{+}'', ``\texttt{-}'', ``\texttt{*}'', ``\texttt{/}'', ``\texttt{(}'', and ``\texttt{)}'', are the
\blue{terminals} or \blue{tokens}. These terminals are precisely the characters that are not found on the left
side of any grammar rule. Terminals can be classified into two types: 
\begin{enumerate}
\item Operator symbols and separators, like ``\texttt{/}'' and ``\texttt{(}'', are used in their literal sense.
\item Tokens such as \textsc{Number} or \textsc{Variable} carry associated values. For \textsc{Number}, the value is numeric; for \textsc{Variable}, it is a string representing the variable's name. To distinguish them from syntactic variables, these token types are always written in uppercase letters.
\end{enumerate}
Grammar rules are often expressed in a notation more compact than that introduced previously. For the given
example, the compact notation is as follows:

\begin{eqnarray*}
  \textsl{arithExpr} & \rightarrow & \textsl{arithExpr} \;\quoted{+}\; \textsl{product} \\
                     & \mid        & \textsl{arithExpr} \;\quoted{-}\; \textsl{product} \\
                     & \mid        & \textsl{product}                                   \\
  \textsl{product} & \rightarrow & \textsl{product} \;\quoted{*}\; \textsl{factor}      \\
                   & \mid        & \textsl{product} \;\quoted{/}\; \textsl{factor}      \\
                   & \mid        & \textsl{factor}                                      \\
  \textsl{factor} & \rightarrow & \squoted{(}\,\; \textsl{arithExpr} \;\squoted{)}      \\
                  & \mid        & \textsc{Number}                                    \\
                  & \mid        & \textsc{Variable}
\end{eqnarray*}
In this format, individual alternatives within a rule are demarcated by the metacharacter \squoted{|}. Building
on the preceding example, we now introduce the formal definition of a
\href{http://en.wikipedia.org/wiki/Context-free_grammar}{context-free grammar}. 

\begin{Definition}[Context-Free Grammar]
A \blue{context-free grammar} \index{context-free grammar} \( G \) is a quadruple 
\[ 
   G = \langle V, T, R, S \rangle,
\]
where
\begin{enumerate}
\item \( V \) is a set called \blue{syntactic variables} \index{syntactic variables} or \blue{non-terminals}\index{non-terminals}. In the preceding example, we have
      \[
      V = \{ \textsl{arithExpr}, \textsl{product}, \textsl{factor} \}.
      \]

\item \( T \) is a set referred to as \blue{terminals}\index{terminals} or \blue{tokens}\index{tokens}. The sets \( T \) and \( V \) are disjoint, hence
      \[
      T \cap V = \emptyset.
      \]
      For the aforementioned example, we have
      \[
      T = \{ \textsc{Number}, \textsc{Variable}, \quoted{+}, \quoted{-}, \quoted{*}, \quoted{/}, \quoted{(}, \quoted{)} \}.
      \]

\item \( R \) is a set of \blue{grammar rules}\index{grammar rule}. Formally, a grammar rule is a pair \( \langle A, \alpha \rangle \) where:
      \begin{enumerate}
      \item The first component, \( A \), is a syntactic variable:
            \[
            A \in V.
            \]
      \item The second component, \( \alpha \), is a string composed of syntactic variables and terminals:
            \[
            \alpha \in (V \cup T)^*.
            \]
      \end{enumerate}
      Consequently, we have
      \[
      R \subseteq V \times (V \cup T)^*.
      \]
      A rule \( \langle x, \alpha \rangle \) is typically written as
      \[
      x \rightarrow \alpha.
      \]
      In the example, the first rule is
      \[
      \textsl{arithExpr} \rightarrow \textsl{arithExpr} \quoted{+} \textsl{product},
      \]
      which formally corresponds to the pair
      \[
      \bigl\langle \textsl{arithExpr}, [\textsl{arithExpr}, \quoted{+}, \textsl{product}] \bigr\rangle.
      \]

\item \( S \) is a member of \( V \) designated as the \blue{start symbol}\index{start symbol}. In the given example, \textsl{arithExpr} is the start symbol.
      \eox
\end{enumerate}
\end{Definition}

\noindent
When presenting a grammar, we typically enumerate the grammar rules and apply the following conventions to identify the start symbol and to differentiate between syntactic variables and terminals:
\begin{enumerate}
\item The start symbol is the syntactic variable appearing on the left side of the first rule.
\item Symbols enclosed within quotes are terminals.
\item Names beginning with an uppercase letter are terminals.
\item Names beginning with a lowercase letter are syntactic variables.
\end{enumerate}

\exampleEng
The set of grammar rules below defines arithmetic expressions constructed from numbers, variables, and the binary operators \quoted{+}, \quoted{-}, \quoted{\(\cdot\)}, and \quoted{/}.

\begin{eqnarray*}
  \textsl{arithExpr} & \rightarrow & \textsl{arithExpr} \quoted{+} \textsl{product}  \\
                     & \mid        & \textsl{arithExpr} \quoted{-} \textsl{product}  \\
                     & \mid        & \textsl{product}                                \\[0.2cm]
  \textsl{product}   & \rightarrow & \textsl{product} \quoted{\(\cdot\)} \textsl{factor} \\
                     & \mid        & \textsl{product} \quoted{/} \textsl{factor}     \\
                     & \mid        & \textsl{factor}                                 \\[0.2cm]
  \textsl{factor}    & \rightarrow & \squoted{(} \textsl{arithExpr} \squoted{)}     \\
                     & \mid        & \textsc{Number}                                 \\
                     & \mid        & \textsc{Variable}
\end{eqnarray*}
In this case, the following observations can be made:
\begin{enumerate}
\item The start symbol is \textsl{arithExpr}, as it is the syntactic variable on the left in the first grammar rule.
\item \textsl{arithExpr}, \textsl{product}, and \textsl{factor} are recognized as syntactic variables because they start with a lowercase letter.
\item The symbols \quoted{+}, \quoted{-}, \quoted{\(\cdot\)}, and \quoted{/} are identified as terminals since they are enclosed in quotes.
\item \textsc{Number} and \textsc{Variable} are terminals, indicated by their initial uppercase letters.
\end{enumerate}

\subsection{Derivations}
Next, we aim to identify the \blue{language} defined by a given grammar \( G \). For this purpose, we first
define the concept of a \blue{derivation step}\index{derivation-step}. Consider the following: 
\begin{enumerate}
\item \( G = \langle V, T, R, S \rangle \) is a grammar,
\item \( b \) is a syntactic variable in \( V \),
\item \( \alpha b \gamma \) is a string composed of terminals and syntactic variables from \( (V \cup T)^* \), which includes the variable \( b \), and
\item \( (b \rightarrow \delta) \) is a rule in \( R \).
\end{enumerate}
Under these conditions, the string \( \alpha b \gamma \) can undergo a derivation step to transform into the
string \( \alpha \delta \gamma \). This process involves substituting one occurrence of the syntactic variable
$b$ with the right-hand side $\delta$ of the rule $b \rightarrow \delta$. We denote this derivation
step as 
\\[0.2cm]
\hspace*{1.3cm}
$\alpha b \gamma \Rightarrow_G \alpha \delta \gamma$.
\\[0.2cm]
When the grammar \( G \) is clear from the context, we may drop the subscript \( _G \) and simply use \( \Rightarrow \) instead of \( \Rightarrow_G \). The transitive and reflexive closure of the relation \( \Rightarrow_G \) is indicated by \( \Rightarrow_G^* \). To specify that the derivation of string \( w \) from the non-terminal $b$ encompasses $n$ derivation steps, we write:

We illustrate with an example:
\begin{eqnarray*}
\textsl{arithExpr} 
& \Rightarrow & \textsl{arithExpr} \quoted{+} \textsl{product}  \\
& \Rightarrow & \textsl{product} \quoted{+} \textsl{product}  \\
& \Rightarrow & \textsl{product} \quoted{$\cdot$} \textsl{factor} \quoted{+} \textsl{product} \\
& \Rightarrow & \textsl{factor} \quoted{$\cdot$} \textsl{factor} \quoted{+} \textsl{product}  \\
& \Rightarrow & \textsc{Number} \quoted{$\cdot$} \textsl{factor} \quoted{+} \textsl{product}  \\
& \Rightarrow & \textsc{Number} \quoted{$\cdot$} \textsc{Number} \quoted{+} \textsl{product}  \\
& \Rightarrow & \textsc{Number} \quoted{$\cdot$} \textsc{Number} \quoted{+} \textsl{factor}   \\
& \Rightarrow & \textsc{Number} \quoted{$\cdot$} \textsc{Number} \quoted{+} \textsc{Number}   
\end{eqnarray*}
Hence, we have demonstrated that
\[
\hspace*{1.3cm}
\textsl{arithExpr} \Rightarrow^* \textsc{Number} \quoted{$\cdot$} \textsc{Number} \quoted{+} \textsc{Number}
\]
is valid. To be more precise, we could express this as
\[
\hspace*{1.3cm}
\textsl{arithExpr} \Rightarrow^8 \textsc{Number} \quoted{$\cdot$} \textsc{Number} \quoted{+} \textsc{Number}
\]
since the derivation comprises eight steps. By substituting the terminal \textsc{Number} with distinct numerals, we demonstrate that the string
\[
\hspace*{1.3cm}
2 \cdot 3 + 4
\]
is an arithmetic expression. Generally, the language \( L(G) \) defined by a grammar \( G \) is the set of all
strings that are exclusively composed of terminals and can be derived from the start symbol \( S \) of the
grammar; that is, we define
\[
\hspace*{1.3cm}
L(G) := \{ w \in T^* \mid S \Rightarrow^* w \}.
\]


\exampleEng
The language
\[
\hspace*{1.3cm}
L = \{ (^n )^n \mid n \in \mathbb{N} \}
\]
is generated by the grammar
\[
\hspace*{1.3cm}
G = \langle \{s\}, \{ \squoted{(}, \squoted{)} \}, R, \textsl{s} \rangle,
\]
where the set of rules \( R \) is defined as:
\[
\hspace*{1.3cm}
\textsl{s} \rightarrow \squoted{(} \textsl{s} \squoted{)} \mid \lambda.
\]

\proofEng
We first establish that each string \( w \) in \( L \) can be derived from the start symbol \( \textsl{s} \):
\[
\hspace*{1.3cm}
\text{If } w \in L, \text{ then } \textsl{s} \Rightarrow^* w.
\]
Let \( w_n = (^n)^n \). We use induction on \( n \in \mathbb{N} \) to show that \( w_n \in L(G) \).
\begin{enumerate}
\item[\textbf{B.C.:}] \( n=0 \).

            We have \( w_0 = \lambda \). Since the grammar includes the rule \( s \rightarrow \lambda \), it follows that
            \[
            \hspace*{1.3cm}
            \textsl{s} \Rightarrow \lambda,
            \]
            and thus \( w_0 \in L(G) \).

\item[\textbf{I.S.:}] \( n \mapsto n + 1 \).

            The string \( w_{n+1} \) has the form \( w_{n+1} = \squoted{(}w_n\squoted{)} \), where \( w_n \) is also in \( L \).
            By the inductive hypothesis, there exists a derivation for \( w_n \):
            \[
            \hspace*{1.3cm}
            \textsl{s} \Rightarrow^* w_n.
            \]
            Thus, we obtain the derivation
            \[
            \hspace*{1.3cm}
            \textsl{s} \Rightarrow \squoted{(}\textsl{s}\squoted{)} \Rightarrow^* \squoted{(} w_n \squoted{)} = w_{n+1},
            \]
            which confirms \( w_{n+1} \in L(G) \).
\end{enumerate}
Next, we prove that any string \( w \) derived from \( \textsl{s} \) belongs to \( L \), using induction on the number \( n \) of derivation steps:
\begin{enumerate}
\item[\textbf{B.C.:}] \( n = 1 \).

            The sole derivation from terminals that is one step long is
            \[
            \hspace*{1.3cm}
            \textsl{s} \Rightarrow \lambda.
            \]
            Hence, \( w = \lambda \), and since \( \lambda = (^0)^0 \) belongs to \( L \), we deduce \( w \in L \).

\item[\textbf{I.S.:}] \( n \mapsto n+1 \).

            For a derivation exceeding one step, it must begin as
            \[
            \hspace*{1.3cm}
            \textsl{s} \Rightarrow \squoted{(} \textsl{s} \squoted{)} \Rightarrow^n w.
            \]
            This implies
            \[
            \hspace*{1.3cm}
            w = \squoted{(}v\squoted{)} \quad \text{and} \quad \textsl{s} \Rightarrow^n v.
            \]
            By the inductive hypothesis, \( v \in L \). Therefore, there exists a \( k \in \mathbb{N} \) such that \( v = (^k)^k \).
            Consequently,
            \[
            \hspace*{1.3cm}
            w = \squoted{(}v\squoted{)} = ((^k)^k) = (^{k+1})^{k+1} \in L. 
            \] \qed
\end{enumerate}

\exerciseEng
We define $\Sigma = \{ \squoted{A}, \squoted{B} \}$ and define the language $L$ as the
set of words $w\in\Sigma^*$ in which the letters \squoted{A} and \squoted{B} occur with the
same frequency:
\\[0.2cm]
\hspace*{1.3cm}
$L := \bigl\{ w \in \Sigma^* \mid \textsl{count}(w,\squoted{A}) = \textsl{count}(w,\squoted{B})\bigr\}$
\\[0.2cm]
Define a grammar $G$ such that $L = L(G)$.
\eox

\exerciseEng
Define $\Sigma := \{ \squoted{A}, \squoted{B} \}$. 
In the previous chapter, we have already defined the reversal of a string 
$w = c_1 c_2 \cdots c_{n-1} c_n \in \Sigma^*$ as the string
\\[0.2cm]
\hspace*{1.3cm}
$w^R := c_n c_{n-1} \cdots c_2 c_1$.
\\[0.2cm]
A string $w \in \Sigma^*$ is called a
\href{http://en.wikipedia.org/wiki/Palindrome}{\blue{palindrome}} \index{palindrome} if the string is identical to its
reversal, i.e.~if
\\[0.2cm]
\hspace*{1.3cm}
$w = w^R$
\\[0.2cm]
holds true.  For example, the strings 
\\[0.2cm]
\hspace*{1.3cm}
$w_1 = \mathtt{ABABA}$ \quad and \quad $w_2 = \mathtt{ABBA}$
\\[0.2cm]
are both palindromes, while the string \texttt{ABB} is not a palindrome. The 
\blue{language of palindromes} $L_\mathrm{palindrome}$ is the set of all 
strings in $\Sigma^*$ that are palindromes, i.e.~we have
\\[0.2cm]
\hspace*{1.3cm}
$L_\mathrm{palindrome} := \bigr\{ w \in \Sigma^* \mid w = w^R \bigr\}$.
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item Prove that the language $L_\mathrm{palindrome}$ is a context-free language.
\item Prove that the language $L_\mathrm{palindrome}$ is not regular.  \eox
\end{enumerate}
\renewcommand{\labelenumi}{\arabic{enumi}.}

 

% \exerciseStar
% Es sei $\Sigma := \{ \squoted{A}, \squoted{B} \}$.  Wir definieren die Menge $L$ als die
% Menge der Strings $s$, die sich \underline{nicht} in der Form $s = ww$ schreiben lassen:
% \\[0.2cm]
% \hspace*{1.3cm}
% $L = \bigl\{ s \in \Sigma^* \mid \neg(\exists w\in\Sigma^*: s = ww)\bigr\}$.
% \\[0.2cm]
% Geben Sie eine kontextfreie Grammatik $G$ an, die diese Sprache erzeugt.
% \eox

% \solution 
% Die Lösung dieser Aufgabe ist so umfangreich, dass wir unsere Überlegungen in vier Teile aufspalten.
% \vspace{0.2cm}

% \noindent
% \textbf{Vorüberlegung \texttt{I}}: String-Notationen \\
% Für einen String $s$ bezeichnen wir mit $s[i]$ den $i$-ten Buchstaben und mit
% $s[i\!:\!j]$ den Teilstring, der sich vom $i$-ten Buchstaben bis zum $j$-ten Buchstaben einschließlich
% erstreckt.  Bei der Nummerierung beginnen wir mit 1.
% Dann gilt
% \begin{enumerate}
% \item $|s[i\!:\!j]| = j - i + 1$

%       Von der Notwendigkeit, hier eine 1 zu addieren, können wir uns dadurch überzeugen, wenn wir den
%       Fall $i = j$ betrachten, denn $s[i\!:\!i]$ ist der Teilstring, der nur aus dem $i$-ten
%       Buchstaben besteht und der hat natürlich die Länge 1.
% \item $s[i\!:\!j][k] = s[i + k - 1]$.

%       Dass in diesem Fall 1 subtrahiert werden muss, sehen Sie, wenn Sie den Fall $k=1$ betrachten,
%       denn der erste Buchstabe des Teilstrings $s[i\!:\!j]$ ist natürlich der $i$-te
%       Buchstabe von $s$.
% \item Hat ein Wort $s \in \Sigma^*$ eine ungerade Länge, gilt also
%       \\[0.2cm]
%       \hspace*{1.3cm}
%       $|s| = 2 \cdot n +1$ \quad für ein $n \in \mathbb{N}$,
%       \\[0.2cm]
%       so liegt der Buchstabe $s[n + 1]$ in der Mitte von $s$.  Um dies einzusehen,
%       betrachten wir die Teilstrings $s[1:n]$ und $s[n+2:2\cdot n+1]$, die links und rechts
%       von $s[n+1]$ liegen:
%       \\[0.2cm]
%       \hspace*{1.3cm}
%       $\underbrace{s[1] \cdots s[n]}_{s[1:n]} s[n+1] \underbrace{s[n+2] \cdots s[2 \cdot n
%         +1]}_{s[n+2:2\cdot n+1]}$
%       \\[0.2cm]
%       Offenbar sind diese Teilstrings gleich lang, denn wir haben
%       \\[0.2cm]
%       \hspace*{1.3cm}
%       $|s[1:n]| = n$ \quad und \quad $|s[n+2:2\cdot n+1]| = 2 \cdot n + 1 - (n+2) + 1 = n$.
%       \\[0.2cm]
%       Also liegt der Buchstabe $s[n+1]$ tatsächlich in der Mitte von $s$.  

%       Für einen String $s$ ungerader Länge definieren wir $\hat{s}$ als den Buchstaben,
%       der in der Mitte von $s$ liegt:
%       \\[0.2cm]
%       \hspace*{1.3cm}
%       $\hat{s} := s[n+1]$ \quad falls $|s| = 2 \cdot n + 1$.
% \end{enumerate}

% \noindent
% \textbf{Vorüberlegung \texttt{II}}:
% Zunächst ist klar, dass alle Strings deren Längen ungerade sind, in der Sprache $L$ liegen,
% denn jeder String der Form $s=ww$ hat offenbar die Länge 
% \\[0.2cm]
% \hspace*{1.3cm}
% $|s| = |w| + |w| = 2\cdot |w|$
% \\[0.2cm]
% und das ist eine gerade Zahl.

% Gilt nun $s \in L$ mit $|s| = 2 \cdot n$, so lässt sich $s$ in zwei Teile $u$ und $v$ gleicher
% Länge zerlegen:
% \\[0.2cm]
% \hspace*{1.3cm}
% $s = uv \quad \mbox{mit} \quad u = s[1\!:\!n], \quad v = s[n+1\!:\!2 \cdot n]
%   \quad \mbox{und} \quad u \not= v
% $.
% \\[0.2cm]
% Aus der Ungleichung $u \not= v$ folgt, dass es mindestens einen Index $k \in \{1,\cdots,n\}$ gibt,
% so dass sich die Strings $u$ und $v$ an diesem Index unterscheiden:
% \\[0.2cm]
% \hspace*{1.3cm}
% $u[k] \not= v[k]$. 
% \\[0.2cm]
% Der Trick besteht jetzt darin, den String $s$ in zwei Teilstrings $x$ und $y$ aufzuteilen,
% von denen der eine 
% Teilstring in der Mitte den Buchstaben $u[k]$ enthält, während der andere Teilstring in der Mitte den
% Buchstaben $v[k]$ enthält.  Wir definieren
% \\[0.2cm]
% \hspace*{1.3cm}
% $x := s[1\!:\!2 \cdot k - 1] \quad \mbox{und} \quad y := s[2 \cdot k\!:\! 2 \cdot n]$.
% \\[0.2cm]
% Für die Längen von $x$ und $y$ folgt daraus
% \\[0.2cm]
% \hspace*{1.3cm}
% $|x| = 2 \cdot k - 1 \quad \mbox{und} \quad |y| = 2 \cdot (n - k) + 1$. 
% \\[0.2cm]
% Dann gilt einerseits
% \\[0.2cm]
% \hspace*{1.3cm}
% $x[k] = s[k] = u[k]$
% \\[0.2cm]
% und andererseits haben wir
% \\[0.2cm]
% \hspace*{1.3cm}
% $
% \begin{array}[t]{lcl}
%     y[n - k + 1] & = & s[2 \cdot k\!:\! 2 \cdot n][n - k + 1] \\[0.1cm]
%                  & = & s[2 \cdot k + (n - k + 1) - 1]     \\[0.1cm]
%                  & = & s[n + k]                           \\[0.1cm]
%                  & = & s[n+1\!:\! 2 \cdot n][k]               \\[0.1cm]
%                  & = & v[k]               
% \end{array}
% $
% \\[0.2cm]
% Die beiden Buchstaben $u[k]$ und $v[k]$, die dafür verantwortlich sind, dass $u$ und $v$ verschieden
% sind, befinden sich also genau in der Mitte der Strings $x$ und $y$.
% \vspace{0.3cm}

% \noindent
% \textbf{Bemerkung}: Wir haben soeben Folgendes gezeigt:  Falls $s \in L$ mit $|s| = 2 \cdot n$ ist, so lässt
% sich $s$ so in zwei Strings $x$ und $y$ aufspalten, dass die Buchstaben, die jeweils in
% der Mitte von $x$ und $y$ liegen, unterschiedlich sind:
% \\[0.2cm]
% \hspace*{1.3cm}
% $s \in L \wedge |s| = 2 \cdot n \rightarrow \exists x,y \in \Sigma^*: \bigl(
%  s = xy \wedge \hat{x} \not= \hat{y}\bigr)$.
% \vspace{0.3cm}

% \noindent
% \textbf{Vorüberlegung \texttt{III}}:
% Wir überlegen uns nun, dass auch die Umkehrung des in der letzten Bemerkung angegebenen
% Zusammenhangs gilt:  Sind $x, y \in \Sigma^*$ mit ungerader Länge und gilt 
% $\hat{x} \not= \hat{y}$, so liegt der String $xy$ in der Sprache $L$:
% \\[0.2cm]
% \hspace*{1.3cm}
% $x, y \in \Sigma^* \wedge |x| = 2 \cdot m + 1 \wedge |y| = 2 \cdot n + 1 \wedge \hat{x}
% \not= \hat{y} \rightarrow xy \in L$. \hspace*{\fill} $(*)$
% \\[0.2cm]

% \noindent
% \textbf{Beweis}: Wir definieren $s$ als die Konkatenation von $x$ und $y$, also $s := xy$.
% Für die Länge von $s$ gilt dann
% \\[0.2cm]
% \hspace*{1.3cm}
% $|s| = 2 \cdot (m + n + 1)$.
% \\[0.2cm]
% Wir werden zeigen, dass
% \\[0.2cm]
% \hspace*{1.3cm}
% $s[m+1] \not= s[(m+n+1) + (m+1)]$
% \\[0.2cm]
% gilt.  Spalten wir $s$ in zwei gleich lange Teile $u$ und $v$ auf, definieren also 
% \\[0.2cm]
% \hspace*{1.3cm}
% $u := s[1:m+n+1]$ \quad und \quad
% $v := s[m+n+2: 2\cdot(m+n+1)]$, 
% \\[0.2cm]
% so werden wir gleich sehen, dass
% \\[0.2cm]
% \hspace*{1.3cm}
% $u[m+1] = s[m+1] \not= s[(m+n+1) + (m+1)] = v[m+1]$,
% \\[0.2cm]
% gilt, woraus  $u \not= v$ und damit $s = uv \in L$ folgt. 
% \vspace{0.3cm}

% \noindent
% Es bleibt der Nachweis von  $s[m+1] \not= s[(m+n+1) + (m+1)]$ zu erledigen:
% \\[0.2cm]
% \hspace*{1.3cm}
% $
% \begin{array}[t]{lcll}
%   s[(m+n+1) + m + 1] &     = & (xy)[(m+n+1) + m + 1]  & \mbox{wegen $s = xy$} \\
%                      &     = & y[n+1]  & \mbox{denn $|x| = 2 \cdot m + 1$}    \\
%                      &     = & \hat{y} & \mbox{denn $|y| = 2 \cdot n + 1$}    \\
%                      & \not= & \hat{x}                                        \\
%                      &     = & x[m+1]  & \mbox{denn $|x| = 2 \cdot m + 1$}    \\
%                      &     = & s[m+1]  & \mbox{wegen $s = xy$}.
% \end{array}
% $
% \\[0.2cm]
% Damit ist der Beweis der Behauptung $(*)$ abgeschlossen.
% \vspace{0.2cm}

% \noindent
% \textbf{Aufstellen der Grammatik}:
% Fassen wir die letzten beiden Vorüberlegungen zusammen, so stellen wir fest, dass die
% Sprache $L$ aus genau den Wörtern besteht, die entweder 
% eine ungerade Länge haben, oder die aus Paaren von Strings ungerader Länge bestehen, die
% in der Mitte unterschiedliche Buchstaben haben:
% \\[0.2cm]
% \hspace*{1.3cm}
% $\begin{array}[t]{lcl}
%   L & =    & \bigl\{ s \in \Sigma^* \big|\; |s| \,\texttt{\%}\, 2 = 1 \bigr\}  \\[0.1cm]
%     & \cup & \bigl\{ s \in \Sigma^* \big|\; \exists x,y \in \Sigma^*: 
%                              s = xy \wedge |x| \,\texttt{\%}\, 2 = 1 
%                                     \wedge |y| \,\texttt{\%}\, 2 = 1  \wedge \hat{x} \not= \hat{y} \bigr\} 
%  \end{array}$
% \\[0.2cm]
% Damit lässt sich die Menge $L$ durch die folgende Grammatik beschreiben
% \\[0.2cm]
% \hspace*{1.3cm}
% $G = \langle \{ s, a, b, x, u \}, \{ \squoted{A}, \squoted{B} \}, R, s \rangle$,
% \\[0.2cm]
% wobei die Menge der Regeln wie folgt gegeben ist:
% \\[0.2cm]
% \hspace*{1.3cm}
% $ 
% \begin{array}[t]{lcl}
%   s & \rightarrow & u \mid a b \mid  b a \\[0.3cm]
%   a & \rightarrow & \squoted{A} \mid x a x         \\[0.3cm]
%   b & \rightarrow & \squoted{B} \mid x b x         \\[0.3cm]
%   u & \rightarrow & x \mid u x x         \\[0.3cm]
%   x & \rightarrow & \squoted{A} \mid \squoted{B}
% \end{array}$
% \\[0.2cm]
% Wir diskutieren die verschiedenen syntaktischen Variablen.
% \begin{enumerate}
% \item $L(x) = \{ \squoted{A}, \squoted{B} \}$.
% \item $L(u) = \{ w \in \Sigma^* \mid \;|w| \,\texttt{\%}\, 2 = 1 \}$,

%       denn ein String ungerader Länge hat entweder die Länge 1 oder er kann aus einem String ungerader Länge
%       durch Anfügen zweier Buchstaben erzeugt werden.
% \item $L(a) = \{ w \in \Sigma^* \mid\; \exists k \in \mathbb{N}: |w| = 2 \cdot k - 1 \wedge w[k] = \squoted{A} \}$,
  
%       denn wenn wir an einen String, bei dem der Buchstabe $\squoted{A}$ in der Mitte steht, vorne
%       und hinten jeweils einen Buchstaben anfügen, erhalten wir wieder einen String, in
%       dessen Mitte der Buchstabe $\squoted{A}$ steht
% \item $L(b) = \{ w \in \Sigma^* \mid\; \exists k \in \mathbb{N}: |w| = 2 \cdot k - 1 \wedge w[k] = \squoted{B} \}$,

%       denn die Variable $b$ ist analog zur Variablen $a$ definiert worden.  Der einzige
%       Unterschied ist der, dass nun der Buchstabe $B$ in der Mitte liegt.
% \item $
%   \begin{array}[t]{lcl}    
% L(s) & = & \quad \bigl\{ w \in \Sigma^* \big|\; |w| \,\texttt{\%}\, 2 = 1 \bigr\} \\[0.1cm] 
%      &   & \cup\; \bigl\{ w \in \Sigma^* \big|\; \exists x,y \in \Sigma^*: 
%                           w = xy \wedge |x| \,\texttt{\%}\, 2 = 1 
%                                  \wedge |y| \,\texttt{\%}\, 2 = 1  \wedge \hat{x} \not= \hat{y} \bigr\} \\[0.2cm]
%      & = & \quad \bigl\{ w \in \Sigma^* \mid \neg (\exists v \in \Sigma^*: w = vv) \bigr\}
%   \end{array}
% $
%       \\[0.2cm]
%       denn wir haben oben argumentiert, dass alle Strings der Sprache $L$ entweder eine
%       ungerade Länge haben oder in zwei Teile ungerader Länge zerlegt werden können, so dass in der Mitte
%       dieser Teile verschiedene Buchstaben stehen: Entweder steht im ersten Teil ein $\squoted{A}$
%       und im zweiten Teil steht ein $\squoted{B}$ oder es ist umgekehrt.
% \end{enumerate}
% Um die obigen Behauptungen formal zu beweisen müssten wir nun einerseits noch durch eine Induktion
% nach der Länge der Herleitung zeigen, dass die von den Grammatik-Symbolen erzeugten
% Strings tatsächlich in den oben angegebenen Mengen liegen.  Andererseits müssten wir für
% die oben angegebenen Mengen zeigen, dass sich jeder String der jeweiligen Menge auch tatsächlich mit den
% angegebenen Grammatik-Regeln erzeugen lässt.  Dieser Nachweis würde dann durch Induktion über die Länge der
% einzelnen Strings geführt werden.  Da diese Nachweise einfach sind und keine
% Überraschungen mehr bieten, verzichten wir hier darauf.
% \qed

% \remark
% Wir werden später sehen, dass das Komplement der in der letzten Aufgabe definierten Sprache $L$,
% also die Sprache
% \\[0.2cm]
% \hspace*{1.3cm}
% $L^\mathtt{c} := \Sigma^* \backslash L = \bigl\{ ww \mid  w\in\Sigma^* \bigr\}$
% \\[0.2cm]
% keine kontextfreie Sprache ist.  Damit sehen wir dann, dass die Menge der kontextfreien Sprachen
% nicht unter Komplementbildung abgeschlossen ist. \eox

\subsection{Parse Trees}
Using a grammar $G$, we can not only tell whether a given string $s$ is an
element of the language $L(G)$ generated by the grammar, we can also \blue{structure} the string
by building a \blue{parse tree}.  If a grammar is
\\[0.2cm]
\hspace*{1.3cm}
$G = \langle V, T, R, S \rangle$
\\[0.2cm]
given, a \blue{parse tree}\index{parse-tree} for this grammar is a tree satisfying the following
conditions:
\begin{enumerate}
\item The tree consists of two types of nodes:
      \begin{enumerate}
      \item The \blue{leaf nodes} are those nodes that have no outgoing edges.
      \item The \blue{inner nodes} are all those nodes that have outgoing edges.
      \end{enumerate}
\item Each \blue{inner node} is labeled with a variable.
\item Each \blue{leaf node} is labeled with a terminal or with a variable.
\item If a leaf node is labeled with a variable $a$, then the grammar contains a 
      rule of the form
      \\[0.2cm]
      \hspace*{1.3cm}
      $a \rightarrow \lambda$.
\item If an inner node is labeled with a variable $a$ and the children of
      of this node are labeled with the symbols $X_1$, $X_2$, $\cdots$, $X_n$, then
      the grammar $G$ contains a rule of the form 
      \\[0.2cm]
      \hspace*{1.3cm}
      $a \rightarrow X_1 X_2 \cdots X_n$.
\end{enumerate}
If we read the leave nodes of a parse tree from left to right,  they yield a word
that is derived from the grammar $G$.  Figure \ref{fig:parse-tree.dot} shows a
parse tree for the word ``\texttt{2*3+4}''.  It is derived using the grammar given above for
arithmetic expressions.  The only caveat here is that instead of the symbol ``$\cdot$'' the parse tree uses the
symbol ``$*$''.

\begin{figure}[!ht]
  \centering
      \epsfig{file=Abbildungen/parse-tree-small.png, scale=0.7}
  \caption{A parse tree for the string ``\texttt{2*3+4}''.}
  \label{fig:parse-tree.dot}
\end{figure}

Since trees of the type shown in Figure \ref{fig:parse-tree.dot} become too large very quickly
we simplify these trees using the following rules:
\begin{enumerate}
\item Is $n$ an interior node labeled with the variable $A$
      and among the children of this node there is exactly one child labeled with a terminal $o$
      then we remove this child and label the node $n$ instead with the
      terminal $o$.
\item If an inner node has only one child, we replace that node with its child.
\end{enumerate}
We call the tree obtained in this way the \blue{abstract syntax tree}.
Figure \ref{fig:abstract-syntax-tree.dot} shows the abstract syntax tree that results
from the tree in Figure \ref{fig:parse-tree.dot}.  The structure stored in this tree is exactly what we need 
to evaluate the arithmetic expression ``\texttt{2*3+4}'', because the tree shows us
the order for evaluating the operators.

\begin{figure}[!ht]
  \centering
      \epsfig{file=Abbildungen/abstract-syntax-tree.eps, scale=0.7}
  \caption{The abstract syntax tree for the string ``\texttt{2*3+4}''.}
  \label{fig:abstract-syntax-tree.dot}
\end{figure}

\subsection{Ambiguous Grammars}
The grammar given at the beginning of section \ref{context-free} to describe arithmetic
expressions seems very complicated because it uses three different syntactic categories: \textsl{arithExpr},
\textsl{product}, and \textsl{factor}.  We introduce a simpler grammar $G$
which describes the same language:
\\[0.2cm]
\hspace*{1.3cm}
$G = \bigl\langle \{\textsl{expr}\}, \{ \textsc{Number}, \textsc{Variable}, \quoted{+}, \quoted{-}, \quoted{$\cdot$}, \quoted{/}, \quoted{(}, \quoted{)} \}, R, \textsl{expr} \bigr\rangle$,
\\[0.2cm]
The rules $R$ are given as follows:
\begin{eqnarray*}
  \textsl{expr} & \rightarrow & \textsl{expr} \quoted{+} \textsl{expr}  \\
                & \mid & \textsl{expr} \quoted{-} \textsl{expr}  \\
                & \mid & \textsl{expr} \quoted{$\cdot$} \textsl{expr}  \\
                & \mid & \textsl{expr} \quoted{/} \textsl{expr}  \\
                & \mid & \quoted{(} \textsl{expr} \quoted{)}     \\
                & \mid & \textsc{Number}                         \\
                & \mid & \textsc{Variable}                         
\end{eqnarray*}
In order to show that the string ``\texttt{2}$\,\cdot\,${3+4}'' is in the language generated by this grammar,
we give the following derivation:
\begin{eqnarray*}
\textsl{expr} & \Rightarrow & \textsl{expr} \quoted{+} \textsl{expr}                           \\
              & \Rightarrow & \textsl{expr} \quoted{$\cdot$} \textsl{expr} \quoted{+} \textsl{expr}  \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \textsl{expr} \quoted{+} \textsl{expr}     \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \texttt{3} \quoted{+} \textsl{expr}        \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \texttt{3} \quoted{+} \texttt{4}           
\end{eqnarray*}
This derivation corresponds to the abstract syntax tree shown in Fig.
\ref{fig:abstract-syntax-tree.dot}
is shown.  However, there is another derivation of the string ``\texttt{2$\,\cdot\,$3+4}'' with this grammar:
\begin{eqnarray*}
\textsl{expr} & \Rightarrow & \textsl{expr} \quoted{$\cdot$} \textsl{expr}                           \\
              & \Rightarrow & \textsl{expr} \quoted{$\cdot$} \textsl{expr} \quoted{+} \textsl{expr}  \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \textsl{expr} \quoted{+} \textsl{expr}     \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \texttt{3} \quoted{+} \textsl{expr}        \\
              & \Rightarrow & \texttt{2} \quoted{$\cdot$} \texttt{3} \quoted{+} \texttt{4}           
\end{eqnarray*}
This derivation corresponds to the abstract syntax tree shown in Fig.
\ref{fig:abstract-syntax-tree-prod.dot}.
In this derivation, the string ``\texttt{2$\,\cdot\,$3+4}'' is apparently taken to be a product,
which contradicts the convention that the operator ``\texttt{$\cdot$}'' binds stronger than the operator
``\texttt{+}''.  If we were to evaluate the string using the last syntax tree, we would
obviously get the wrong result! 
\begin{figure}[!ht]
  \centering
      \epsfig{file=Abbildungen/abstract-syntax-tree-prod.eps, scale=0.6}
  \caption{Another abstract syntax tree for the string ``\texttt{2$\,\cdot\,$3+4}''. Here ``$\cdot$'' is
    denoted as ``\texttt{*}''.}
  \label{fig:abstract-syntax-tree-prod.dot}
\end{figure}
The reason for this problem is the fact that the last specified grammar is
\blue{\underline{ambi}g\underline{uous}}. \index{ambiguous grammar}
An ambiguous grammar is unsuitable for parsing.  Unfortunately, the question of whether a given
grammar is ambiguous is, in general, not
\href{http://en.wikipedia.org/wiki/Ambiguous_grammar#Recognizing_ambiguous_grammars}{decidable}:
It can be shown that this question is equivalent to the
\href{http://en.wikipedia.org/wiki/post_correspondence_problem}{\blue{Post correspondence problem}}.
Since Post's correspondence problem has been shown to be undecidable,  the
question  whether a grammar is ambiguous is also unsolvable.
Proofs of these claims can be found, for example, in the book by Hopcroft, Motwani, and Ullman \cite{hopcroft:06}. 

% \example
% Es sei $\Sigma = \{ \squoted{A}, \squoted{B} \}$.  Die Sprache $L$ enthalte alle die Wörter
% aus $\Sigma^*$, bei denen die Buchstaben \squoted{A} and \squoted{B} mit der gleichen
% Häufigkeit auftreten, es gilt also
% \\[0.2cm]
% \hspace*{1.3cm}
% $L = \bigl\{ w \in \Sigma^* \mid \textsl{count}(w, \squoted{A}) = \textsl{count}(w, \squoted{B}) \bigr\}$.
% \\[0.2cm]
% Dann wird die Sprache $L$ durch die kontextfreie Grammatik $G_1 = \langle \{s\}, \Sigma, R_1, s \rangle$ beschrieben,
% deren Regeln wie folgt gegeben sind:
% \\[0.2cm]
% \hspace*{1.3cm}
% $\textsl{s} \;\rightarrow\; \quoted{A} s \quoted{B} s \;\mid\; \quoted{B} s \quoted{A} s \;\mid\; \lambda$
% \\[0.2cm]
% Der Grund ist, dass ein String $w \in L$ entweder mit einem \squoted{A} oder mit einem \squoted{B}
% beginnt.  Im ersten Fall muss es zu diesem \squoted{A} ein korrespondierendes \squoted{B} geben, denn
% die Anzahl der Auftreten von \squoted{A} und \squoted{B} sind gleich.  Fassen wir den Buchstaben
% \squoted{A} wie eine öffnende Klammer auf und interpretieren den Buchstaben \squoted{B} als die zu
% \squoted{A} korrespondierende schließende Klammer, so ist klar, dass der String, der zwischen diesen
% beiden Auftreten von \squoted{A} und \squoted{B} liegt, ebenfalls gleich viele Auftreten von
% \squoted{A} wie von \squoted{B} hat.  Genauso muss dies dann für den Rest des Strings gelten, der nach
% dem \squoted{B} folgt.  Diese Überlegung erklärt die Regel
% \\[0.2cm]
% \hspace*{1.3cm}
% $\textsl{s} \;\rightarrow\; \quoted{A} s \quoted{B} s$
% \\[0.2cm]
% Die Regel
% \\[0.2cm]
% \hspace*{1.3cm}
% $\textsl{s} \;\rightarrow\; \quoted{B} s \quoted{A} s$
% \\[0.2cm]
% lässt sich in analoger Weise erklären,  wenn wir den Buchstaben \squoted{B} als öffnende Klammer und
% \squoted{A} als schließende Klammer interpretieren. 

% Diese Grammatik ist allerdings mehrdeutig: Betrachten wir beispielsweise den String 
% ``\texttt{ABAB}'', so stellen wir fest, dass sich dieser prinzipiell auf zwei Arten ableiten lässt:
% \begin{eqnarray*}
%   s & \Rightarrow &\quoted{A} s \quoted{B} s                       \\
%     & \Rightarrow &\quoted{A} \quoted{B} s                         \\
%     & \Rightarrow &\quoted{A} \quoted{B}\quoted{A} s \quoted{B} s \\
%     & \Rightarrow &\quoted{A} \quoted{B}\quoted{A} \quoted{B} s   \\
%     & \Rightarrow &\quoted{A} \quoted{B}\quoted{A} \quoted{B} 
% \end{eqnarray*}
% Eine andere Ableitung desselben Strings ergibt sich, wenn wir im zweiten Ableitungs-Schritt nicht das erste
% $s$ durch $\lambda$ ersetzen sondern stattdessen das zweite $s$ durch $\lambda$ ersetzen:
% \begin{eqnarray*}
%   s & \Rightarrow &\quoted{A} s \quoted{B} s                       \\
%     & \Rightarrow &\quoted{A} s \quoted{B}                         \\
%     & \Rightarrow &\quoted{A} \quoted{B} s\quoted{A} s \quoted{B} \\
%     & \Rightarrow &\quoted{A} \quoted{B}\quoted{A} s \quoted{B}   \\
%     & \Rightarrow &\quoted{A} \quoted{B}\quoted{A} \quoted{B}     \\
% \end{eqnarray*}
% Abbildung \ref{fig:ambiguous-a.dot} zeigt die Parse-Bäume, die sich aus den beiden Ableitungen ergeben.
% Wir können erkennen, dass die Struktur dieser Bäume unterschiedlich ist:  Im ersten Fall gehört das erste
% ``\texttt{A}'' zu dem ersten ``\texttt{B}'', im zweiten Fall gehört das erste ``\texttt{A}'' zu dem letzten
% ``\texttt{B}''.

% \begin{figure}[!ht]
%       \epsfig{file=Abbildungen/ambiguous-a.eps, scale=0.6}
% \quad
%       \epsfig{file=Abbildungen/ambiguous-b.eps, scale=0.6}
%   \caption{Zwei strukturell verschiedene Parse-Bäume für den String ``\texttt{ABAB}''.}
%   \label{fig:ambiguous-a.dot}
% \end{figure}

% Wir definieren nun eine  kontextfreie Grammatik $G_2 = \langle \{s, u, v, x, y\}, \Sigma, R_2, s \rangle$,
% deren Regeln wie folgt gegeben sind:
% \hspace*{1.3cm}
% \begin{eqnarray*}
% \textsl{s} & \rightarrow & \textsl{u}\, \textsl{s} \;\mid\; \textsl{v}\, \textsl{s} \;\mid\; \lambda \\[0.2cm]
% \textsl{u} & \rightarrow &\quoted{A} \textsl{x} \quoted{B}                \\[0.2cm]
% \textsl{v} & \rightarrow & \quoted{B} \textsl{y} \quoted{A}                \\[0.2cm]
% \textsl{x} & \rightarrow & \textsl{u}\, \textsl{x} \;\mid\; \lambda \\[0.2cm]
% \textsl{y} & \rightarrow & \textsl{v}\,  \textsl{y} \;\mid\; \lambda          
% \end{eqnarray*}
% Um die Sprachen, die von den einzelnen Variablen erzeugt werden, klarer beschreiben zu
% können, definieren wir für zwei Strings $\sigma$ und $\omega$ die Relation $\sigma \preceq \omega$ (lese: $\sigma$ ist ein
% Präfix von $\omega$) wie folgt:
% \\[0.2cm]
% \hspace*{1.3cm}
% $\sigma \preceq \omega \quad \stackrel{\rm{def}}{\Longleftrightarrow}\quad \exists \tau \in \Sigma^*: \sigma \tau = \omega$
% \\[0.2cm]
% Sodann bemerken wir, dass von den syntaktischen Variablen $x$ und $y$ die folgenden
% Sprachen erzeugt werden:
% \\[0.2cm]
% \hspace*{1.3cm} 
% $L(x) = \bigl\{ \omega \in L \mid \forall \sigma \preceq \omega : 
%                   \textsl{count}(\sigma,\squoted{B}) \leq \textsl{count}(\sigma,\squoted{A}) \bigr\}$
% \quad und \\[0.2cm]
% \hspace*{1.3cm}
% $L(y) = \bigl\{ \omega \in L \mid \forall \sigma \preceq \omega : 
%                   \textsl{count}(\sigma, \squoted{A}) \leq \textsl{count}(\sigma, \squoted{B}) \bigr\}$.
% \\[0.2cm]
% Ist $w \in L(x)$, so gibt es zu jedem Auftreten des Buchstabens ``\texttt{B}'' in dem String $w$ ein
% dazu korrespondierendes Auftreten des Buchstabens ``\texttt{A}'', das dem Auftreten des Buchstabens
% ``\texttt{B}'' vorangeht.  Würden wir den Buchstaben
% ``\texttt{A}'' durch eine öffnende Klammer und den Buchstaben ``\texttt{B}'' durch eine schließende
% Klammer ersetzen, so wird also niemals eine Klammer geschlossen, die nicht vorher geöffnet wurde.
% Damit ist klar, dass in einem String der Form
% \\[0.2cm]
% \hspace*{1.3cm}
% ``\texttt{A}'' $w$ ``\texttt{B}'' \quad mit $w \in L(x)$ 
% \\[0.2cm]
% das zu dem ersten ``\texttt{A}'' korrespondierende ``\texttt{B}'' nur das letzte ``\texttt{B}'' sein kann.
% Analog können wir sehen, dass in einem String der Form
% \\[0.2cm]
% \hspace*{1.3cm}
% ``\texttt{B}'' $w$ ``\texttt{A}'' \quad mit $w \in L(y)$ 
% \\[0.2cm]
% das zu dem ersten ``\texttt{B}'' korrespondierende ``\texttt{A}'' nur das letzte ``\texttt{A}'' sein kann.

% Ein String der Sprache $L$ fängt nun entweder mit ``\texttt{A}'' oder mit ``\texttt{B}''
% an.  Im ersten Fall interpretieren wir das ``\texttt{A}'' als öffnende Klammer und 
% das ``\texttt{B}'' als schließende Klammer und suchen nun das ``\texttt{B}'', das dem
% ``\texttt{A}'' am Anfang des Strings zugeordnet ist.  Der String, der mit dem
% ``\texttt{A}'' anfängt und dem ``\texttt{B}'' endet, liegt in der Sprache $L(u)$.
% Auf dieses ``\texttt{B}'' kann dann noch ein weiterer Teilstring folgen, der
% gleich viele ``\texttt{A}''s und ``\texttt{B}''s enthält.  Ein solcher Teilstring liegt
% offensichtlich ebenfalls in der Sprache $L$ und kann daher von $s$ mittels der Regel
% \\[0.2cm]
% \hspace*{1.3cm}
% $\textsl{s} \rightarrow \textsl{u}\, \textsl{s}$
% \\[0.2cm]
% erzeugt werden.
% Im zweiten Fall fängt der String mit einem ``\texttt{B}'' an.  Dieser Fall ist
% analog zum ersten Fall.    \qed
% \vspace*{0.3cm}

% In dem obigen Beispiel hatten wir Glück und konnten eine Grammatik finden, mit der sich
% die Sprache eindeutig parsen lässt.  Es  gibt allerdings auch kontextfreie Sprachen, die 
% \href{http://en.wikipedia.org/wiki/Ambiguous_grammar#Inherently_ambiguous_languages}{inhärent mehrdeutig}
% \index{inhärent mehrdeutig}
% sind: Es lässt sich beispielsweise zeigen, dass für das Alphabet 
% $\Sigma =  \{ \squoted{A}, \squoted{B}, \squoted{C}, \squoted{D} \}$
% die Sprache
% \\[0.2cm]
% \hspace*{1.3cm}
% $L =  \bigl\{ \mathtt{A}^m \mathtt{B}^m \mathtt{C}^n \mathtt{D}^n \mid m, n \in \mathbb{N} \bigr\}
%  \cup \bigl\{ \mathtt{A}^m \mathtt{B}^n \mathtt{C}^n \mathtt{D}^m \mid m, n \in \mathbb{N} \bigr\}
% $
% \\[0.2cm]
% kontextfrei ist, aber jede Grammatik $G$ mit der Eigenschaft $L = L(G)$ ist
% notwendigerweise mehrdeutig.  Das Problem ist, dass für gewisse große Zahlen $n\in \mathbb{N}$ ein
% String der Form 
% \\[0.2cm]
% \hspace*{1.3cm}
% $\mathtt{A}^n \mathtt{B}^n \mathtt{C}^n \mathtt{D}^n$
% \\[0.2cm]
% immer zwei strukturell verschiedene Parse-Bäume besitzen muss.  Ein Beweis dieser Behaupung
% findet sich in der ersten Auflage des Buchs von  Hopcroft und Ullman auf Seite 100 \cite{hopcroft:79}.   

\section{Top-Down Parser}
In this section, we present a method that can be used to conveniently parse a whole range of
grammars.  The basic idea is simple: In order to parse a string $w$ using
a grammar rule of the form
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{a} \rightarrow \textsl{X}_1 \textsl{X}_2 \cdots \textsl{X}_n$
\\[0.2cm]
we try to parse an $X_1$ first.  In doing so, we decompose the string $w$ into the
form
$w = w_1 r_1$ such that $w_1 \in L(X_1)$ holds.  Then we try to find an $X_2$ in the residual string
$r_1$, thus decomposing $r_1$ as $r_1 = w_2 r_2$ where
$w_2 \in L(X_2)$ holds.  Continuing this process, we end up with the string $w$ being split as
\\[0.2cm]
\hspace*{1.3cm}
$w = w_1 w_2 \cdots w_n$ \quad with $w_i \in L(X_i)$ for all $i=1,\cdots,n$.
\\[0.2cm]
Unfortunately, this procedure does not work when the grammar is
\blue{left-recursive}\index{left-recursive}, that is, a rule has the form
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{a} \rightarrow \textsl{a}\, \beta$
\\[0.2cm]
because then to parse an $\textsl{a}$ we would immediately try again to parse an $a$ and thus we would be stuck in an infinite loop.
There are two ways to deal with this kind of problem:
\begin{enumerate}[(a)]
\item We can rewrite the grammar so that it no longer is left-recursive.
\item A simpler method is to extend the notion of a context-free grammar.
      We will use the notion of a so called \blue{extended Backus Naur form} grammar
      (abbreviated as \textsc{Ebnf}-grammar).   Theoretically, the expressive power of
      \textsc{Ebnf} grammars is the same as the expressive power of context-free grammars.
      In practice, however, it turns out that the construction of top-down parsers for
      \textsc{Ebnf} grammars is easier, because in an \textsc{Ebnf} grammar the left recursion can often be replaced
      by iteration. 
\end{enumerate}
In the rest of this chapter we will discuss these two procedures in more detail using the grammar for
arithmetic expressions as an example.  


\subsection{Rewriting a  Grammar to Eliminate Left Recursion \label{left-recursion}}
In the following, assume that a grammar $G = \langle V, T, R, S \rangle$ is given, $a \in V$ is a syntactic
variable and the Greek letters $\beta$ and $\gamma$ stand for any strings consisting of syntactic variables and
tokens, i.e.~we have $\beta, \gamma \in (V \cup T)^*$.  If  $a$ is defined by the two rules
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcl}
a & \rightarrow & a \beta \\
  & \mid & \gamma
\end{array}
$
\\[0.2cm]
then a derivation of $a$, where we always replace the syntactic variable $a$ first, has the form 
\\[0.2cm]
\hspace*{1.3cm}
$a \Rightarrow a \beta \Rightarrow a \beta \beta \Rightarrow a \beta \beta \beta
 \Rightarrow \cdots \Rightarrow a \beta^n \Rightarrow \gamma \beta^n$.
\\[0.2cm]
Thus we see that the language $L(a)$ described by the syntactic variable $a$ consists of all the
strings that can be derived from the expression $\gamma \beta^n$:
\\[0.2cm]
\hspace*{1.3cm}
$L(a) = \bigl\{ w \in \Sigma^* \mid \exists n \in \mathbb{N}: \gamma \beta^n \Rightarrow^* w \bigr\}$.
\\[0.2cm]
This language can also be described by the following rules for $a$:
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcl}
a & \rightarrow & \gamma b \\[0.2cm]
b & \rightarrow & \beta b \\
  & \mid & \lambda 
\end{array}
$
\\[0.2cm]
Here we have introduced the auxiliary variable $b$.  The derivations resulting from the syntactic variable $b$
have the form
\\[0.2cm]
\hspace*{1.3cm} $b \Rightarrow \beta b \Rightarrow \beta \beta b \Rightarrow \cdots \Rightarrow
\beta^n b \Rightarrow \beta^n$.
\\[0.2cm]
Hence the variable $b$ describes the language
\\[0.2cm]
\hspace*{1.3cm} $L(b) = \bigl\{ w \in \Sigma \mid \exists n \in \mathbb{N}: \beta^n \Rightarrow^* w
\bigr\}$.
\\[0.2cm]
Thus it is clear that with the grammar rules given above we have
\\[0.2cm]
\hspace*{1.3cm} $L(a) = \bigl\{ w \in \Sigma^* \mid \exists n \in \mathbb{N}: \gamma \beta^n
\Rightarrow^* w \bigr\}$.
\\[0.2cm]
To remove the left recursion from the grammar shown in Figure \ref{fig:Expr} on page \pageref{fig:Expr},
we need to generalize the example given above.  We now consider
the general case and assume that a non-terminal $a$ is defined by rules of the following form:
\\[0.2cm]
\hspace*{1.3cm} $
\begin{array}[t]{lcl}
a & \rightarrow & a \beta_1 \\
  & \mid & a \beta_2 \\
  & \vdots & \vdots \\
  & \mid & a \beta_k \\[0.2cm]
  & \mid & \gamma_1 \\
  & \vdots & \vdots \\
  & \mid & \gamma_l
\end{array}
$
\\[0.2cm]
We can reduce this case to the first case by introducing two auxiliary variables $b$ and $c$:
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcl}
a & \rightarrow & a b \mid c \\[0.2cm]
b & \rightarrow & \beta_1 \mid \cdots \mid \beta_k \\[0.2cm]
c & \rightarrow & \gamma_1 \mid \cdots \mid \gamma_l
\end{array}
$
\\[0.2cm]
Then we can rewrite this grammar by introducing a new auxiliary variable, let's call it $l$
for list, and get
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcl}
a & \rightarrow & c\;l \\[0.2cm]
l & \rightarrow & b\;l \mid \lambda.  
\end{array}
$
\\[0.2cm]
At this point, the auxiliary variables $b$ and $c$ can now be eliminated.  This yields the following grammar
rules: 
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}[t]{lcl}
a & \rightarrow & \gamma_1\;l \;\mid\; \gamma_2\;l \;\mid\; \cdots \;\mid\; \gamma_l\;l \\[0.2cm]
l & \rightarrow & \beta_1 \;l \;\mid\; \beta_2 \;l \;\mid\; \cdots \;\mid\; \beta_k \;l \;\mid\; \lambda
\end{array}
$
\begin{figure}[htbp]
  \begin{center}    
  \framebox{
  \framebox{
  \begin{minipage}[t]{8cm}
  \begin{eqnarray*}
  \textsl{expr} & \rightarrow & \;\textsl{expr} \quoted{+} \textsl{product}  \\
                   & \mid & \;\textsl{expr} \quoted{-} \textsl{product}  \\
                   & \mid & \;\textsl{product}                           \\[0.2cm]
  \textsl{product} & \rightarrow & \;\textsl{product} \quoted{$\cdot$} \textsl{factor} \\
                   & \mid & \;\textsl{product} \quoted{/} \textsl{factor}\\
                   & \mid & \;\textsl{factor}                            \\[0.2cm]
  \textsl{factor} & \rightarrow & \quoted{(} \textsl{expr} \quoted{)}        \\
                   & \mid & \;\textsc{Number} 
  \end{eqnarray*}
  \vspace*{-0.5cm}
  \end{minipage}}}
  \end{center}
  \caption{Left-recursive grammar for arithmetic expressions.}
  \label{fig:Expr}
\end{figure}
\vspace*{0.3cm}


\noindent
If we apply this procedure to the grammar for arithmetic expressions shown in Figure \ref{fig:Expr}, we obtain
the grammar shown in Figure \ref{fig:Expr2}. The variables \textsl{exprRest} and \textsl{productRest} can be
interpreted as follows:

\begin{figure}[htbp]
  \begin{center}    
  \framebox{
  \framebox{
  \begin{minipage}[t]{9cm}
  \begin{eqnarray*}
  \textsl{expr}        & \rightarrow & \;\textsl{product}\;\;\textsl{exprRest}            \\[0.2cm]
  \textsl{exprRest}    & \rightarrow & \quoted{+} \textsl{product}\;\;\textsl{exprRest}   \\
                       & \mid        & \quoted{-} \textsl{product}\;\;\textsl{exprRest}   \\
                       & \mid        & \;\lambda                                      \\[0.2cm]
  \textsl{product}     & \rightarrow & \;\textsl{factor}\;\;\textsl{productRest}          \\[0.2cm]
  \textsl{productRest} & \rightarrow & \quoted{$\cdot$} \textsl{factor}\;\;\textsl{productRest} \\
                       & \mid        & \quoted{/} \textsl{factor}\;\;\textsl{productRest} \\
                       & \mid        & \;\lambda                                      \\[0.2cm]
  \textsl{factor}      & \rightarrow & \quoted{(} \textsl{expr} \quoted{)}                \\
                       & \mid        & \;\textsc{Number} 
  \end{eqnarray*}
  \vspace*{-0.5cm}
  \end{minipage}}}
  \end{center}
  \caption{Grammar for arithmetic expressions without left-recursion.}
  \label{fig:Expr2}
\end{figure}

\begin{enumerate}
\item \textsl{exprRest} describes a list of the form.
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{op} \;\textsl{product} \;\cdots \;\textsl{op}\; \textsl{product}$,
      \\[0.2cm]
      where $\textsl{op} \in \{ \quoted{+}, \quoted{-} \}$.
\item \textsl{productRest} describes a list of the form
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{op} \;\textsl{factor} \;\cdots \;\textsl{op} \;\textsl{factor}$,
      \\[0.2cm]
      where $\textsl{op} \in \{ \quoted{$\cdot$}, \quoted{/} \}$ holds. 
\end{enumerate}

\exerciseEng \label{exercise:regexp}
\begin{enumerate}[(a)]
\item The following grammar describes regular expressions:
      \begin{center}    
          \framebox{
            \begin{minipage}[t]{9cm}
              \begin{eqnarray*}
                \textsl{regExp} & \rightarrow & \;\textsl{regExp} \quoted{+} \textsl{regExp} \\
                                & \mid & \;\textsl{regExp} \;\textsl{regExp}                 \\
                                & \mid & \;\textsl{regExp}\quoted{*}                         \\
                                & \mid & \quoted{(} \textsl{regExp} \quoted{)}               \\
                                & \mid & \;\textsc{Letter}                               
              \end{eqnarray*}
              \vspace*{-0.5cm}
            \end{minipage}}
      \end{center}
      This grammar uses only the syntactic variable $\{ \textsl{regExp} \}$ and the following 
      Terminals
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{\squoted{+}, \squoted{*}, \squoted{(}, \squoted{)}, \textsc{Letter}\}$.
      \\[0.2cm]
      Since the grammar is ambiguous, this grammar is unsuitable for parsing.
      Transform this grammar into an unambiguous grammar where the
      postfix operator ``\texttt{*}'' binds more strongly than the concatenation of two regular
      expressions, while the ``\texttt{+}'' operator binds weaker than concatenation. 
      Use the grammar for arithmetic expressions as a guide and introduce suitable new syntactic
      variables.
\item Remove the left recursion from the grammar created in part (a) of this task.
      \eox
\end{enumerate}


\subsection{Implementing a Top Down Parser in \textsl{Python}}
\noindent
Now we are ready to implement a parser for recognizing arithmetic expressions.
We will use the grammar that is shown in Figure \ref{fig:Expr2} on page \pageref{fig:Expr2}.
Before we can implement the parser, we need a scanner.  We will use a hand-coded scanner that is shown in
Figure \ref{fig:Top-Down-Parser:scanner.ipynb} on page \pageref{fig:Top-Down-Parser:scanner.ipynb}.
The function \texttt{tokenize} implemented in this scanner receives a string \texttt{s} as argument and returns
a list of tokens.  The string \texttt{s} is supposed to represent an arithmetical expression. 
In order to understand the implementation, you need to know the following:
\begin{enumerate}[(a)]
\item We need to set the flag \texttt{re.VERBOSE} in our call of the function \texttt{findall}
      below because otherwise we are not able to format the regular expression \texttt{lexSpec} the way 
      we have done it.  In prticular, we would not be able to use comment inside the regular expression
      and we would not be able to format the regular expression using white space.
\item The regular expression \texttt{lexSpec} contains 3 alternatives: white space, numbers, and operator symbols.
      White space is removed, while everything else is collected in the list \texttt{result}.
      Furthermore, the empty string that occurs at the end has to be removed in the same way as white space.
\end{enumerate}


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm
              ]{python3}
    def tokenize(s: str) -> list[str]:
        lexSpec = r'''[ \t]+        |  # blanks and tabs
                      [1-9][0-9]*|0 |  # numbers
                      [-+*/()]      |  # arithmetical operators and parentheses
                   '''
        tokenList = re.findall(lexSpec, s, re.VERBOSE)
        result    = []
        for token in tokenList:
            if token == '' or token[0] in [' ', '\t']:        # skip blanks and tabs
                continue
            result += [ token ]
        return result
\end{minted}
\vspace*{-0.3cm}
\caption{A scanner for arithmetic expressions.}
\label{fig:Top-Down-Parser:scanner.ipynb}
\end{figure}


\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.0cm,
                xrightmargin  = 0.0cm
              ]{python3}
    def parse(s):
         TL           = tokenize(s)
         result, Rest = parseExpr(TL)
         assert Rest == [], f'Parse Error: could not parse {TL}'
         return result
    
    def parseExpr(TL):
        product, Rest = parseProduct(TL)
        return parseExprRest(product, Rest)
    
    def parseExprRest(Sum, TL):
        if TL == []:
            return Sum, []
        elif TL[0] == '+':
            product, Rest = parseProduct(TL[1:])
            return parseExprRest(Sum + product, Rest)
        elif TL[0] == '-':
            product, Rest = parseProduct(TL[1:])
            return parseExprRest(Sum - product, Rest)
        else:
            return Sum, TL
    
    def parseProduct(TL):
        factor, Rest = parseFactor(TL)
        return parseProductRest(factor, Rest)
    
    def parseProductRest(product, TL):
        if TL == []:
            return product, []
        elif TL[0] == '*': 
            factor, Rest = parseFactor(TL[1:])
            return parseProductRest(product * factor, Rest)
        elif TL[0] == '/':
            factor, Rest = parseFactor(TL[1:])
            return parseProductRest(product / factor, Rest)
        else:
            return product, TL
    
    def parseFactor(TL):
        if TL[0] == '(': 
            expr, Rest = parseExpr(TL[1:])
            assert Rest[0] == ')', 'Parse Error: expected ")"'
            return expr, Rest[1:]
        else: 
            return int(TL[0]), TL[1:]
\end{minted}
\vspace*{-0.3cm}
\caption{A top down parser for arithmetic expressions.}
\label{fig:Top-Down-Parser.ipynb}
\end{figure}


\noindent
Figure \ref{fig:Top-Down-Parser.ipynb} on page
\pageref{fig:Top-Down-Parser.ipynb} shows an implementation of a recursive descent parser in
\textsc{Python}. 
\begin{enumerate}[(a)]
\item The main function is the function \texttt{parse}. This function takes a string $s$
      representing an arithmetic expression.  This string is tokenized using the 
      function \texttt{tokenize}.  The function \texttt{tokenize} turns a
      string into a list of tokens.  For example, the expression
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|tokenize('(1 + 2) * 3')|
      \\[0.2cm]
      returns the result
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|['(', 1, '+', 2, ')', '*', 3]|.
      \\[0.2cm]
      This list of tokens is then parsed by the function \texttt{parseExpr}.
      That function returns a pair: 
      \begin{enumerate}
      \item The first  component is the value of the arithmetic expression.
      \item The second component is the list of those tokens that have not been consumed
            when parsing the expression.  Of course, on a successful parse this list
            should be empty.
      \end{enumerate}
\item The function \texttt{parseExpr} implements the grammar rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{expr} \;\rightarrow\;\textsl{product}\;\;\textsl{exprRest}$. 
      \\[0.2cm]
      It takes a token list \texttt{TL} as input.  It will return a pair of the form
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{($v$, Rest)},
      \\[0.2cm]
      where $v$ is the value of the arithmetic expression that has been parsed, while
      \texttt{Rest} is the list of the remaining tokens.  For example, the expression
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|parseExpr(['(', 1, '+', 2, ')', '*', 3, ')', '*', 2])|
      \\[0.2cm]
      returns the result
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|[9, [')', '*', 2]]|.
      \\[0.2cm]
      Here, the part \verb|['(', 1, '+', 2, ')', '*', 3]| has been parsed and evaluated as
      the number $9$ and \\ \verb|[')', '*', 2]| is the list of tokens that have not yet been
      processed.

      In order to parse an arithmetic expression, the function first parses a
      \textsl{product} and then it tries to parse the remaining tokens as an
      \textsl{exprRest}.   The function \texttt{parseExprRest} that is used to parse an
      \textsl{exprRest} needs two arguments:
      \begin{enumerate}
      \item The first argument is the value of the product that has been parsed 
            by the function \texttt{parseProduct}.
      \item The second argument is the list of tokens that can be used.
      \end{enumerate}
      To understand the mechanics of \texttt{parseExpr}, consider the evaluation of
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|[1, '*', 2, '+', 3]|.
      \\[0.2cm]
      Here, the function \texttt{parseProduct} will return the result
      \\[0.2cm]
      \hspace*{1.3cm}
      \verb|(2, ['+', 3])|,
      \\[0.2cm]
      where $2$ is the result of parsing and evaluating the token list \verb|[1, '*', 2]|, while
      \verb|['+', 3]| is the part of the input token list that is not used by
      \texttt{parseProduct}.  Next, the list \verb|['+', 3]| needs to be parsed as 
      the rest of an expression and then $3$ needs to be added to $2$.      
\item The function \texttt{parseExprRest} takes a number and a list of tokens.
      It implements the following grammar rules:
      \hspace*{1.3cm}
      \begin{eqnarray*}
        \textsl{exprRest} & \rightarrow & \quoted{+} \textsl{product}\;\;\textsl{exprRest} \\
                          & \mid        & \quoted{-} \textsl{product}\;\;\textsl{exprRest} \\
                          & \mid        & \;\lambda                                    
      \end{eqnarray*}
      Therefore, it checks whether the first token is either \squoted{+} or \squoted{-}.
      If the token is \squoted{+}, it parses a \textsl{product}, adds the result of this 
      product to the \texttt{sum} of values parsed already and proceeds to parse the rest
      of the tokens.  

      The case that the first token is \squoted{-} is similar to the previous case.
      If the next token is neither \squoted{+} nor \squoted{-}, then it could be either the
      token \squoted{)} or else it might be the case that the list of tokens is already
      exhausted.  In either case, the rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{exprRest} \;\rightarrow\; \lambda$
      \\[0.2cm]
      is used.  Therefore, in that case we have not consumed any tokens and hence
      the input argument is already the result.
\item The function \texttt{parseProduct} implements the rule
      \\[0.2cm]
      \hspace*{1.3cm}
      $\textsl{product} \;\rightarrow\; \textsl{factor} \;\; \textsl{exprRest}$.
      \\[0.2cm]
      The implementation is similar to the implementation of \textsl{parseExpr}.
\item The function \texttt{parseProductRest} implements the rules
      \begin{eqnarray*}
      \textsl{productRest} & \rightarrow & \quoted{$\cdot$} \textsl{factor}\;\;\textsl{productRest} \\
                       & \mid        & \quoted{/} \textsl{factor}\;\;\textsl{productRest}     \\
                       & \mid        & \;\lambda                                      
      \end{eqnarray*}
      The implementation is similar to the implementation of \textsl{parseExprRest}.
\item The function \texttt{parseFactor} implements the rules
      \begin{eqnarray*}
      \textsl{factor} & \rightarrow & \quoted{(} \textsl{expr} \quoted{)} \\
                      & \mid        & \;\textsc{Number} 
      \end{eqnarray*}
      Therefore, we first check whether the next token is \squoted{(} because in that case,
      we have to use the first grammar rule, otherwise we use the second.
\end{enumerate}
The parser shown in Figure \ref{fig:Top-Down-Parser.ipynb} does not contain any error handling. 
Appropriate error handling will be discussed once we have covered the theory of top-down parsing.

\exerciseEng
In Exercise 21 on page \pageref{exercise:regexp} you have developed a grammar for regular expressions that does
not contain left recursion.  Implement a top down parser for this grammar.  The resulting grammar should return
a nested tuple that represents a regular expression.
\eox

\subsection{Implementing a Recursive Descent Parser that Uses an \textsc{EBNF} Grammar}
The previous solution to parse an arithmetical expression was not completely
satisfying:  The reason is that we did not really fix the problem of left recursion but rather cured the
symptoms.  The underlying reason for left recursion is that context free grammars are not that convenient to
describe the structure of programming languages since a description of this structure needs both
recursion and iteration, but context-free grammars provide no direct way to describe iteration.
Rather, they simulate iteration via recursion.  Let us therefore improve the convenience of context-free
languages by admitting the regular expression operators \squoted{*}, \squoted{|}, and \squoted{?} on
the right hand side of grammar rules.  The meaning of these operators is the same as when these operators are used in 
the regular expressions of the programming language \textsl{Python}.  Furthermore, the right hand side of a
grammar rule can be structured using parentheses.  These new type of grammars are known as
\href{http://en.wikipedia.org/wiki/Extended_Backus_Naur_Form}{\emph{extended Backus Naur form}}
\index{\textsc{Ebnf}-Grammar} grammars, which is abbreviated as \textsc{Ebnf} grammars.



\begin{figure}[htbp]
  \begin{center}    
  \framebox{
  \framebox{
  \begin{minipage}[t]{9cm}

  \begin{eqnarray*}
  \mathrm{expr}    & \rightarrow & \mathrm{product}\;\;\bigl((\texttt{'+'}\;|\;\texttt{'-'})\;\; \mathrm{product}\bigr)^* \\[0.2cm]
  \mathrm{product} & \rightarrow & \mathrm{factor} \;\;\bigl((\texttt{'*'}\;|\;\texttt{'/'})\;\; \mathrm{factor}\bigr)^*  \\[0.2cm]   
  \mathrm{factor}  & \rightarrow & \texttt{'('} \;\;\mathrm{expr} \;\;\texttt{')'}                             \\
                   & \mid        & \texttt{NUMBER} 
  \end{eqnarray*}
  \vspace*{-0.5cm}

  \end{minipage} \hspace*{1.cm}}}
  \end{center}
  \caption{\textsc{Ebnf} grammar for arithmetical expressions.}
  \label{fig:arith-expr-ebnf}
\end{figure}

It can be shown that the languages described by \textsc{Ebnf} grammars are still context-free
languages.  Therefore, these operators do not change the expressive power of context-free 
grammars. 
However, it is often much more \underline{convenient} to describe a language using an \textsc{Ebnf}
grammar rather than using a context-free grammar.  Figure \ref{fig:arith-expr-ebnf}
displays an \textsc{Ebnf} grammar for arithmetical expressions.  

Obviously, the grammar in Figure \ref{fig:arith-expr-ebnf}  is
more concise than the context-free grammar shown in Figure \ref{fig:Expr2} on page \pageref{fig:Expr2}.
For example, the first rule clearly expresses that an arithmetical expression is a list of
products that are separated by the operators \squoted{+} and \squoted{-}.

\noindent
Figure \ref{fig:differentiate.stlx} shows a recursive descent parser that implements this grammar.
\begin{enumerate}
\item The function \texttt{parseExpr} recognizes a \texttt{product} in line 2. 
      The value of this \texttt{product} is stored in the variable 
      \texttt{result} together with the list \texttt{Rest} of those tokens that have not been consumed
      yet.  If the list \texttt{Rest} is not empty and the first token in this
      list is either the operator \squoted{+} or the operator \squoted{-},
      then the function \texttt{parseExpr} tries to recognize more products.
      These are added to or subtracted from the \texttt{result} computed so far in
      line 7 or 9.  If there are no more products to be parsed, the \texttt{while} loop 
      terminates and the function returns the \texttt{result} together with the list of the remaining
      tokens \texttt{Rest}.
\item The function \texttt{parseProduct} recognizes a \texttt{factor} in line 13. 
      The value of this \texttt{factor} is stored in the variable 
      \texttt{result} together with the list \texttt{Rest} of those tokens that have not been consumed
      yet.  If the list \texttt{Rest} is not empty and the first token in this
      list is either the operator \squoted{*} or the operator \squoted{/},
      then the function \texttt{parseProduct} tries to recognize more factors.
      The \texttt{result} computed so far is multiplied with or divided by these factors in
      line 18 or 20.  If there are no more products to be parsed, the \texttt{while} loop 
      terminates and the function returns the \texttt{result} together with the list
      \texttt{Rest} of tokens that have not been consumed.
\item The function \texttt{parseFactor} recognizes a \texttt{factor}.
      This is either an expression in parentheses or a number.
      \begin{itemize}
      \item If the first token is a an opening parenthesis, the function tries to parse
            an expression next.  This expression has to be followed by a closing parenthesis.
            The tokens following this closing parenthesis are not consumed but rather are returned 
            together with the result of evaluating the expression.
      \item If the first token is a number, this number is returned together with the list
            of all those tokens that have not been consumed.
      \end{itemize}
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{minted}[ frame         = lines, 
                framesep      = 0.3cm, 
                firstnumber   = 1,
                bgcolor       = sepia,
                numbers       = left,
                numbersep     = -0.2cm,
                xleftmargin   = 0.3cm,
                xrightmargin  = 0.3cm,
              ]{python3}
    def parseExpr(TL):
        result, Rest = parseProduct(TL)
        while len(Rest) > 1 and Rest[0] in {'+', '-'}: 
            operator = Rest[0]
            arg, Rest = parseProduct(Rest[1:])
            if operator == '+': 
                result += arg
            else:             # operator == '-': 
                result -= arg
        return result, Rest
    
    def parseProduct(TL):
        result, Rest = parseFactor(TL)
        while len(Rest) > 1 and Rest[0] in {'*', '/'}:
            operator = Rest[0]
            arg, Rest = parseFactor(Rest[1:])
            if operator == '*':
                result *= arg
            else:             # operator == '/':
                result /= arg
        return result, Rest
    
    def parseFactor(TL):
        if TL[0] == '(': 
            expr, Rest = parseExpr(TL[1:])
            assert Rest[0] == ')', "ERROR: ')' expected, got {Rest[0]}"
            return expr, Rest[1:]
        else:
            assert isinstance(TL[0], int), "ERROR: Number expected, got {TL[0]}"
            return TL[0], TL[1:]
\end{minted}
\vspace*{-0.3cm}
\caption{A recursive descent parser for the grammar in Figure \ref{fig:arith-expr-ebnf}.}
\label{fig:differentiate.stlx}
\end{figure}

\exerciseEng
In Exercise 21 on page \pageref{exercise:regexp} you have developed an \textsc{Ebnf} grammar for regular
expressions.  Implement a top down parser for this grammar.  The resulting grammar should return
a nested tuple that represents a regular expression.
\eox

\paragraph{Historical Notes} The language \textsc{Algol} \cite{backus:1959,naur:1960} was the first
programming language with a syntax that was based on an \textsc{Ebnf} grammar.  
\pagebreak

\section{Check your Understanding}
\begin{enumerate}[(a)]
\item Define the concept of a \blue{context-free grammar}.
\item Assume that $G$ is a context-free grammar.  How is the language $L(G)$ defined?
\item What is the definition of a \blue{parse tree}?
\item How do we transform a parse tree into an \blue{abstract syntax tree}?
\item What are ambiguous grammars?  
\item How can a context free grammar that contains left recursion be transformed into an equivalent grammar
      that does not contain left recursion.
\item How does a top-down parser work? 
\item Why do we have to eliminate left recursion from a grammar in order to build a top-down parser?
\item Define the notion of an \textsc{Ebnf} grammar.
\end{enumerate}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "formal-languages.tex"
%%% End: 
